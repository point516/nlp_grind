{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fL69zGpmx01k"
      },
      "source": [
        "# Contact\n",
        "For any doubt, question, issue or help, you can always contact us at the following email addresses:\n",
        "\n",
        "Teaching Assistants:\n",
        "\n",
        "- Federico Ruggeri -> federico.ruggeri6@unibo.it\n",
        "- Eleonora Mancini -> e.mancini@unibo.it\n",
        "\n",
        "Professor:\n",
        "- Paolo Torroni -> p.torroni@unibo.it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55jnW-xKxi-2"
      },
      "source": [
        "# Introduction\n",
        "You are asked to address the [EXIST 2023 Task 1](https://clef2023.clef-initiative.eu/index.php?page=Pages/labs.html#EXIST) on sexism detection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HWp5bGwySsb"
      },
      "source": [
        "## Problem Definition\n",
        "The systems have to decide whether or not a given tweet contains or describes sexist expressions or behaviors (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behavior).\n",
        "\n",
        "### Examples:\n",
        "\n",
        "**Text**: *Can’t go a day without women womening*\n",
        "\n",
        "**Label**: Sexist\n",
        "\n",
        "**Text**: *''Society's set norms! Happy men's day though!#weareequal''*\n",
        "\n",
        "**Label**: Not sexist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iu1X4I98M8B"
      },
      "source": [
        "#[Task 1 - 1.0 points] Corpus\n",
        "\n",
        "We have preparared a small version of EXIST dataset in our dedicated [Github repository](https://github.com/lt-nlp-lab-unibo/nlp-course-material/tree/main/2024-2025/Assignment%201/data).\n",
        "\n",
        "Check the `A1/data` folder. It contains 3 `.json` files representing `training`, `validation` and `test` sets.\n",
        "\n",
        "The three sets are slightly unbalanced, with a bias toward the `Non-sexist` class.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AASoMV9XN5l6"
      },
      "source": [
        "### Dataset Description\n",
        "- The dataset contains tweets in both English and Spanish.\n",
        "- There are labels for multiple tasks, but we are focusing on **Task 1**.\n",
        "- For Task 1, soft labels are assigned by six annotators.\n",
        "- The labels for Task 1 represent whether the tweet is sexist (\"YES\") or not (\"NO\").\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFjwB_lCOQKj"
      },
      "source": [
        "\n",
        "### Example\n",
        "\n",
        "\n",
        "    \"203260\": {\n",
        "        \"id_EXIST\": \"203260\",\n",
        "        \"lang\": \"en\",\n",
        "        \"tweet\": \"ik when mandy says “you look like a whore” i look cute as FUCK\",\n",
        "        \"number_annotators\": 6,\n",
        "        \"annotators\": [\"Annotator_473\", \"Annotator_474\", \"Annotator_475\", \"Annotator_476\", \"Annotator_477\", \"Annotator_27\"],\n",
        "        \"gender_annotators\": [\"F\", \"F\", \"M\", \"M\", \"M\", \"F\"],\n",
        "        \"age_annotators\": [\"18-22\", \"23-45\", \"18-22\", \"23-45\", \"46+\", \"46+\"],\n",
        "        \"labels_task1\": [\"YES\", \"YES\", \"YES\", \"NO\", \"YES\", \"YES\"],\n",
        "        \"labels_task2\": [\"DIRECT\", \"DIRECT\", \"REPORTED\", \"-\", \"JUDGEMENTAL\", \"REPORTED\"],\n",
        "        \"labels_task3\": [\n",
        "          [\"STEREOTYPING-DOMINANCE\"],\n",
        "          [\"OBJECTIFICATION\"],\n",
        "          [\"SEXUAL-VIOLENCE\"],\n",
        "          [\"-\"],\n",
        "          [\"STEREOTYPING-DOMINANCE\", \"OBJECTIFICATION\"],\n",
        "          [\"OBJECTIFICATION\"]\n",
        "        ],\n",
        "        \"split\": \"TRAIN_EN\"\n",
        "      }\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJ45bvuOOJ7I"
      },
      "source": [
        "### Instructions\n",
        "1. **Download** the `A1/data` folder.\n",
        "2. **Load** the three JSON files and encode them as pandas dataframes.\n",
        "3. **Generate hard labels** for Task 1 using majority voting and store them in a new dataframe column called `hard_label_task1`. Items without a clear majority will be removed from the dataset.\n",
        "4. **Filter the DataFrame** to keep only rows where the `lang` column is `'en'`.\n",
        "5. **Remove unwanted columns**: Keep only `id_EXIST`, `lang`, `tweet`, and `hard_label_task1`.\n",
        "6. **Encode the `hard_label_task1` column**: Use 1 to represent \"YES\" and 0 to represent \"NO\"."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4j9sbRYE9gl",
        "outputId": "8ed7af47-bd3d-4906-8329-0a9bdd1c04ed"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np\n",
        "import nltk\n",
        "\n",
        "from tqdm import tqdm\n",
        "from collections import OrderedDict\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.tokenize import WhitespaceTokenizer\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "BNhCjpRiE_fV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading JSON data from a file\n",
        "def encode_json(file_path):\n",
        "  with open(file_path, 'r', encoding='utf-8') as file:\n",
        "      data = json.load(file)\n",
        "\n",
        "  df = pd.DataFrame.from_dict(data, orient='index')\n",
        "  return df\n",
        "\n",
        "# Convert dictionary to pandas DataFrame\n",
        "training = encode_json('/content/drive/MyDrive/assignment-2425/data/training.json')\n",
        "validation = encode_json('/content/drive/MyDrive/assignment-2425/data/validation.json')\n",
        "test = encode_json('/content/drive/MyDrive/assignment-2425/data/test.json')"
      ],
      "metadata": {
        "id": "6gXM9Kp6OB0V"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_labels(soft_labels):\n",
        "  labels = []\n",
        "  for row in soft_labels['labels_task1']:\n",
        "    if row.count('YES') > row.count('NO'):\n",
        "      labels.append('YES')\n",
        "    elif row.count('NO') > row.count('YES'):\n",
        "      labels.append('NO')\n",
        "    else:\n",
        "      labels.append(None)\n",
        "\n",
        "  return labels\n",
        "\n",
        "training['hard_label_task1'] = get_labels(training)\n",
        "validation['hard_label_task1'] = get_labels(validation)\n",
        "test['hard_label_task1'] = get_labels(test)\n",
        "\n",
        "training.dropna(inplace=True)\n",
        "validation.dropna(inplace=True)\n",
        "test.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "6gvYlPJjGSK9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training = training[training['lang'] == 'en']\n",
        "validation = validation[validation['lang'] == 'en']\n",
        "test = test[test['lang'] == 'en']"
      ],
      "metadata": {
        "id": "E5qm1B46QNI2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training = training.loc[:,['id_EXIST', 'lang', 'tweet', 'hard_label_task1']]\n",
        "validation = validation.loc[:,['id_EXIST', 'lang', 'tweet', 'hard_label_task1']]\n",
        "test = test.loc[:,['id_EXIST', 'lang', 'tweet', 'hard_label_task1']]"
      ],
      "metadata": {
        "id": "-sF5ija_QmMZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training.loc[training['hard_label_task1'] == 'YES','hard_label_task1'] = 1\n",
        "training.loc[training['hard_label_task1'] == 'NO','hard_label_task1'] = 0\n",
        "\n",
        "validation.loc[validation['hard_label_task1'] == 'YES','hard_label_task1'] = 1\n",
        "validation.loc[validation['hard_label_task1'] == 'NO','hard_label_task1'] = 0\n",
        "\n",
        "test.loc[test['hard_label_task1'] == 'YES','hard_label_task1'] = 1\n",
        "test.loc[test['hard_label_task1'] == 'NO','hard_label_task1'] = 0"
      ],
      "metadata": {
        "id": "oSBD9RYVT2MG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "KOy0zxFg_HhI"
      },
      "source": [
        "# [Task2 - 0.5 points] Data Cleaning\n",
        "In the context of tweets, we have noisy and informal data that often includes unnecessary elements like emojis, hashtags, mentions, and URLs. These elements may interfere with the text analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "i0mLIhZf_HhJ"
      },
      "source": [
        "\n",
        "### Instructions\n",
        "- **Remove emojis** from the tweets.\n",
        "- **Remove hashtags** (e.g., `#example`).\n",
        "- **Remove mentions** such as `@user`.\n",
        "- **Remove URLs** from the tweets.\n",
        "- **Remove special characters and symbols**.\n",
        "- **Remove specific quote characters** (e.g., curly quotes).\n",
        "- **Perform lemmatization** to reduce words to their base form."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_tweet(tweet):\n",
        "    # Remove emojis\n",
        "    tweet = re.sub(r'[^\\x00-\\x7F]+', '', tweet)\n",
        "\n",
        "    # Remove hashtags\n",
        "    tweet = re.sub(r'#\\w+', '', tweet)\n",
        "\n",
        "    # Remove mentions\n",
        "    tweet = re.sub(r'@\\w+', '', tweet)\n",
        "\n",
        "    # Remove URLs\n",
        "    tweet = re.sub(r'http\\S+|www\\S+|https\\S+', '', tweet, flags=re.MULTILINE)\n",
        "\n",
        "    # Remove special characters and symbols\n",
        "    tweet = re.sub(r'[^\\w\\s]', '', tweet)\n",
        "\n",
        "    # Remove specific quote characters\n",
        "    tweet = re.sub(r'[“”‘’\"\\']', '', tweet)\n",
        "\n",
        "    # Remove excessive whitespaces\n",
        "    tweet = re.sub(r'\\s+', ' ', tweet)\n",
        "\n",
        "    return tweet.strip().lower()\n",
        "\n",
        "training['tweet'] = training['tweet'].apply(clean_tweet)\n",
        "validation['tweet'] = validation['tweet'].apply(clean_tweet)\n",
        "test['tweet'] = test['tweet'].apply(clean_tweet)\n",
        "\n",
        "train_texts = training['tweet'].values\n",
        "val_texts = validation['tweet'].values\n",
        "test_texts = test['tweet'].values\n",
        "\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "tokenizer = WhitespaceTokenizer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def get_wordnet_key(pos_tag):\n",
        "    if pos_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif pos_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif pos_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif pos_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return 'n'\n",
        "\n",
        "def lem_text(text: str):\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    tagged = pos_tag(tokens)\n",
        "    words = [lemmatizer.lemmatize(word, get_wordnet_key(tag)) for word, tag in tagged]\n",
        "    return \" \".join(words)\n",
        "\n",
        "lem_train_texts = [lem_text(text) for text in tqdm(train_texts, leave=True, position=0)]\n",
        "lem_val_texts = [lem_text(text) for text in tqdm(val_texts, leave=True, position=0)]\n",
        "lem_test_texts = [lem_text(text) for text in tqdm(test_texts, leave=True, position=0)]\n",
        "\n",
        "training['lemmatized'] = lem_train_texts\n",
        "validation['lemmatized'] = lem_val_texts\n",
        "test['lemmatized'] = lem_test_texts"
      ],
      "metadata": {
        "id": "xs1fQP77LqOY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bcf8864-278f-4d96-9dd7-8791e7387adf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "100%|██████████| 2870/2870 [00:06<00:00, 413.74it/s]\n",
            "100%|██████████| 158/158 [00:01<00:00, 155.22it/s]\n",
            "100%|██████████| 286/286 [00:01<00:00, 241.77it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3KylLHNl0bE"
      },
      "source": [
        "# [Task 3 - 0.5 points] Text Encoding\n",
        "To train a neural sexism classifier, you first need to encode text into numerical format.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hr1lTHUVOXff"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* Embed words using **GloVe embeddings**.\n",
        "* You are **free** to pick any embedding dimension.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6NNMEjWOZQr"
      },
      "source": [
        "### Note : What about OOV tokens?\n",
        "   * All the tokens in the **training** set that are not in GloVe **must** be added to the vocabulary.\n",
        "   * For the remaining tokens (i.e., OOV in the validation and test sets), you have to assign them a **special token** (e.g., [UNK]) and a **static** embedding.\n",
        "   * You are **free** to define the static embedding using any strategy (e.g., random, neighbourhood, etc...)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90UztlGUObXk"
      },
      "source": [
        "### More about OOV\n",
        "\n",
        "For a given token:\n",
        "\n",
        "* **If in train set**: add to vocabulary and assign an embedding (use GloVe if token in GloVe, custom embedding otherwise).\n",
        "* **If in val/test set**: assign special token if not in vocabulary and assign custom embedding.\n",
        "\n",
        "Your vocabulary **should**:\n",
        "\n",
        "* Contain all tokens in train set; or\n",
        "* Union of tokens in train set and in GloVe $\\rightarrow$ we make use of existing knowledge!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "import gensim.downloader as gloader\n",
        "\n",
        "embedding_dimension = 100\n",
        "glove = gloader.load(\"glove-wiki-gigaword-{}\".format(embedding_dimension))"
      ],
      "metadata": {
        "id": "WvYY2FuvjYzH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6a29614-f6b9-47c6-ce57-3b67e00eafff"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocabulary(df):\n",
        "    idx_to_word = OrderedDict()\n",
        "    word_to_idx = OrderedDict()\n",
        "\n",
        "    # start from 2 because index 0 will be for padding, 1 for <OOV>\n",
        "    curr_idx = 2\n",
        "    for sentence in df:\n",
        "        tokens = sentence.split()\n",
        "        for token in tokens:\n",
        "            if token not in word_to_idx:\n",
        "                word_to_idx[token] = curr_idx\n",
        "                idx_to_word[curr_idx] = token\n",
        "                curr_idx += 1\n",
        "\n",
        "    word_listing = list(idx_to_word.values())\n",
        "    return idx_to_word, word_to_idx, word_listing\n",
        "\n",
        "idx_to_word, word_to_idx, word_listing = build_vocabulary(lem_train_texts)\n",
        "#add 'UNK' token for the OOV tokens in val and test sets\n",
        "idx_to_word[1] = 'UNK'\n",
        "word_to_idx['UNK'] = 1\n",
        "word_listing.append('UNK')\n",
        "print(f\"\\n{len(word_listing)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mhy91mJK2K-V",
        "outputId": "b266c146-b05e-40ab-89f8-e556b22e2bdd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "9841\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizing the tweets\n",
        "def tokenize_and_map(text, word_to_index):\n",
        "\n",
        "    tokens = text.split()\n",
        "\n",
        "    # 4. Map tokens to indices, use 'UNK' index if not found\n",
        "    indices = [word_to_index.get(token, word_to_index['UNK']) for token in tokens]\n",
        "\n",
        "    return indices\n",
        "\n",
        "training['tokenized'] = training['lemmatized'].apply(lambda x: tokenize_and_map(x, word_to_idx))\n",
        "validation['tokenized'] = validation['lemmatized'].apply(lambda x: tokenize_and_map(x, word_to_idx))\n",
        "test['tokenized'] = test['lemmatized'].apply(lambda x: tokenize_and_map(x, word_to_idx))"
      ],
      "metadata": {
        "id": "kKWccpFdTze8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_OOV_terms(embedding_model,\n",
        "                    word_listing):\n",
        "    \"\"\"\n",
        "    Checks differences between pre-trained embedding model vocabulary\n",
        "    and dataset specific vocabulary in order to highlight out-of-vocabulary terms.\n",
        "\n",
        "    :param embedding_model: pre-trained word embedding model (gensim wrapper)\n",
        "    :param word_listing: dataset specific vocabulary (list)\n",
        "\n",
        "    :return\n",
        "        - list of OOV terms\n",
        "    \"\"\"\n",
        "    embedding_vocabulary = set(embedding_model.key_to_index.keys())\n",
        "    oov = set(word_listing).difference(embedding_vocabulary)\n",
        "    return list(oov)\n",
        "\n",
        "oov_terms = check_OOV_terms(glove, word_listing)\n",
        "oov_percentage = float(len(oov_terms)) * 100 / len(word_listing)\n",
        "print(f\"Total OOV terms: {len(oov_terms)} ({oov_percentage:.2f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "or48sukUnj0W",
        "outputId": "879c8fe6-92c8-43de-d6b4-cb83fa817f79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total OOV terms: 1865 (18.95%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "random embeddings"
      ],
      "metadata": {
        "id": "2DYRIcnHFmjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_embedding_matrix(embedding_model,\n",
        "                           embedding_dimension,\n",
        "                           word_to_idx,\n",
        "                           vocab_size,\n",
        "                           oov_terms):\n",
        "    \"\"\"\n",
        "    Builds the embedding matrix of a specific dataset given a pre-trained word embedding model\n",
        "\n",
        "    :param embedding_model: pre-trained word embedding model (gensim wrapper)\n",
        "    :param word_to_idx: vocabulary map (word -> index) (dict)\n",
        "    :param vocab_size: size of the vocabulary\n",
        "    :param oov_terms: list of OOV terms (list)\n",
        "\n",
        "    :return\n",
        "        - embedding matrix that assigns a high dimensional vector to each word in the dataset specific vocabulary (shape |V| x d)\n",
        "    \"\"\"\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dimension), dtype=np.float32)\n",
        "    for word, idx in tqdm(word_to_idx.items()):\n",
        "        try:\n",
        "            embedding_vector = embedding_model[word]\n",
        "        except (KeyError, TypeError):\n",
        "            embedding_vector = np.random.uniform(low=-0.05, high=0.05, size=embedding_dimension)\n",
        "\n",
        "        embedding_matrix[idx] = embedding_vector\n",
        "\n",
        "    return embedding_matrix"
      ],
      "metadata": {
        "id": "MpyWAwIdCRSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = build_embedding_matrix(glove, embedding_dimension, word_to_idx, len(word_to_idx)+1, oov_terms)\n",
        "np.save('/content/drive/MyDrive/assignment-2425/embed.npy', embedding_matrix)\n",
        "print(f\"\\nEmbedding matrix shape: {embedding_matrix.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kETkcEOgERV2",
        "outputId": "cc01200f-4727-47c0-bf7b-6e784d04e1b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9841/9841 [00:00<00:00, 292055.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Embedding matrix shape: (9842, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JLnuLGHGAUT"
      },
      "source": [
        "# [Task 4 - 1.0 points] Model definition\n",
        "\n",
        "You are now tasked to define your sexism classifier.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQFI9J-JOfXD"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* **Baseline**: implement a Bidirectional LSTM with a Dense layer on top.\n",
        "* You are **free** to experiment with hyper-parameters to define the baseline model.\n",
        "\n",
        "* **Model 1**: add an additional LSTM layer to the Baseline model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jALc_qYGS2E"
      },
      "source": [
        "### Token to embedding mapping\n",
        "\n",
        "You can follow two approaches for encoding tokens in your classifier.\n",
        "\n",
        "### Work directly with embeddings\n",
        "\n",
        "- Compute the embedding of each input token\n",
        "- Feed the mini-batches of shape (batch_size, # tokens, embedding_dim) to your model\n",
        "\n",
        "### Work with Embedding layer\n",
        "\n",
        "- Encode input tokens to token ids\n",
        "- Define a Embedding layer as the first layer of your model\n",
        "- Compute the embedding matrix of all known tokens (i.e., tokens in your vocabulary)\n",
        "- Initialize the Embedding layer with the computed embedding matrix\n",
        "- You are **free** to set the Embedding layer trainable or not"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Need to pad tokenized sequences to max_length, 60 is the max_length in training\n",
        "max_len = 60\n",
        "training['padded'] = pad_sequences(training['tokenized'], maxlen=max_len, padding='post').tolist()\n",
        "validation['padded'] = pad_sequences(validation['tokenized'], maxlen=max_len, padding='post').tolist()\n",
        "test['padded'] = pad_sequences(test['tokenized'], maxlen=max_len, padding='post').tolist()"
      ],
      "metadata": {
        "id": "lNqZmuybU6rJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.load('/content/drive/MyDrive/assignment-2425/embed.npy')\n",
        "vocab_size = embedding_matrix.shape[0]\n",
        "\n",
        "baseline = Sequential([\n",
        "    Embedding(\n",
        "        input_dim=vocab_size,\n",
        "        output_dim=embedding_dimension,\n",
        "        weights=[embedding_matrix],  # Load the pre-trained embeddings\n",
        "        mask_zero=True,\n",
        "        trainable=False               # Set to False to keep embeddings fixed\n",
        "    ),\n",
        "    Bidirectional(LSTM(64, return_sequences=False)),\n",
        "    Dense(1, activation='sigmoid')  # For binary classification\n",
        "])\n",
        "\n",
        "model_1 = Sequential([\n",
        "    Embedding(\n",
        "        input_dim=vocab_size,\n",
        "        output_dim=embedding_dimension,\n",
        "        weights=[embedding_matrix],  # Load the pre-trained embeddings\n",
        "        mask_zero=True,\n",
        "        trainable=False               # Set to False to keep embeddings fixed\n",
        "    ),\n",
        "    Bidirectional(LSTM(64, return_sequences=True)),\n",
        "    Bidirectional(LSTM(64)), # add another LSTM layer\n",
        "    Dense(1, activation='sigmoid')  # For binary classification\n",
        "])"
      ],
      "metadata": {
        "id": "0axd1zrQJlio"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEQTPu6eGgGv"
      },
      "source": [
        "### Padding\n",
        "\n",
        "Pay attention to padding tokens!\n",
        "\n",
        "Your model **should not** be penalized on those tokens.\n",
        "\n",
        "#### How to?\n",
        "\n",
        "There are two main ways.\n",
        "\n",
        "However, their implementation depends on the neural library you are using.\n",
        "\n",
        "- Embedding layer\n",
        "- Custom loss to compute average cross-entropy on non-padding tokens only\n",
        "\n",
        "**Note**: This is a **recommendation**, but we **do not penalize** for missing workarounds."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFjBgdiRG3wD"
      },
      "source": [
        "# [Task 5 - 1.0 points] Training and Evaluation\n",
        "\n",
        "You are now tasked to train and evaluate the Baseline and Model 1.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWPK4umGOjtT"
      },
      "source": [
        "\n",
        "### Instructions\n",
        "\n",
        "* Train **all** models on the train set.\n",
        "* Evaluate **all** models on the validation set.\n",
        "* Compute metrics on the validation set.\n",
        "* Pick **at least** three seeds for robust estimation.\n",
        "* Pick the **best** performing model according to the observed validation set performance.\n",
        "* Evaluate your models using macro F1-score."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.array(training['padded'].to_list()).astype('float32')\n",
        "y_train = training['hard_label_task1'].values.astype('float32')\n",
        "\n",
        "x_val = np.array(validation['padded'].to_list()).astype('float32')\n",
        "y_val = validation['hard_label_task1'].values.astype('float32')"
      ],
      "metadata": {
        "id": "q-wOJRlkzjud"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_values = [1, 42 , 7]\n",
        "\n",
        "for seed in seed_values:\n",
        "  print(f\"model_{seed}\")\n",
        "  tf.random.set_seed(seed)\n",
        "\n",
        "  optim = tf.keras.optimizers.AdamW(learning_rate=0.001)\n",
        "  reduce_LR = tf.keras.callbacks.ReduceLROnPlateau(patience=4)\n",
        "  checkpoint_baseline = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/assignment-2425/baseline_trainable_{seed}.weights.h5', save_weights_only=True, save_best_only=True)\n",
        "\n",
        "  baseline = Sequential([\n",
        "    Embedding(\n",
        "        input_dim=vocab_size,\n",
        "        output_dim=embedding_dimension,\n",
        "        weights=[embedding_matrix],  # Load the pre-trained embeddings\n",
        "        mask_zero=True,\n",
        "        trainable=True               # Set to False to keep embeddings fixed\n",
        "    ),\n",
        "    Bidirectional(LSTM(64, return_sequences=False)),\n",
        "    Dense(1, activation='sigmoid')  # For binary classification\n",
        "])\n",
        "\n",
        "  baseline.compile(\n",
        "      loss='binary_crossentropy',\n",
        "      optimizer=optim,\n",
        "      metrics=['accuracy']\n",
        "  )\n",
        "\n",
        "  history_baseline = baseline.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(x_val, y_val),\n",
        "    callbacks=[reduce_LR, checkpoint_baseline]\n",
        "  )\n",
        "\n",
        "  baseline.load_weights(f'/content/drive/MyDrive/assignment-2425/baseline_trainable_{seed}.weights.h5')\n",
        "  y_pred = baseline.predict(x_val)\n",
        "  f1 = tf.keras.metrics.F1Score(threshold=0.5, average='macro')\n",
        "  f1.update_state(np.expand_dims(y_val,1).astype('int32'), y_pred)\n",
        "  print(f1.result())"
      ],
      "metadata": {
        "id": "yyRDspfAos_I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b669d725-eafe-452e-cde5-b4903f57cd4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_1\n",
            "Epoch 1/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.6160 - loss: 0.6470 - val_accuracy: 0.6456 - val_loss: 0.7049 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7367 - loss: 0.5331 - val_accuracy: 0.7342 - val_loss: 0.7174 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8140 - loss: 0.4255 - val_accuracy: 0.7658 - val_loss: 0.5174 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8698 - loss: 0.3092 - val_accuracy: 0.7722 - val_loss: 0.5040 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9160 - loss: 0.2141 - val_accuracy: 0.8038 - val_loss: 0.5691 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9557 - loss: 0.1209 - val_accuracy: 0.7722 - val_loss: 0.5630 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9763 - loss: 0.0690 - val_accuracy: 0.7975 - val_loss: 0.6289 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9841 - loss: 0.0488 - val_accuracy: 0.7975 - val_loss: 0.9629 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9911 - loss: 0.0346 - val_accuracy: 0.8228 - val_loss: 0.9437 - learning_rate: 1.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9937 - loss: 0.0234 - val_accuracy: 0.8228 - val_loss: 0.9649 - learning_rate: 1.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9953 - loss: 0.0198 - val_accuracy: 0.8165 - val_loss: 0.9807 - learning_rate: 1.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9993 - loss: 0.0171 - val_accuracy: 0.8101 - val_loss: 0.9983 - learning_rate: 1.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0153 - val_accuracy: 0.8101 - val_loss: 0.9911 - learning_rate: 1.0000e-05\n",
            "Epoch 14/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0148 - val_accuracy: 0.8165 - val_loss: 0.9871 - learning_rate: 1.0000e-05\n",
            "Epoch 15/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9995 - loss: 0.0144 - val_accuracy: 0.8165 - val_loss: 0.9857 - learning_rate: 1.0000e-05\n",
            "Epoch 16/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9998 - loss: 0.0142 - val_accuracy: 0.8165 - val_loss: 0.9858 - learning_rate: 1.0000e-05\n",
            "Epoch 17/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 0.0139 - val_accuracy: 0.8165 - val_loss: 0.9859 - learning_rate: 1.0000e-06\n",
            "Epoch 18/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9998 - loss: 0.0139 - val_accuracy: 0.8165 - val_loss: 0.9859 - learning_rate: 1.0000e-06\n",
            "Epoch 19/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9998 - loss: 0.0139 - val_accuracy: 0.8165 - val_loss: 0.9859 - learning_rate: 1.0000e-06\n",
            "Epoch 20/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 0.0139 - val_accuracy: 0.8165 - val_loss: 0.9860 - learning_rate: 1.0000e-06\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "tf.Tensor(0.7428571, shape=(), dtype=float32)\n",
            "model_42\n",
            "Epoch 1/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.6275 - loss: 0.6469 - val_accuracy: 0.7025 - val_loss: 0.6311 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7652 - loss: 0.4916 - val_accuracy: 0.7468 - val_loss: 0.5871 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8387 - loss: 0.3759 - val_accuracy: 0.7785 - val_loss: 0.5248 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8912 - loss: 0.2656 - val_accuracy: 0.7785 - val_loss: 0.5913 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.9421 - loss: 0.1636 - val_accuracy: 0.7722 - val_loss: 0.8334 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9641 - loss: 0.0997 - val_accuracy: 0.7848 - val_loss: 0.5023 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9715 - loss: 0.0827 - val_accuracy: 0.7848 - val_loss: 0.7680 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9917 - loss: 0.0421 - val_accuracy: 0.7911 - val_loss: 0.7643 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9963 - loss: 0.0201 - val_accuracy: 0.8038 - val_loss: 0.7716 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9977 - loss: 0.0117 - val_accuracy: 0.8101 - val_loss: 0.8938 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 0.0070 - val_accuracy: 0.7911 - val_loss: 0.9653 - learning_rate: 1.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9997 - loss: 0.0054 - val_accuracy: 0.7911 - val_loss: 0.9884 - learning_rate: 1.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9997 - loss: 0.0051 - val_accuracy: 0.7975 - val_loss: 1.0035 - learning_rate: 1.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9997 - loss: 0.0048 - val_accuracy: 0.8038 - val_loss: 1.0164 - learning_rate: 1.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9999 - loss: 0.0045 - val_accuracy: 0.8038 - val_loss: 1.0173 - learning_rate: 1.0000e-05\n",
            "Epoch 16/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9999 - loss: 0.0045 - val_accuracy: 0.8038 - val_loss: 1.0185 - learning_rate: 1.0000e-05\n",
            "Epoch 17/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9999 - loss: 0.0044 - val_accuracy: 0.8038 - val_loss: 1.0199 - learning_rate: 1.0000e-05\n",
            "Epoch 18/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9999 - loss: 0.0044 - val_accuracy: 0.8038 - val_loss: 1.0213 - learning_rate: 1.0000e-05\n",
            "Epoch 19/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 0.0043 - val_accuracy: 0.8038 - val_loss: 1.0215 - learning_rate: 1.0000e-06\n",
            "Epoch 20/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 0.0043 - val_accuracy: 0.8038 - val_loss: 1.0217 - learning_rate: 1.0000e-06\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "tf.Tensor(0.72580636, shape=(), dtype=float32)\n",
            "model_7\n",
            "Epoch 1/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.6159 - loss: 0.6685 - val_accuracy: 0.6709 - val_loss: 0.6018 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7500 - loss: 0.5229 - val_accuracy: 0.7468 - val_loss: 0.4998 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8320 - loss: 0.3875 - val_accuracy: 0.7848 - val_loss: 0.4417 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8717 - loss: 0.3027 - val_accuracy: 0.7785 - val_loss: 0.4924 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9323 - loss: 0.1772 - val_accuracy: 0.8038 - val_loss: 0.5886 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9678 - loss: 0.0957 - val_accuracy: 0.7785 - val_loss: 0.6929 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9823 - loss: 0.0605 - val_accuracy: 0.7785 - val_loss: 0.5813 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9881 - loss: 0.0434 - val_accuracy: 0.7722 - val_loss: 0.6627 - learning_rate: 1.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9883 - loss: 0.0353 - val_accuracy: 0.7722 - val_loss: 0.7169 - learning_rate: 1.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9915 - loss: 0.0303 - val_accuracy: 0.7722 - val_loss: 0.7547 - learning_rate: 1.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9922 - loss: 0.0262 - val_accuracy: 0.7722 - val_loss: 0.7900 - learning_rate: 1.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.9948 - loss: 0.0233 - val_accuracy: 0.7848 - val_loss: 0.7711 - learning_rate: 1.0000e-05\n",
            "Epoch 13/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9926 - loss: 0.0225 - val_accuracy: 0.7848 - val_loss: 0.7656 - learning_rate: 1.0000e-05\n",
            "Epoch 14/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9926 - loss: 0.0221 - val_accuracy: 0.7848 - val_loss: 0.7660 - learning_rate: 1.0000e-05\n",
            "Epoch 15/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9926 - loss: 0.0217 - val_accuracy: 0.7848 - val_loss: 0.7689 - learning_rate: 1.0000e-05\n",
            "Epoch 16/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9926 - loss: 0.0214 - val_accuracy: 0.7848 - val_loss: 0.7691 - learning_rate: 1.0000e-06\n",
            "Epoch 17/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9926 - loss: 0.0214 - val_accuracy: 0.7848 - val_loss: 0.7694 - learning_rate: 1.0000e-06\n",
            "Epoch 18/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9926 - loss: 0.0213 - val_accuracy: 0.7848 - val_loss: 0.7697 - learning_rate: 1.0000e-06\n",
            "Epoch 19/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9926 - loss: 0.0213 - val_accuracy: 0.7848 - val_loss: 0.7700 - learning_rate: 1.0000e-06\n",
            "Epoch 20/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9926 - loss: 0.0213 - val_accuracy: 0.7848 - val_loss: 0.7700 - learning_rate: 1.0000e-07\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step\n",
            "tf.Tensor(0.73015875, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Embedding(training=False) F1-scores = (0.7633587, 0.76422757, 0.779661)\n",
        "#### Embedding(trainable=True) F1-score = (0.7428571, 0.72580636, 0.73015875)"
      ],
      "metadata": {
        "id": "zPjwnDSBp1hH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed_values = [1, 42 , 7]\n",
        "\n",
        "for seed in seed_values:\n",
        "  print(f\"model_{seed}\")\n",
        "  tf.random.set_seed(seed)\n",
        "\n",
        "  model_1 = Sequential([\n",
        "    Embedding(\n",
        "        input_dim=vocab_size,\n",
        "        output_dim=embedding_dimension,\n",
        "        weights=[embedding_matrix],  # Load the pre-trained embeddings\n",
        "        mask_zero=True,\n",
        "        trainable=True               # Set to False to keep embeddings fixed\n",
        "    ),\n",
        "    Bidirectional(LSTM(64, return_sequences=True)),\n",
        "    Bidirectional(LSTM(64)), # add another LSTM layer\n",
        "    Dense(1, activation='sigmoid')  # For binary classification\n",
        "  ])\n",
        "\n",
        "  optim = tf.keras.optimizers.AdamW(learning_rate=0.001)\n",
        "  reduce_LR = tf.keras.callbacks.ReduceLROnPlateau(patience=4)\n",
        "  checkpoint_model1 = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/assignment-2425/model1_trainable_{seed}.weights.h5', save_weights_only=True, save_best_only=True)\n",
        "\n",
        "  model_1.compile(\n",
        "      loss='binary_crossentropy',\n",
        "      optimizer=optim,\n",
        "      metrics=['accuracy']\n",
        "  )\n",
        "\n",
        "  history_model1 = model_1.fit(\n",
        "      x_train,\n",
        "      y_train,\n",
        "      epochs=30,\n",
        "      batch_size=32,\n",
        "      validation_data=(x_val, y_val),\n",
        "      callbacks=[reduce_LR, checkpoint_model1]\n",
        "  )\n",
        "\n",
        "  model_1.load_weights(f'/content/drive/MyDrive/assignment-2425/model1_trainable_{seed}.weights.h5')\n",
        "  y_pred = model_1.predict(x_val)\n",
        "  f1 = tf.keras.metrics.F1Score(threshold=0.5, average='macro')\n",
        "  f1.update_state(np.expand_dims(y_val,1).astype('int32'), y_pred)\n",
        "  print(f1.result())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNI_TmD6rPbk",
        "outputId": "7f35b8ec-fb43-4f68-95d0-81378f31d33e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_1\n",
            "Epoch 1/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.6153 - loss: 0.6391 - val_accuracy: 0.7089 - val_loss: 0.6802 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.7715 - loss: 0.4936 - val_accuracy: 0.7532 - val_loss: 0.6137 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8398 - loss: 0.3706 - val_accuracy: 0.7785 - val_loss: 0.6186 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.8967 - loss: 0.2592 - val_accuracy: 0.8101 - val_loss: 0.4574 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9361 - loss: 0.1666 - val_accuracy: 0.7342 - val_loss: 0.6106 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9554 - loss: 0.1174 - val_accuracy: 0.8038 - val_loss: 0.6364 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.9740 - loss: 0.0730 - val_accuracy: 0.8165 - val_loss: 0.7095 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9900 - loss: 0.0277 - val_accuracy: 0.8165 - val_loss: 1.0369 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9948 - loss: 0.0195 - val_accuracy: 0.8165 - val_loss: 0.9797 - learning_rate: 1.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.9963 - loss: 0.0141 - val_accuracy: 0.8165 - val_loss: 1.0144 - learning_rate: 1.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9963 - loss: 0.0126 - val_accuracy: 0.8101 - val_loss: 1.0494 - learning_rate: 1.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9963 - loss: 0.0115 - val_accuracy: 0.8101 - val_loss: 1.0830 - learning_rate: 1.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9973 - loss: 0.0105 - val_accuracy: 0.8101 - val_loss: 1.0865 - learning_rate: 1.0000e-05\n",
            "Epoch 14/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9973 - loss: 0.0104 - val_accuracy: 0.8101 - val_loss: 1.0902 - learning_rate: 1.0000e-05\n",
            "Epoch 15/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9973 - loss: 0.0103 - val_accuracy: 0.8101 - val_loss: 1.0943 - learning_rate: 1.0000e-05\n",
            "Epoch 16/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9973 - loss: 0.0102 - val_accuracy: 0.8101 - val_loss: 1.0987 - learning_rate: 1.0000e-05\n",
            "Epoch 17/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9973 - loss: 0.0100 - val_accuracy: 0.8101 - val_loss: 1.0992 - learning_rate: 1.0000e-06\n",
            "Epoch 18/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9973 - loss: 0.0100 - val_accuracy: 0.8101 - val_loss: 1.0997 - learning_rate: 1.0000e-06\n",
            "Epoch 19/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9973 - loss: 0.0100 - val_accuracy: 0.8101 - val_loss: 1.1002 - learning_rate: 1.0000e-06\n",
            "Epoch 20/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9973 - loss: 0.0100 - val_accuracy: 0.8101 - val_loss: 1.1007 - learning_rate: 1.0000e-06\n",
            "Epoch 21/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9973 - loss: 0.0100 - val_accuracy: 0.8101 - val_loss: 1.1008 - learning_rate: 1.0000e-07\n",
            "Epoch 22/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.9973 - loss: 0.0100 - val_accuracy: 0.8101 - val_loss: 1.1008 - learning_rate: 1.0000e-07\n",
            "Epoch 23/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9973 - loss: 0.0100 - val_accuracy: 0.8101 - val_loss: 1.1009 - learning_rate: 1.0000e-07\n",
            "Epoch 24/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.9973 - loss: 0.0100 - val_accuracy: 0.8101 - val_loss: 1.1010 - learning_rate: 1.0000e-07\n",
            "Epoch 25/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9973 - loss: 0.0100 - val_accuracy: 0.8101 - val_loss: 1.1010 - learning_rate: 1.0000e-08\n",
            "Epoch 26/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.9973 - loss: 0.0100 - val_accuracy: 0.8101 - val_loss: 1.1010 - learning_rate: 1.0000e-08\n",
            "Epoch 27/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9973 - loss: 0.0100 - val_accuracy: 0.8101 - val_loss: 1.1010 - learning_rate: 1.0000e-08\n",
            "Epoch 28/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9973 - loss: 0.0100 - val_accuracy: 0.8101 - val_loss: 1.1010 - learning_rate: 1.0000e-08\n",
            "Epoch 29/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9973 - loss: 0.0100 - val_accuracy: 0.8101 - val_loss: 1.1010 - learning_rate: 1.0000e-09\n",
            "Epoch 30/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.9973 - loss: 0.0100 - val_accuracy: 0.8101 - val_loss: 1.1010 - learning_rate: 1.0000e-09\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step\n",
            "tf.Tensor(0.76562494, shape=(), dtype=float32)\n",
            "model_42\n",
            "Epoch 1/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - accuracy: 0.6206 - loss: 0.6343 - val_accuracy: 0.7152 - val_loss: 0.6105 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.7689 - loss: 0.4775 - val_accuracy: 0.7785 - val_loss: 0.5467 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8444 - loss: 0.3583 - val_accuracy: 0.7468 - val_loss: 0.8170 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8865 - loss: 0.2686 - val_accuracy: 0.8165 - val_loss: 0.4825 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.9396 - loss: 0.1461 - val_accuracy: 0.8165 - val_loss: 0.5236 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9621 - loss: 0.0973 - val_accuracy: 0.7911 - val_loss: 0.7546 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9760 - loss: 0.0617 - val_accuracy: 0.7911 - val_loss: 0.7990 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9779 - loss: 0.0580 - val_accuracy: 0.7722 - val_loss: 0.5592 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.9938 - loss: 0.0278 - val_accuracy: 0.8165 - val_loss: 0.6583 - learning_rate: 1.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.9962 - loss: 0.0181 - val_accuracy: 0.8101 - val_loss: 0.6989 - learning_rate: 1.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.9973 - loss: 0.0157 - val_accuracy: 0.8101 - val_loss: 0.7326 - learning_rate: 1.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.9978 - loss: 0.0139 - val_accuracy: 0.8101 - val_loss: 0.7625 - learning_rate: 1.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9980 - loss: 0.0126 - val_accuracy: 0.8101 - val_loss: 0.7648 - learning_rate: 1.0000e-05\n",
            "Epoch 14/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9980 - loss: 0.0125 - val_accuracy: 0.8101 - val_loss: 0.7674 - learning_rate: 1.0000e-05\n",
            "Epoch 15/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9980 - loss: 0.0123 - val_accuracy: 0.8101 - val_loss: 0.7704 - learning_rate: 1.0000e-05\n",
            "Epoch 16/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9980 - loss: 0.0122 - val_accuracy: 0.8101 - val_loss: 0.7735 - learning_rate: 1.0000e-05\n",
            "Epoch 17/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.9980 - loss: 0.0121 - val_accuracy: 0.8101 - val_loss: 0.7738 - learning_rate: 1.0000e-06\n",
            "Epoch 18/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9980 - loss: 0.0120 - val_accuracy: 0.8101 - val_loss: 0.7742 - learning_rate: 1.0000e-06\n",
            "Epoch 19/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9980 - loss: 0.0120 - val_accuracy: 0.8101 - val_loss: 0.7746 - learning_rate: 1.0000e-06\n",
            "Epoch 20/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9980 - loss: 0.0120 - val_accuracy: 0.8101 - val_loss: 0.7749 - learning_rate: 1.0000e-06\n",
            "Epoch 21/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.9980 - loss: 0.0120 - val_accuracy: 0.8101 - val_loss: 0.7750 - learning_rate: 1.0000e-07\n",
            "Epoch 22/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.9980 - loss: 0.0120 - val_accuracy: 0.8101 - val_loss: 0.7750 - learning_rate: 1.0000e-07\n",
            "Epoch 23/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9980 - loss: 0.0120 - val_accuracy: 0.8101 - val_loss: 0.7751 - learning_rate: 1.0000e-07\n",
            "Epoch 24/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9980 - loss: 0.0120 - val_accuracy: 0.8101 - val_loss: 0.7751 - learning_rate: 1.0000e-07\n",
            "Epoch 25/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9980 - loss: 0.0120 - val_accuracy: 0.8101 - val_loss: 0.7751 - learning_rate: 1.0000e-08\n",
            "Epoch 26/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.9980 - loss: 0.0120 - val_accuracy: 0.8101 - val_loss: 0.7751 - learning_rate: 1.0000e-08\n",
            "Epoch 27/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9980 - loss: 0.0120 - val_accuracy: 0.8101 - val_loss: 0.7751 - learning_rate: 1.0000e-08\n",
            "Epoch 28/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.9980 - loss: 0.0120 - val_accuracy: 0.8101 - val_loss: 0.7751 - learning_rate: 1.0000e-08\n",
            "Epoch 29/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9980 - loss: 0.0120 - val_accuracy: 0.8101 - val_loss: 0.7751 - learning_rate: 1.0000e-09\n",
            "Epoch 30/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9980 - loss: 0.0120 - val_accuracy: 0.8101 - val_loss: 0.7751 - learning_rate: 1.0000e-09\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step\n",
            "tf.Tensor(0.76422757, shape=(), dtype=float32)\n",
            "model_7\n",
            "Epoch 1/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.5957 - loss: 0.6682 - val_accuracy: 0.6835 - val_loss: 0.5697 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.7425 - loss: 0.5089 - val_accuracy: 0.7658 - val_loss: 0.4829 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8393 - loss: 0.3635 - val_accuracy: 0.8165 - val_loss: 0.4915 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.9009 - loss: 0.2421 - val_accuracy: 0.8101 - val_loss: 0.5332 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9514 - loss: 0.1346 - val_accuracy: 0.8038 - val_loss: 0.5405 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9692 - loss: 0.0865 - val_accuracy: 0.8038 - val_loss: 0.6311 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9868 - loss: 0.0468 - val_accuracy: 0.8038 - val_loss: 0.7306 - learning_rate: 1.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.9897 - loss: 0.0339 - val_accuracy: 0.8228 - val_loss: 0.7509 - learning_rate: 1.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.9922 - loss: 0.0284 - val_accuracy: 0.8165 - val_loss: 0.7765 - learning_rate: 1.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.9946 - loss: 0.0240 - val_accuracy: 0.8101 - val_loss: 0.8002 - learning_rate: 1.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9952 - loss: 0.0203 - val_accuracy: 0.8101 - val_loss: 0.7996 - learning_rate: 1.0000e-05\n",
            "Epoch 12/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.9954 - loss: 0.0199 - val_accuracy: 0.8101 - val_loss: 0.8002 - learning_rate: 1.0000e-05\n",
            "Epoch 13/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9954 - loss: 0.0195 - val_accuracy: 0.8101 - val_loss: 0.8023 - learning_rate: 1.0000e-05\n",
            "Epoch 14/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9954 - loss: 0.0192 - val_accuracy: 0.8101 - val_loss: 0.8051 - learning_rate: 1.0000e-05\n",
            "Epoch 15/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9954 - loss: 0.0188 - val_accuracy: 0.8101 - val_loss: 0.8055 - learning_rate: 1.0000e-06\n",
            "Epoch 16/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.9956 - loss: 0.0188 - val_accuracy: 0.8101 - val_loss: 0.8058 - learning_rate: 1.0000e-06\n",
            "Epoch 17/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.9956 - loss: 0.0187 - val_accuracy: 0.8101 - val_loss: 0.8062 - learning_rate: 1.0000e-06\n",
            "Epoch 18/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.9956 - loss: 0.0187 - val_accuracy: 0.8101 - val_loss: 0.8066 - learning_rate: 1.0000e-06\n",
            "Epoch 19/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.9956 - loss: 0.0187 - val_accuracy: 0.8101 - val_loss: 0.8066 - learning_rate: 1.0000e-07\n",
            "Epoch 20/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9956 - loss: 0.0187 - val_accuracy: 0.8101 - val_loss: 0.8066 - learning_rate: 1.0000e-07\n",
            "Epoch 21/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9956 - loss: 0.0187 - val_accuracy: 0.8101 - val_loss: 0.8067 - learning_rate: 1.0000e-07\n",
            "Epoch 22/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9956 - loss: 0.0187 - val_accuracy: 0.8101 - val_loss: 0.8067 - learning_rate: 1.0000e-07\n",
            "Epoch 23/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.9956 - loss: 0.0186 - val_accuracy: 0.8101 - val_loss: 0.8067 - learning_rate: 1.0000e-08\n",
            "Epoch 24/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9956 - loss: 0.0186 - val_accuracy: 0.8101 - val_loss: 0.8067 - learning_rate: 1.0000e-08\n",
            "Epoch 25/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9956 - loss: 0.0186 - val_accuracy: 0.8101 - val_loss: 0.8067 - learning_rate: 1.0000e-08\n",
            "Epoch 26/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.9956 - loss: 0.0186 - val_accuracy: 0.8101 - val_loss: 0.8067 - learning_rate: 1.0000e-08\n",
            "Epoch 27/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9956 - loss: 0.0186 - val_accuracy: 0.8101 - val_loss: 0.8067 - learning_rate: 1.0000e-09\n",
            "Epoch 28/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9956 - loss: 0.0186 - val_accuracy: 0.8101 - val_loss: 0.8067 - learning_rate: 1.0000e-09\n",
            "Epoch 29/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.9956 - loss: 0.0186 - val_accuracy: 0.8101 - val_loss: 0.8067 - learning_rate: 1.0000e-09\n",
            "Epoch 30/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.9956 - loss: 0.0186 - val_accuracy: 0.8101 - val_loss: 0.8067 - learning_rate: 1.0000e-09\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step\n",
            "tf.Tensor(0.6942148, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Embedding(training=False) F1-scores = (0.74999994, 0.73684204, 0.76033056)\n",
        "#### Embedding(trainable=True) F1-score = (0.76562494, 0.76422757, 0.6942148)"
      ],
      "metadata": {
        "id": "ki5k5EcksHIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = Sequential([\n",
        "    Embedding(\n",
        "        input_dim=vocab_size,\n",
        "        output_dim=embedding_dimension,\n",
        "        weights=[embedding_matrix],  # Load the pre-trained embeddings\n",
        "        mask_zero=True,\n",
        "        trainable=False               # Set to False to keep embeddings fixed\n",
        "    ),\n",
        "    Bidirectional(LSTM(64, return_sequences=True)),\n",
        "    Bidirectional(LSTM(64)), # add another LSTM layer\n",
        "    Dense(1, activation='sigmoid')  # For binary classification\n",
        "])"
      ],
      "metadata": {
        "id": "wgV1-gL_sIQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optim = tf.keras.optimizers.AdamW(learning_rate=0.001)\n",
        "reduce_LR = tf.keras.callbacks.ReduceLROnPlateau(patience=4)\n",
        "checkpoint_model1 = tf.keras.callbacks.ModelCheckpoint('/content/drive/MyDrive/assignment-2425/model1.weights.h5', save_weights_only=True, save_best_only=True)\n",
        "\n",
        "\n",
        "model_1.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=optim,\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "KT-PcbhgoIF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_model1 = model_1.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    validation_data=(x_val, y_val),\n",
        "    callbacks=[reduce_LR, checkpoint_model1]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePRsKk6FmX3E",
        "outputId": "dd37772c-2a30-4f30-983e-4b8ff9742ca7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.5997 - loss: 0.6634 - val_accuracy: 0.7025 - val_loss: 0.5419 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.7207 - loss: 0.5521 - val_accuracy: 0.7468 - val_loss: 0.5222 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7541 - loss: 0.5077 - val_accuracy: 0.7595 - val_loss: 0.4868 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8000 - loss: 0.4448 - val_accuracy: 0.7658 - val_loss: 0.4822 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8198 - loss: 0.4096 - val_accuracy: 0.7848 - val_loss: 0.4772 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.8372 - loss: 0.3820 - val_accuracy: 0.8101 - val_loss: 0.4415 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8563 - loss: 0.3310 - val_accuracy: 0.7975 - val_loss: 0.5320 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8771 - loss: 0.2851 - val_accuracy: 0.7975 - val_loss: 0.5084 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9223 - loss: 0.2093 - val_accuracy: 0.7722 - val_loss: 0.6342 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.9302 - loss: 0.1848 - val_accuracy: 0.7658 - val_loss: 0.7452 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9495 - loss: 0.1458 - val_accuracy: 0.7975 - val_loss: 0.6506 - learning_rate: 1.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9780 - loss: 0.0827 - val_accuracy: 0.8101 - val_loss: 0.7013 - learning_rate: 1.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9737 - loss: 0.0801 - val_accuracy: 0.8038 - val_loss: 0.7498 - learning_rate: 1.0000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9860 - loss: 0.0537 - val_accuracy: 0.7975 - val_loss: 0.7605 - learning_rate: 1.0000e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9892 - loss: 0.0515 - val_accuracy: 0.7975 - val_loss: 0.7755 - learning_rate: 1.0000e-05\n",
            "Epoch 16/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9879 - loss: 0.0508 - val_accuracy: 0.7975 - val_loss: 0.7834 - learning_rate: 1.0000e-05\n",
            "Epoch 17/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9881 - loss: 0.0506 - val_accuracy: 0.7975 - val_loss: 0.7919 - learning_rate: 1.0000e-05\n",
            "Epoch 18/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.9871 - loss: 0.0500 - val_accuracy: 0.7975 - val_loss: 0.7949 - learning_rate: 1.0000e-05\n",
            "Epoch 19/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9867 - loss: 0.0516 - val_accuracy: 0.7975 - val_loss: 0.7953 - learning_rate: 1.0000e-06\n",
            "Epoch 20/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9899 - loss: 0.0500 - val_accuracy: 0.7975 - val_loss: 0.7962 - learning_rate: 1.0000e-06\n",
            "Epoch 21/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9874 - loss: 0.0532 - val_accuracy: 0.7975 - val_loss: 0.7964 - learning_rate: 1.0000e-06\n",
            "Epoch 22/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9865 - loss: 0.0525 - val_accuracy: 0.7975 - val_loss: 0.7970 - learning_rate: 1.0000e-06\n",
            "Epoch 23/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9888 - loss: 0.0493 - val_accuracy: 0.7975 - val_loss: 0.7971 - learning_rate: 1.0000e-07\n",
            "Epoch 24/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9894 - loss: 0.0485 - val_accuracy: 0.7975 - val_loss: 0.7971 - learning_rate: 1.0000e-07\n",
            "Epoch 25/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9889 - loss: 0.0502 - val_accuracy: 0.7975 - val_loss: 0.7971 - learning_rate: 1.0000e-07\n",
            "Epoch 26/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9877 - loss: 0.0510 - val_accuracy: 0.7975 - val_loss: 0.7972 - learning_rate: 1.0000e-07\n",
            "Epoch 27/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9894 - loss: 0.0492 - val_accuracy: 0.7975 - val_loss: 0.7972 - learning_rate: 1.0000e-08\n",
            "Epoch 28/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9865 - loss: 0.0498 - val_accuracy: 0.7975 - val_loss: 0.7972 - learning_rate: 1.0000e-08\n",
            "Epoch 29/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9879 - loss: 0.0520 - val_accuracy: 0.7975 - val_loss: 0.7972 - learning_rate: 1.0000e-08\n",
            "Epoch 30/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9903 - loss: 0.0466 - val_accuracy: 0.7975 - val_loss: 0.7972 - learning_rate: 1.0000e-08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline.load_weights('/content/drive/MyDrive/assignment-2425/baseline.weights.h5')\n",
        "print(baseline.evaluate(x_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CB3JVYqg0KHz",
        "outputId": "9ae071b1-77b0-4474-d96f-8f6b2c30e159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7855 - loss: 0.4468 \n",
            "[0.44200608134269714, 0.7848101258277893]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.load_weights('/content/drive/MyDrive/assignment-2425/model1.weights.h5')\n",
        "print(model_1.evaluate(x_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HIxtXGJscw6",
        "outputId": "11993069-60b3-4a26-dee9-30975f144305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8026 - loss: 0.4434\n",
            "[0.4414699971675873, 0.8101266026496887]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSy9sPwYHUoD"
      },
      "source": [
        "# [Task 6 - 1.0 points] Transformers\n",
        "\n",
        "In this section, you will use a transformer model specifically trained for hate speech detection, namely [Twitter-roBERTa-base for Hate Speech Detection](https://huggingface.co/cardiffnlp/twitter-roberta-base-hate).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "njQmpZzH_HhP"
      },
      "source": [
        "### Relevant Material\n",
        "- Tutorial 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "uZTi5m0L_HhQ"
      },
      "source": [
        "### Instructions\n",
        "1. **Load the Tokenizer and Model**\n",
        "\n",
        "2. **Preprocess the Dataset**:\n",
        "   You will need to preprocess your dataset to prepare it for input into the model. Tokenize your text data using the appropriate tokenizer and ensure it is formatted correctly.\n",
        "\n",
        "   **Note**: You have to use the plain text of the dataset and not the version that you tokenized before, as you need to tokenize the cleaned text obtained after the initial cleaning process.\n",
        "\n",
        "3. **Train the Model**:\n",
        "   Use the `Trainer` to train the model on your training data.\n",
        "\n",
        "4. **Evaluate the Model on the Test Set** using F1-macro."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from transformers import DataCollatorWithPadding\n",
        "import torch\n",
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "MGUJCJunGMnI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "b97c1341-30ae-42e9-b94b-682647554841"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-89228e4d5b6f>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataCollatorWithPadding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1780\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1782\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1783\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1784\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1779\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPlaceholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1781\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1782\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1791\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1793\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1794\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1795\u001b[0m             raise RuntimeError(\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m )\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_decoder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEncoderDecoderConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mauto_factory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_LazyAutoMapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m from .configuration_auto import (\n\u001b[1;32m     40\u001b[0m     \u001b[0mCONFIG_MAPPING_NAMES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mgeneration\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenerationMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1779\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPlaceholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1781\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1782\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1791\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1793\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1794\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1795\u001b[0m             raise RuntimeError(\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfsdp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_fsdp_managed_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling_outputs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCausalLMOutputWithPast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeq2SeqLMOutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0misin_mps_friendly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenization_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExtensionsTrie\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m from ..utils import (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_torch_greater_or_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"2.5\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_torch_distributed_available\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReplicate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     from torch.distributed.tensor.parallel import (\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mColwiseParallel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mRowwiseParallel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/distributed/tensor/parallel/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Copyright (c) Meta Platforms, Inc. and affiliates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparallelize_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mloss_parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m from torch.distributed.tensor.parallel.style import (\n\u001b[1;32m      5\u001b[0m     \u001b[0mColwiseParallel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/distributed/tensor/parallel/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mTensorParallelRNGTracker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m )\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_validate_tp_mesh_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParallelStyle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/distributed/tensor/parallel/_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternal_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_compiling\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mis_torchdynamo_compiling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume_execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlist_backends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallback_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGlobalStateGuard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_compile_pg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCompileTimeInstructionCounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompile_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstructured\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inductor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minductor_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_shapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pytree\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpytree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdataclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrozen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mConstraint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m     \u001b[0mwarn_only\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/dataclasses.py\u001b[0m in \u001b[0;36mwrap\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m         return _process_class(cls, init, repr, eq, order, unsafe_hash,\n\u001b[0m\u001b[1;32m   1176\u001b[0m                               frozen, match_args, kw_only, slots)\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/dataclasses.py\u001b[0m in \u001b[0;36m_process_class\u001b[0;34m(cls, init, repr, eq, order, unsafe_hash, frozen, match_args, kw_only, slots)\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfrozen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1075\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_frozen_get_del_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1076\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_set_new_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m                 raise TypeError(f'Cannot overwrite attribute {fn.__name__} '\n",
            "\u001b[0;32m/usr/lib/python3.10/dataclasses.py\u001b[0m in \u001b[0;36m_frozen_get_del_attr\u001b[0;34m(cls, fields, globals)\u001b[0m\n\u001b[1;32m    604\u001b[0m         \u001b[0;31m# Special case for the zero-length tuple.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0mfields_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'()'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m     return (_create_fn('__setattr__',\n\u001b[0m\u001b[1;32m    607\u001b[0m                       \u001b[0;34m(\u001b[0m\u001b[0;34m'self'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'value'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m                       (f'if type(self) is cls or name in {fields_str}:',\n",
            "\u001b[0;32m/usr/lib/python3.10/dataclasses.py\u001b[0m in \u001b[0;36m_create_fn\u001b[0;34m(name, args, body, globals, locals, return_type)\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"def __create_fn__({local_vars}):\\n{txt}\\n return {name}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0mns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m     \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__create_fn__'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts = training['lemmatized'].tolist()\n",
        "val_texts = validation['lemmatized'].tolist()\n",
        "test_texts = test['lemmatized'].tolist()\n",
        "\n",
        "train_labels = training['hard_label_task1'].tolist()\n",
        "val_labels = validation['hard_label_task1'].tolist()\n",
        "test_labels = test['hard_label_task1'].tolist()"
      ],
      "metadata": {
        "id": "i5OpB4KrG8od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"cardiffnlp/twitter-roberta-base-hate\"  # Replace with the correct model name\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
      ],
      "metadata": {
        "id": "JyYID4LQHMdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the training and testing data\n",
        "train_encodings = tokenizer(train_texts)\n",
        "val_encodings = tokenizer(val_texts)\n",
        "test_encodings = tokenizer(test_texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qq0VyhKdHUEH",
        "outputId": "fb082029-3a4c-4e3d-c913-0ba11018c10b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cg1pebcdLmHw",
        "outputId": "16247aab-f911-45ae-d4fb-4dbf1d61dbdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Encoding(num_tokens=49, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SexismDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = SexismDataset(train_encodings, train_labels)\n",
        "val_dataset = SexismDataset(val_encodings, val_labels)\n",
        "test_dataset = SexismDataset(test_encodings, test_labels)"
      ],
      "metadata": {
        "id": "yKDPJuiuSjm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "QWmCQfupQgiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='/content/drive/MyDrive/assignment-2425/transformer/results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir='/content/drive/MyDrive/assignment-2425/transformer/logs',\n",
        "    load_best_model_at_end=True,\n",
        "    seed = 42\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAKEUL_aNY2V",
        "outputId": "1e41c842-94b1-4702-fcc7-717e7ac00f4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return {\n",
        "        'f1': f1_score(labels, predictions, average='macro')\n",
        "    }"
      ],
      "metadata": {
        "id": "0iowvQLQRuUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=data_collator\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0zKqFpIRC5W",
        "outputId": "65b13c16-bd28-4ac1-a807-927de5e3c95a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-41-27b6ee46aeb3>:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Yk7qUbgNSLGY",
        "outputId": "9548597a-1d6e-4657-918f-4d773ab094b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1077' max='1077' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1077/1077 03:09, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.322713</td>\n",
              "      <td>0.884221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>0.425000</td>\n",
              "      <td>0.894403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.225000</td>\n",
              "      <td>0.540179</td>\n",
              "      <td>0.887497</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1077, training_loss=0.31003141270374523, metrics={'train_runtime': 189.7013, 'train_samples_per_second': 45.387, 'train_steps_per_second': 5.677, 'total_flos': 239207004869520.0, 'train_loss': 0.31003141270374523, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = trainer.evaluate()\n",
        "print(f\"F1-Macro Score: {eval_result['eval_f1']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "omWQfi3hT_Y9",
        "outputId": "7410b418-bd58-4b6b-8aa5-58a66cbc5c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-Macro Score: 0.8842\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gtiG2mAL3HM"
      },
      "source": [
        "# [Task 7 - 0.5 points] Error Analysis\n",
        "\n",
        "### Instructions\n",
        "\n",
        "After evaluating the model, perform a brief error analysis:\n",
        "\n",
        " - Review the results and identify common errors.\n",
        "\n",
        " - Summarize your findings regarding the errors and their impact on performance (e.g. but not limited to Out-of-Vocabulary (OOV) words, data imbalance, and performance differences between the custom model and the transformer...)\n",
        " - Suggest possible solutions to address the identified errors.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Error analysis for baseline model with seed 7"
      ],
      "metadata": {
        "id": "_WyUOO7xhmVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.load('/content/drive/MyDrive/assignment-2425/embed.npy')\n",
        "vocab_size = embedding_matrix.shape[0]"
      ],
      "metadata": {
        "id": "2v93Lm3i1Kr9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline = Sequential([\n",
        "  Embedding(\n",
        "      input_dim=vocab_size,\n",
        "      output_dim=embedding_dimension,\n",
        "      weights=[embedding_matrix],  # Load the pre-trained embeddings\n",
        "      mask_zero=True,\n",
        "      trainable=False               # Set to False to keep embeddings fixed\n",
        "  ),\n",
        "  Bidirectional(LSTM(64, return_sequences=False)),\n",
        "  Dense(1, activation='sigmoid')  # For binary classification\n",
        "])\n",
        "\n",
        "baseline.build(input_shape=(32, 60))\n",
        "baseline.load_weights('/content/drive/MyDrive/assignment-2425/baseline_7.weights.h5')"
      ],
      "metadata": {
        "id": "KdewhKzPku70"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay, ConfusionMatrixDisplay, PrecisionRecallDisplay, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score"
      ],
      "metadata": {
        "id": "bFp-FN4_l4lg"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = np.array(test['padded'].to_list()).astype('float32')\n",
        "y_test = test['hard_label_task1'].values.astype('float32')"
      ],
      "metadata": {
        "id": "y2wOtfkcorqa"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get model predictions (assume `model` and `X_test` are defined)\n",
        "y_pred_probs = baseline.predict(x_test)  # For binary classification, shape: (n_samples, 1)\n",
        "y_pred_probs = y_pred_probs.ravel()   # Flatten to 1D array if needed\n",
        "\n",
        "# Calculate precision, recall, thresholds\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_probs)\n",
        "\n",
        "# Plot the Precision-Recall curve\n",
        "plt.figure()\n",
        "plt.plot(recall, precision, marker='.', label='Precision-Recall curve')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "hnTdqD-lnVjA",
        "outputId": "c7f9de7a-5f15-42c1-d810-5329184e9513"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAW+hJREFUeJzt3XlcVFX/B/DPZWRgQBaRVQLBvRQ3RH5oihqFS5ZZSWm5lGapZZJPgWuraJlpaWpWak+LpJJZbilq5vKkqZiWuyiorKWDsgpzf3/Q3BiYgZlhFmb4vF8vXo9z596ZM1d65uM553uOIIqiCCIiIiI74WDtBhARERGZEsMNERER2RWGGyIiIrIrDDdERERkVxhuiIiIyK4w3BAREZFdYbghIiIiu8JwQ0RERHaF4YaIiIjsCsMNUSM0duxYhISEGHTN3r17IQgC9u7da5Y22bp+/fqhX79+0uPLly9DEASsWbPGam0iaqwYbogsYM2aNRAEQfpxdnZGu3btMGXKFOTk5Fi7eQ2eOiiofxwcHODl5YVBgwbh0KFD1m6eSeTk5GD69Ono0KEDXFxc4OrqivDwcLz99tu4efOmtZtHZFOaWLsBRI3Jm2++idDQUJSUlGD//v1Yvnw5tm7dilOnTsHFxcVi7Vi1ahVUKpVB1/Tt2xfFxcWQy+VmalXdnnzySQwePBgVFRU4d+4cPv74Y/Tv3x9HjhxBWFiY1dpVX0eOHMHgwYNx+/ZtPPXUUwgPDwcA/Pbbb5g/fz727duHn376ycqtJLIdDDdEFjRo0CD06NEDADB+/Hg0b94cixYtwvfff48nn3xS6zWFhYVwdXU1aTscHR0NvsbBwQHOzs4mbYehunfvjqeeekp63KdPHwwaNAjLly/Hxx9/bMWWGe/mzZt45JFHIJPJcPz4cXTo0EHj+XfeeQerVq0yyXuZ43eJqCHisBSRFQ0YMAAAkJ6eDqByLkzTpk1x8eJFDB48GG5ubhg1ahQAQKVSYfHixejYsSOcnZ3h5+eHiRMn4saNGzVed9u2bYiOjoabmxvc3d0RERGBr7/+Wnpe25ybdevWITw8XLomLCwMS5YskZ7XNedm/fr1CA8Ph0KhgLe3N5566ilcu3ZN4xz157p27RqGDRuGpk2bwsfHB9OnT0dFRYXR969Pnz4AgIsXL2ocv3nzJl5++WUEBQXByckJbdq0wYIFC2r0VqlUKixZsgRhYWFwdnaGj48PBg4ciN9++006Z/Xq1RgwYAB8fX3h5OSEe+65B8uXLze6zdWtXLkS165dw6JFi2oEGwDw8/PDrFmzpMeCIOD111+vcV5ISAjGjh0rPVYPhf7888+YNGkSfH19cdddd2HDhg3ScW1tEQQBp06dko6dOXMGjz32GLy8vODs7IwePXpg8+bN9fvQRGbGnhsiK1J/KTdv3lw6Vl5ejtjYWNx7771YuHChNFw1ceJErFmzBuPGjcNLL72E9PR0LF26FMePH8eBAwek3pg1a9bgmWeeQceOHZGYmAhPT08cP34c27dvx8iRI7W2Y+fOnXjyySdx3333YcGCBQCA06dP48CBA5g6darO9qvbExERgaSkJOTk5GDJkiU4cOAAjh8/Dk9PT+nciooKxMbGIjIyEgsXLsSuXbvw/vvvo3Xr1njhhReMun+XL18GADRr1kw6VlRUhOjoaFy7dg0TJ05EcHAwDh48iMTERGRlZWHx4sXSuc8++yzWrFmDQYMGYfz48SgvL8cvv/yC//3vf1IP2/Lly9GxY0c89NBDaNKkCX744QdMmjQJKpUKkydPNqrdVW3evBkKhQKPPfZYvV9Lm0mTJsHHxwdz5sxBYWEhhgwZgqZNm+Lbb79FdHS0xrnJycno2LEjOnXqBAD4448/0Lt3bwQGBiIhIQGurq749ttvMWzYMGzcuBGPPPKIWdpMVG8iEZnd6tWrRQDirl27xLy8PDEzM1Nct26d2Lx5c1GhUIhXr14VRVEUx4wZIwIQExISNK7/5ZdfRADiV199pXF8+/btGsdv3rwpurm5iZGRkWJxcbHGuSqVSvrzmDFjxJYtW0qPp06dKrq7u4vl5eU6P8OePXtEAOKePXtEURTFsrIy0dfXV+zUqZPGe/34448iAHHOnDka7wdAfPPNNzVes1u3bmJ4eLjO91RLT08XAYhvvPGGmJeXJ2ZnZ4u//PKLGBERIQIQ169fL5371ltvia6uruK5c+c0XiMhIUGUyWRiRkaGKIqiuHv3bhGA+NJLL9V4v6r3qqioqMbzsbGxYqtWrTSORUdHi9HR0TXavHr16lo/W7NmzcQuXbrUek5VAMS5c+fWON6yZUtxzJgx0mP179y9995b4+/1ySefFH19fTWOZ2VliQ4ODhp/R/fdd58YFhYmlpSUSMdUKpXYq1cvsW3btnq3mcjSOCxFZEExMTHw8fFBUFAQnnjiCTRt2hTfffcdAgMDNc6r3pOxfv16eHh44P7770d+fr70Ex4ejqZNm2LPnj0AKntgbt26hYSEhBrzYwRB0NkuT09PFBYWYufOnXp/lt9++w25ubmYNGmSxnsNGTIEHTp0wJYtW2pc8/zzz2s87tOnDy5duqT3e86dOxc+Pj7w9/dHnz59cPr0abz//vsavR7r169Hnz590KxZM417FRMTg4qKCuzbtw8AsHHjRgiCgLlz59Z4n6r3SqFQSH9WKpXIz89HdHQ0Ll26BKVSqXfbdSkoKICbm1u9X0eXCRMmQCaTaRyLi4tDbm6uxhDjhg0boFKpEBcXBwD4+++/sXv3bowYMQK3bt2S7uNff/2F2NhYnD9/vsbwI1FDwWEpIgtatmwZ2rVrhyZNmsDPzw/t27eHg4PmvzGaNGmCu+66S+PY+fPnoVQq4evrq/V1c3NzAfw7zKUeVtDXpEmT8O2332LQoEEIDAzEAw88gBEjRmDgwIE6r7ly5QoAoH379jWe69ChA/bv369xTD2npapmzZppzBnKy8vTmIPTtGlTNG3aVHr83HPP4fHHH0dJSQl2796NDz/8sMacnfPnz+P333+v8V5qVe9VixYt4OXlpfMzAsCBAwcwd+5cHDp0CEVFRRrPKZVKeHh41Hp9Xdzd3XHr1q16vUZtQkNDaxwbOHAgPDw8kJycjPvuuw9A5ZBU165d0a5dOwDAhQsXIIoiZs+ejdmzZ2t97dzc3BrBnKghYLghsqCePXtKczl0cXJyqhF4VCoVfH198dVXX2m9RtcXub58fX2RlpaGHTt2YNu2bdi2bRtWr16N0aNHY+3atfV6bbXqvQfaRERESKEJqOypqTp5tm3btoiJiQEAPPjgg5DJZEhISED//v2l+6pSqXD//ffj1Vdf1foe6i9vfVy8eBH33XcfOnTogEWLFiEoKAhyuRxbt27FBx98YHA5vTYdOnRAWloaysrK6lVmr2tidtWeJzUnJycMGzYM3333HT7++GPk5OTgwIEDmDdvnnSO+rNNnz4dsbGxWl+7TZs2RreXyJwYbohsQOvWrbFr1y707t1b65dV1fMA4NSpUwZ/8cjlcgwdOhRDhw6FSqXCpEmTsHLlSsyePVvra7Vs2RIAcPbsWanqS+3s2bPS84b46quvUFxcLD1u1apVrefPnDkTq1atwqxZs7B9+3YAlffg9u3bUgjSpXXr1tixYwf+/vtvnb03P/zwA0pLS7F582YEBwdLx9XDgKYwdOhQHDp0CBs3btS5HEBVzZo1q7GoX1lZGbKysgx637i4OKxduxapqak4ffo0RFGUhqSAf++9o6NjnfeSqKHhnBsiGzBixAhUVFTgrbfeqvFceXm59GX3wAMPwM3NDUlJSSgpKdE4TxRFna//119/aTx2cHBA586dAQClpaVar+nRowd8fX2xYsUKjXO2bduG06dPY8iQIXp9tqp69+6NmJgY6aeucOPp6YmJEydix44dSEtLA1B5rw4dOoQdO3bUOP/mzZsoLy8HADz66KMQRRFvvPFGjfPU90rd21T13imVSqxevdrgz6bL888/j4CAALzyyis4d+5cjedzc3Px9ttvS49bt24tzRtS++STTwwuqY+JiYGXlxeSk5ORnJyMnj17agxh+fr6ol+/fli5cqXW4JSXl2fQ+xFZEntuiGxAdHQ0Jk6ciKSkJKSlpeGBBx6Ao6Mjzp8/j/Xr12PJkiV47LHH4O7ujg8++ADjx49HREQERo4ciWbNmuHEiRMoKirSOcQ0fvx4/P333xgwYADuuusuXLlyBR999BG6du2Ku+++W+s1jo6OWLBgAcaNG4fo6Gg8+eSTUil4SEgIpk2bZs5bIpk6dSoWL16M+fPnY926dfjPf/6DzZs348EHH8TYsWMRHh6OwsJCnDx5Ehs2bMDly5fh7e2N/v374+mnn8aHH36I8+fPY+DAgVCpVPjll1/Qv39/TJkyBQ888IDUozVx4kTcvn0bq1atgq+vr8E9Jbo0a9YM3333HQYPHoyuXbtqrFB87NgxfPPNN4iKipLOHz9+PJ5//nk8+uijuP/++3HixAns2LED3t7eBr2vo6Mjhg8fjnXr1qGwsBALFy6scc6yZctw7733IiwsDBMmTECrVq2Qk5ODQ4cO4erVqzhx4kT9PjyRuVizVIuosVCX5R45cqTW88aMGSO6urrqfP6TTz4Rw8PDRYVCIbq5uYlhYWHiq6++Kl6/fl3jvM2bN4u9evUSFQqF6O7uLvbs2VP85ptvNN6nain4hg0bxAceeED09fUV5XK5GBwcLE6cOFHMysqSzqleCq6WnJwsduvWTXRychK9vLzEUaNGSaXtdX2uuXPnivr835C6rPq9997T+vzYsWNFmUwmXrhwQRRFUbx165aYmJgotmnTRpTL5aK3t7fYq1cvceHChWJZWZl0XXl5ufjee++JHTp0EOVyuejj4yMOGjRIPHr0qMa97Ny5s+js7CyGhISICxYsED///HMRgJieni6dZ2wpuNr169fFadOmie3atROdnZ1FFxcXMTw8XHznnXdEpVIpnVdRUSG+9tprore3t+ji4iLGxsaKFy5c0FkKXtvv3M6dO0UAoiAIYmZmptZzLl68KI4ePVr09/cXHR0dxcDAQPHBBx8UN2zYoNfnIrIGQRRr6asmIiIisjGcc0NERER2heGGiIiI7ArDDREREdkVhhsiIiKyKww3REREZFcYboiIiMiuNLpF/FQqFa5fvw43N7dad0kmIiKihkMURdy6dQstWrSosf9edY0u3Fy/fh1BQUHWbgYREREZITMzE3fddVet5zS6cOPm5gag8ua4u7tbuTVERESkj4KCAgQFBUnf47VpdOFGPRTl7u7OcENERGRj9JlSwgnFREREZFcYboiIiMiuMNwQERGRXWl0c26IiBqCiooK3Llzx9rNIGpQ5HJ5nWXe+mC4ISKyIFEUkZ2djZs3b1q7KUQNjoODA0JDQyGXy+v1Ogw3REQWpA42vr6+cHFx4WKiRP9QL7KblZWF4ODgev23wXBDRGQhFRUVUrBp3ry5tZtD1OD4+Pjg+vXrKC8vh6Ojo9GvwwnFREQWop5j4+LiYuWWEDVM6uGoioqKer0Oww0RkYVxKIpIO1P9t8FwQ0RERHbFquFm3759GDp0KFq0aAFBELBp06Y6r9m7dy+6d+8OJycntGnTBmvWrDF7O4mIyPL0/V4w9Fxbt3fvXgiCIFXcrVmzBp6enlZtU0Nj1XBTWFiILl26YNmyZXqdn56ejiFDhqB///5IS0vDyy+/jPHjx2PHjh1mbql+spTFOHgxH1nKYo0/V3/OkHONfU7bYyIiY4wdOxaCIEAQBMjlcrRp0wZvvvkmysvLzfq+WVlZGDRokMnPrY+QkBDpXri4uCAsLAyffvqp2d+XDGPVaqlBgwYZ9Mu4YsUKhIaG4v333wcA3H333di/fz8++OADxMbGmquZevnyf1cw5/tTUImAesRQBOAgALEd/bDjjxyoxJqPazvX2Oe0PU4aHoa4iGDL3RAisisDBw7E6tWrUVpaiq1bt2Ly5MlwdHREYmJijXPLysrqvU4JAPj7+5vl3Pp68803MWHCBBQVFWH9+vWYMGECAgMDLRKuGgpT/R2bi03NuTl06BBiYmI0jsXGxuLQoUM6ryktLUVBQYHGj6llKYsx+59gA1QGjn/+CJUIbDuVIz1X/XFt5xr7nLbHM1JOsQeHyI5YumfWyckJ/v7+aNmyJV544QXExMRg8+bNACp7doYNG4Z33nkHLVq0QPv27QEAmZmZGDFiBDw9PeHl5YWHH34Yly9f1njdzz//HB07doSTkxMCAgIwZcoU6bmqQ01lZWWYMmUKAgIC4OzsjJYtWyIpKUnruQBw8uRJDBgwAAqFAs2bN8dzzz2H27dvS8+r27xw4UIEBASgefPmmDx5sl6rRru5ucHf3x+tWrXCa6+9Bi8vL+zcuVN6/ubNmxg/fjx8fHzg7u6OAQMG4MSJExqv8cMPPyAiIgLOzs7w9vbGI488Ij333//+Fz169JDeZ+TIkcjNza2zXbW5evUqnnzySXh5ecHV1RU9evTAr7/+qnEvqnr55ZfRr18/6XG/fv0wZcoUvPzyy/D29kZsbCxGjhyJuLg4jevu3LkDb29vfPHFFwAq165JSkpCaGgoFAoFunTpgg0bNtTrs+jDpta5yc7Ohp+fn8YxPz8/FBQUoLi4GAqFosY1SUlJeOONN8zarvT8Qohi3edZU4Uo4nJ+EQI8at4jIrIOURRRfMfwkteNR69i7uY/pJ7ZNx7qiEfD7zLoNRSOsnpVpigUCvz111/S49TUVLi7u0tf8nfu3EFsbCyioqLwyy+/oEmTJnj77bcxcOBA/P7775DL5Vi+fDni4+Mxf/58DBo0CEqlEgcOHND6fh9++CE2b96Mb7/9FsHBwcjMzERmZqbWcwsLC6X3PnLkCHJzczF+/HhMmTJFY57mnj17EBAQgD179uDChQuIi4tD165dMWHCBL3ugUqlwnfffYcbN25o9GI8/vjjUCgU2LZtGzw8PLBy5Urcd999OHfuHLy8vLBlyxY88sgjmDlzJr744guUlZVh69at0vV37tzBW2+9hfbt2yM3Nxfx8fEYO3asxjmGuH37NqKjoxEYGIjNmzfD398fx44dg0qlMuh11q5dixdeeEH6O7pw4QIef/xx3L59G02bNgUA7NixA0VFRVJYS0pKwpdffokVK1agbdu22LdvH5566in4+PggOjraqM+jD5sKN8ZITExEfHy89LigoABBQUEmfY9Qb1c4CJB6ShoimSAgxJtraxA1JMV3KnDPnPrNGVSJwOzv/8Ds7/8w6Lo/34yFi9zwrwBRFJGamoodO3bgxRdflI67urri008/lb7kv/zyS6hUKnz66adSiFq9ejU8PT2xd+9ePPDAA3j77bfxyiuvYOrUqdLrREREaH3fjIwMtG3bFvfeey8EQUDLli11tvHrr79GSUkJvvjiC7i6ugIAli5diqFDh2LBggXSP5KbNWuGpUuXQiaToUOHDhgyZAhSU1PrDDevvfYaZs2ahdLSUpSXl8PLywvjx48HAOzfvx+HDx9Gbm4unJycAAALFy7Epk2bsGHDBjz33HN455138MQTT2j8w7tLly7Sn5955hnpz61atcKHH36IiIgIjRBhiK+//hp5eXk4cuQIvLy8AABt2rQx+HXatm2Ld999V3rcunVruLq64rvvvsPTTz8tvddDDz0ENzc3lJaWYt68edi1axeioqKkz7N//36sXLnSrOHGpoal/P39kZOTo3EsJycH7u7uWnttgMquVHd3d40fUwvwUCBpeBhk//wHLAj/zomRCQIe7R4oPVf9cW3nGvucTBDQ5S4PqX0yQcC84Z3Ya0NERvvxxx/RtGlTODs7Y9CgQYiLi8Prr78uPR8WFqbRe3HixAlcuHABbm5uaNq0KZo2bQovLy+UlJTg4sWLyM3NxfXr13Hffffp9f5jx45FWloa2rdvj5deegk//fSTznNPnz6NLl26SMEGAHr37g2VSoWzZ89Kxzp27AiZTCY9DggIkIZ/5s2bJ7W7adOmyMjIkM77z3/+g7S0NOzevRuRkZH44IMPpLBw4sQJ3L59G82bN9e4Pj09HRcvXgQApKWl1fq5jx49iqFDhyI4OBhubm5SCKjaBkOkpaWhW7duUrAxVnh4uMbjJk2aYMSIEfjqq68AVPaYff/99xg1ahSAyp6doqIi3H///Rr34osvvpDuhbnYVM9NVFRUjW65nTt3SonQmuIigtG3nQ8u5xdJPSTqPwd4KDA9tr3Ox7Wda+xz205m48RVJaJaN8eiEV0YbIgaIIWjDH++aVgxRLayBDGLftboKXYQgF3x0fD3cDbovQ3Rv39/LF++HHK5HC1atECTJppfH1WDBFA5FBIeHi598VXl4+Nj8M7P3bt3R3p6OrZt24Zdu3ZhxIgRiImJqdf8jerL+wuCIA3VPP/88xgxYoT0XIsWLaQ/e3t7o02bNmjTpg3Wr1+PsLAw9OjRA/fccw9u376NgIAA7N27t8b7qcu1df1jHPh3SC02NhZfffUVfHx8kJGRgdjYWJSVlRn1OWt7P6Bys0qx2twKbXOPqv8dA8CoUaMQHR2N3Nxc7Ny5EwqFAgMHDgQAaY7Tli1bEBgYqHGdulfLXKwabm7fvo0LFy5Ij9PT05GWlgYvLy8EBwcjMTER165dkyYmPf/881i6dCleffVVPPPMM9i9eze+/fZbbNmyxVofQUOAh0IjRFT/c12PTf0cAHg3dWKwIWqgBEEweGiolU9TJA0Pw4yUU6gQRalntpWP4cMVhnB1dTVoKKN79+5ITk6Gr6+vzh7zkJAQpKamon///nq9pru7O+Li4hAXF4fHHnsMAwcOxN9//12jR+Luu+/GmjVrUFhYKH0hHzhwAA4ODtJk57p4eXnp1dMRFBSEuLg4JCYm4vvvv0f37t2RnZ2NJk2aICQkROs1nTt3RmpqKsaNG1fjuTNnzuCvv/7C/PnzpSkUv/32m15t1qVz58749NNPtd4roDJsnjp1SuNYWlqaXns79erVC0FBQUhOTsa2bdvw+OOPS9fdc889cHJyQkZGhlmHoLSx6rDUb7/9hm7duqFbt24AgPj4eHTr1g1z5swBULluQdVuuNDQUGzZsgU7d+5Ely5d8P777+PTTz+1ehk4EZElxUUEY39Cf3wz4f+wP6F/g1zmYdSoUfD29sbDDz+MX375Benp6di7dy9eeuklXL16FQDw+uuv4/3338eHH36I8+fP49ixY/joo4+0vt6iRYvwzTff4MyZMzh37hzWr18Pf39/rYvXjRo1Cs7OzhgzZgxOnTqFPXv24MUXX8TTTz9doyjFFKZOnYoffvgBv/32G2JiYhAVFYVhw4bhp59+wuXLl3Hw4EHMnDlTCilz587FN998g7lz5+L06dM4efIkFixYAAAIDg6GXC7HRx99hEuXLmHz5s1466236tW+J598Ev7+/hg2bBgOHDiAS5cuYePGjVKl8YABA/Dbb7/hiy++wPnz5zF37twaYac2I0eOxIoVK7Bz505pSAqorCqbPn06pk2bhrVr1+LixYvS3/HatWvr9ZnqYtVw069fP4iiWONHPZt9zZo1Nbr2+vXrh+PHj6O0tBQXL17E2LFjLd5uIiJrC/BQIKp18wbbM+vi4oJ9+/YhODgYw4cPx913341nn30WJSUlUk/OmDFjsHjxYnz88cfo2LEjHnzwQZw/f17r67m5ueHdd99Fjx49EBERgcuXL2Pr1q1ah7dcXFywY8cO/P3334iIiMBjjz2G++67D0uXLjXLZ73nnnvwwAMPYM6cORAEAVu3bkXfvn0xbtw4tGvXDk888QSuXLkiBat+/fph/fr12Lx5M7p27YoBAwbg8OHDACp7UdasWYP169fjnnvuwfz587Fw4cJ6tU8ul+Onn36Cr68vBg8ejLCwMMyfP1+abxQbG4vZs2fj1VdfRUREBG7duoXRo0fr/fqjRo3Cn3/+icDAQPTu3VvjubfeeguzZ89GUlIS7r77bgwcOBBbtmxBaGhovT5TXQSx+kCbnSsoKICHhweUSqVZJhc3FJ/vT8ebP/6JoV1a4KMnu1m7OUQEoKSkBOnp6QgNDYWzs/7zY4gai9r+GzHk+9umqqWIiIiI6sJwQ0RERHaF4YaIiIjsCsMNERER2RWGGyIiC2tkdRxEejPVfxsMN0REFqJe3KyoqMjKLSFqmNSrMFfdFsMYNrX9ApG1ZSmLkZ5fiFBvVwR4KGo8JqqNTCaDp6entH+Ri4tLvXbmJrInKpUKeXl5cHFxqbG9h6EYboiq0RVgTl5VYsH2M1CJlXv59G3njZ/P5kNE5eOk4WENcqVYalj8/f0BQAo4RPQvBwcHBAcH1zv0M9xQo6RvgOnT1hv7zlUGmKpUIrD3bL7G4xkpp9C3nQ97cKhWgiAgICAAvr6+WjcnJGrM5HK5wZuqasNwQ42GrgBz/z1++OnPHFSfx6YSgZ/P5Wt/MS0qRBGX84sYbkgvMpms3vMKiEg7hhuyG7XNh9l3Lg+JKSeh0hJgdvyRY5L3lwkCQrxdTPJaRERkPIYbsmm6emMGdvLHtpPZNYaTTEUmCBjWrQU2HrsGoPI95w3vxF4bIqIGgOGGbIq+vTFbT2bX+73UAWbT8euoEEXIBAGvDmqPzoGeCPF2QYCHAj+cuI6yChEbX+iFbsHN6v2eRERUfww31OBp650RAJP0yugTYKbHtsfl/CLpcVWVM/pF+Lpzh2ciooaC4YYaHH16ZwwNNoIACCKgAgwOMAEeCpsZbuK6O0REDDfUQJiyd0Zbb8y84Z3Qt52PXQSYqnQFQa67Q0SNGcMNWYUpemeM6Y2x9QCja00eQYBGKTvX3SGixozhhiwu+UiGFGbq0ztjr70xgO4qsL7tfPDz2bwa90zbXnNcd4eIGiuGG7II9Zd1EwcBCRtPSl/O9e2dAeyrNybU2xV7zuRi1qZTWqvA9p7N0/s9uO4OETVWDDdkNlLvQ6YS83ec0dq7UBt9emdsiaFbPBiqai+Y+t7Z8v0iIjIWww2ZRdWhp7o0ht6Z2tbkMWSLB11kgoAXB7TB4tTz8FA4YvvLfWzynhERmQLDDZmM+ss871YpXtt4stZzHfBvmLHl3hnxn+6o3IISBHr+O7z0e6YSC4zorapNXWvy3Cy6g8Wp5yFv4mBT95CIyNQYbqhejBl6kgkCUiZFoahMZdO9M8lHMlBWUfmBH11+EPe28cYv500wvGTkmjw3i7jDNBERwHBD9WDI0JOauqemS5Btb1WQpSxGYsq/vVMqEdh33vDhpca0Jg8RkaUw3JBB1D01rnIZElJO1tpTU3XoSds8GluWnl9oUKhrLGvyEBE1BAw3pDdDemp0DT3Zi1BvVzgI0PteNITeGG7NQESNBcMN1SlLWYyjV25orE9TG3sZeqpNgIcCScPDMCPllDScVNcGnOrrzK2sXIUsZTEAcGsGImqUGG6oVnX11tjz0FNd4iKCa/TG1LYBp7ntOJUNAFAW30GvpN0AtC+SyK0ZiMjeMdyQTupJs7qCjb0PPemj+nCStSb7ZimLsWT3eelxXT1s3JqBiOwZww3VkKUsRnpeITYdv1ZrsLH3oSdbkp5faNCaOtyagYjsGcMNaahzGEoAPnyiG8JDmvFf/Q1IXROcq+4a7iCAWzMQkV1zsHYDqOHIUhYjoVqwEfDvL4lMEJA0PAwPdmnBL8YGRj3BWSYIAP4pPf/nOZkg4O2HO0nnbn+5LycTE5FdY88NScNQG45erTG0IQJYOrIbvFydGu28GltRfYIzAOnPzV2dMHPTKQCAn7uzNZtJRGR2DDeNXF3DUDJBQPeWHIKyFdomOAOV5eGG4Jo4RGTLGG4aMW3VUMI/P1U3teSXm/3TtYM518QhIlvEcNNIZSmLse5wRo0eGw5DNR7SpqdXlViw/QxUoubEY4Br4hCRbWK4aYRqG4riMJT9yykowfZTWVp/B7SVk3NNHCKyNQw3jUxtC/NxGMp+rf8tU/pz7Af79NpGQ41r4hCRrWG4aWQOX/pba7CZPeRuDO4cwGBjh7KUxZj9/SnpcV3BRqhyDgMvEdkirnPTSGQpi7HtZBaStp2u8ZxMEBhs7Fh6fqFeu5cDlb8LY3uHAKhcGHB/Qn9OJiYim8Oem0ag+hwbhaMMpeUVUIn8l3ljoG31YkEABFH7pqdnsm9h9YHLaOrUhL8XRGSTGG7sXHFZRY05NqXlFfhuUq9GveFlY6JevXhGyilUiKIUaKvvaK52JvuWFVtLRFR/DDd2rrCsvMaQhEoEispUiGrd3DqNIourvnqxOsww2BKRPWK4sXNntfwrnNUvjVP11YuJiOwVJxTbub8LywBobqLIOTakj9ul5chSFlu7GUREBmPPjZ06nnFD4/FrA9ujS1AzzrGhOu07lwegssqq9/zd3H6BiGwOe27sUJayGD/+nqVx7L0d5xhsqE5ZymKsOXhZeqzefoE9OERkSxhu7FB6fmGNhdrUS+gT1SY9v7DGFgz83SEiW2P1cLNs2TKEhITA2dkZkZGROHz4sM5z79y5gzfffBOtW7eGs7MzunTpgu3bt1uwtbZBva5JVZxETPoI9XaFwN8dIrJxVg03ycnJiI+Px9y5c3Hs2DF06dIFsbGxyM3N1Xr+rFmzsHLlSnz00Uf4888/8fzzz+ORRx7B8ePHLdzyhk29ronsn28pTiImfQV4KDC2V4j0mL87RGSLBFHUtg+wZURGRiIiIgJLly4FAKhUKgQFBeHFF19EQkJCjfNbtGiBmTNnYvLkydKxRx99FAqFAl9++aVe71lQUAAPDw8olUq4u7ub5oM0UFnKYq2LtBHVZs/ZXIxbfQSh3q74ekIkf3eIqEEw5PvbatVSZWVlOHr0KBITE6VjDg4OiImJwaFDh7ReU1paCmdnZ41jCoUC+/fv1/k+paWlKC0tlR4XFBTUs+W2g+uaUH1w+wUislVWG5bKz89HRUUF/Pz8NI77+fkhOztb6zWxsbFYtGgRzp8/D5VKhZ07dyIlJQVZWVlazweApKQkeHh4SD9BQUEm/RxE9i5LWYyDF/NZMUVENsPqE4oNsWTJErRt2xYdOnSAXC7HlClTMG7cODg46P4YiYmJUCqV0k9mZqYFW0xku26XlmPlzxfRe/5ujFz1K3rP343kIxnWbhYRUZ2sFm68vb0hk8mQk5OjcTwnJwf+/v5ar/Hx8cGmTZtQWFiIK1eu4MyZM2jatClatWql832cnJzg7u6u8UNEulVdxC9p2xlpbzKueUNEtsJq4UYulyM8PBypqanSMZVKhdTUVERFRdV6rbOzMwIDA1FeXo6NGzfi4YcfNndziRqF6ov4Vcc1b4jIFlh1+4X4+HiMGTMGPXr0QM+ePbF48WIUFhZi3LhxAIDRo0cjMDAQSUlJAIBff/0V165dQ9euXXHt2jW8/vrrUKlUePXVV635MYjshrZF/KrimjdEZAusGm7i4uKQl5eHOXPmIDs7G127dsX27dulScYZGRka82lKSkowa9YsXLp0CU2bNsXgwYPx3//+F56enlb6BET2Rb0ApEpLwBEEcM0bIrIJVl3nxhoa0zo3RMZIPpKBGSmnUCGKkAkCWjZ3waX8Qswc3AET+rau9dosZTHS8wsR6u3KEEREJmUT69wQUcMUFxGMvu18pAUgZ6ScxKX8Qni6yGucWzXM7DuXh8SUk1CJgIMA7iZORFbDcENENdS2AKQ60Jy8qsSC7ZXVVAKgsVmrurKqbzsf9uAQkcUx3BBRrUruVAAAbhaVIflIhtQ7U5W2sW11ZRXDDRFZGsMNEemUfCQDhy79DQCYt/WM1hCjCyuriMhabGqFYiKynCxlMRJTTkqP6wo2/2xCD6Byzg0rq4jIWhhuiEir9PxCrSXh2sgEAfOHh8HRoTLhpLzQi5OJichqOCxFRFppW/NGEABBBFSoDDSvDmqPzoGeCPF2QYCHArM3/QFAhK+7s7WaTUTEcENE2gV4KJA0PExjzZt5wztplIlXH3ZSL5uVW1CCFp4ckiIi62C4ISKdqq95ow4z2ubSJB/JwJ1/unmGLz/IdW6IyGo454aIahXgoUBU6+a1Tg6uPvmYO4gTkTUx3BBRvWmbfMwdxInIWhhuiKje1JOPq+I6N0RkLQw3RFRv6snHalznhoisieGGiEwiLiKY69wQUYPAcENEJiP8s0yxep2bLGUxDl7M58RiIrIoloITkVlU3WTTQQBLw4nIYthzQ0Qmo17E7+TVm0iosns4S8OJyJIYbojIJKou4jfxy2MQWRpORFbCcENE9VZ9ET9tWBpORJbCcENE9VbXDuLqfalYGk5ElsAJxURUb7p2EBdFoHtwMywb1Y3Bhogshj03RFRv6kX8ZP+UgssEAY90CwQAeLnKGWyIyKLYc0NEJlF9B/G9Z/OQcuwa/i4sQ5aymAGHiCyGPTdEZDJVdxA/cvlvAMCxjBvoPX83ko9kWLl1RNRYMNwQkcllKYvx3bFr0mOuc0NElsRwQ0Qml55fiOrFU1znhogsheGGiEwu1NsVQrVjXOeGiCyF4YaITC7AQ4FHugdKj7nODRFZEsMNEZlFRIgXgMp1bvYn9OemmURkMQw3RGRWXOeGiCyN4YaIzEq9zg0RkaUw3BCRWXCdGyKyFoYbIjI5rnNDRNbEcENEJsd1bojImhhuiMjkuM4NEVkTww0RmRzXuSEia2K4ISKzqL7OTd92Pjh4MZ/zbojI7JpYuwFEZP82p13Hgu1noBIBBwFIGh7GRf2IyGwYbojILKqWgh/LuCEdV1dO9W3nw2EqIjILDksRkclVLwWvjpVTRGRODDdEZHLaSsGrYuUUEZkTww0RmVyotyscqteC/8NBACuniMisGG6IyOQCPBRIGh4GmVCZcGSCAF83JwDAB3FdOZmYiMyKE4qJyCziIoLRt50PLucXIcTbBU9/dhi5t0qt3SwiagTYc0NEZhPgoUBU6+bYdy4PF3JvAwBeTk7jJppEZFYMN0RkVlnKYiSmnJQei3psopmlLOaCf0RkNA5LEZFZpecXQlWtdEpdCq5tUnHykQwkppzkgn9EZDSGGyIyK3XlVNWAU70UPEtZjPT8QjjKBCRsPCmVkXPBPyIyBsMNEZmVunLqtY2VQ1PqUnAAOHgxHyevKqWtGbSprZeHiEgbq8+5WbZsGUJCQuDs7IzIyEgcPny41vMXL16M9u3bQ6FQICgoCNOmTUNJSYmFWktExoiLCEYb36YAKkvBAaD3/N0YuepXJG3THWwALvhHRIazarhJTk5GfHw85s6di2PHjqFLly6IjY1Fbm6u1vO//vprJCQkYO7cuTh9+jQ+++wzJCcnY8aMGRZuOREZ62ZRGRL+mVNTFxkX/CMiIwiiKOrxfzHmERkZiYiICCxduhQAoFKpEBQUhBdffBEJCQk1zp8yZQpOnz6N1NRU6dgrr7yCX3/9Ffv379frPQsKCuDh4QGlUgl3d3fTfBAiqlXykQxpWKouVefnHEzojxae7LUhIsO+v63Wc1NWVoajR48iJibm38Y4OCAmJgaHDh3Sek2vXr1w9OhRaejq0qVL2Lp1KwYPHqzzfUpLS1FQUKDxQ0SWU70UvDYyQcCsIfeYuUVEZO+sNqE4Pz8fFRUV8PPz0zju5+eHM2fOaL1m5MiRyM/Px7333gtRFFFeXo7nn3++1mGppKQkvPHGGyZtOxHpT1spOFD5LysVKgPNq4Pao3OgJ0K8XbDtZLZ0zr0L9pitFFxdoRXq7cphLyI7Y1PVUnv37sW8efPw8ccfIzIyEhcuXMDUqVPx1ltvYfbs2VqvSUxMRHx8vPS4oKAAQUFBlmoyUaOnqxQ8ZVIUispUCPF2kcJFlrIYb2/5UzrPlKXgVcPMvnN5XEuHyI5ZLdx4e3tDJpMhJydH43hOTg78/f21XjN79mw8/fTTGD9+PAAgLCwMhYWFeO655zBz5kw4ONQcZXNycoKTk5PpPwAR6UVdCj4j5RQqRBEyQcC84Z3QJahZjXMNXfBPX1UXBhSEylWS1biWDpH9sVq4kcvlCA8PR2pqKoYNGwagckJxamoqpkyZovWaoqKiGgFGJpMBAKw4L5qI6lB9E01dIUJXL4+L3AEHL+YbPISUpSzG0Ss3NBYG1PZ/FVxLh8i+WHVYKj4+HmPGjEGPHj3Qs2dPLF68GIWFhRg3bhwAYPTo0QgMDERSUhIAYOjQoVi0aBG6desmDUvNnj0bQ4cOlUIOETVMAR6KOsNDgIcCs4bcgzd/rByakgnAsG4t8MjHBw0eQqraW1MXrqVDZF+sGm7i4uKQl5eHOXPmIDs7G127dsX27dulScYZGRkaPTWzZs2CIAiYNWsWrl27Bh8fHwwdOhTvvPOOtT4CEZnYsG6BUrhZ/lR3TPzymNTbUtcQknpeze2SOxq9NdVVHZpysOBaOpzETGQZVl3nxhq4zg1Rw/b5/nQp3OjyzYT/Q1Tr5gD+DQwnM5WYv+OM1mGnqmSCgDce7ohZm04BAL4eH4lebbxN0vbqqoaZ1NO5mP39KYh69EAxBBHVZMj3t01VSxGRfateLaVN1SEkQ4aeHATgwye6ITykGVJP/7sK+lOf/WqyaildFVnVaeuBkkJalb22TF3JxdBEjQXDDRE1GLrWxFFTr4mTnl+IzL+Kah16AjTX0pk3vBMe7NICWcpizPn+lHSOqaqlqgat6pOitakQRWz5PQtDOgfoDEL1bRvL36mxYrghogZDW7WUAEAEcP/dfugR0gwL6thoU03XWjqmLjfXVpGlT/sA4O0tp/HOltO1BjRj21Zb2GL5O9k7hhsiajC0rYnTr4MPUk/nIudWMZK25dT9IkCta+noKjfXt1pK36Gn6tQhrbq6LjW0kkvfsMXyd7JnDDdE1KBUXxNHPfH396va94XTtY2Dri/tAA8F3ny4k/S6hlRL1bYYYHWCAAjiv23rEuSBYxk363yP6oZ1a1Fr26qGrb1n8zDju5N1TqoGWP5O9o3hhogaHPWaOFnKYuyuMvm3Ol1DT4bQJwjouxhg1XbNG95JCmkucgcMW3ZQ5/lVg1B1m45fx/TY9hqfTdvk47pU7TmyZPk7kTUw3BBRg5WeX6hz2Ka2oafaVJ9QLEJ35ZKhQ09VK7LUrxXgocDBi/l1fo6+7Xyw5fcsvL3ltMbz1YePDKkQq/oe/dr7IPVMZVDUFsxYSUX2hOGGiBosbfNjtAUIQ9Q1oVhj6Am1z4mpPvSkrsgy9nMM6RyAeVtP69x+oomDUGeFWFXq9wjyUmDYx//2HFUPdNUnH7OSimwdww0RNVi6Nt3UFiD0Vdv+VT/+fl1z6KmW16k+9FTXPB99Pof6vNc2ngRQGa6GdWuBYR8f1Gv4TFfYOngxv8b16lL0iJBmGj1BrKQie8BwQ0QNmr6bbupL24TiqvtX1UXX0JM5PocIYOOxa3U3CrWHrVBvV60ToKsPgamxkopsHcMNETV4+my6aYjHe9wlhZtp97fF+z+d13muvkNP+qjrc2Qpi5GYcrLO16mrQqz6ewR4KDCgva8056YurKQiW8dwQ0SNzvrfrkp/ri3YGDL0ZAp1rdCsbpOhFWJZymLsPqtfsGElFdkDhhsialSqV0tpY+zQU31pXaFZS8+RoRVi6fmFda7Jo36+cW2lTPaK4YaIGhVdvSPa9qGyNF0Tj+vbc6QtNKk5VJuLo600nsjWGBVuKioqsGbNGqSmpiI3NxcqlebSU7t37zZJ44iITE1XtVR9FwM0FV0Tj+vTJm2hST1XJ/92CV78Jk3jfE4oJltnVLiZOnUq1qxZgyFDhqBTp04QBMHU7SIiMgtdvSOGDvWYk6knUAO6Q1OWsrhee20RNURGhZt169bh22+/xeDBg03dHiIiszN1ebmt0BaaAjwUeKhLC2xKuy4dq2s/K6KGzsGYi+RyOdq0aWPqthARWUyAhwJRrZs3+i/xLGUxNp+4rnFs0/HryFIWW6lFRPVnVLh55ZVXsGTJEoicVk9EZNNq246CyFYZNSy1f/9+7NmzB9u2bUPHjh3h6Oio8XxKSopJGkdEROala4I159yQLTMq3Hh6euKRRx4xdVuIiMjCOOeG7JFR4Wb16tWmbgcREVmBrjk302PbM+CQzarXIn55eXk4e/YsAKB9+/bw8fExSaOIiMgyaptzw3BDtsqoCcWFhYV45plnEBAQgL59+6Jv375o0aIFnn32WRQVcRIaEZGtUM+5qYpzbsjWGRVu4uPj8fPPP+OHH37AzZs3cfPmTXz//ff4+eef8corr5i6jUREZCbqOTdVcc4N2TpBNKKe29vbGxs2bEC/fv00ju/ZswcjRoxAXl6eqdpncgUFBfDw8IBSqYS7u7u1m0NEZFVZymL0nr+7RrXU/oT+DDjUoBjy/W1Uz01RURH8/PxqHPf19eWwFBGRDeE6N2SPjAo3UVFRmDt3LkpKSqRjxcXFeOONNxAVFWWyxhERkXlxzg3ZI6OqpZYsWYLY2Fjcdddd6NKlCwDgxIkTcHZ2xo4dO0zaQCIiMh991rnJUhYjPb8Qod6uHKoim2BUuOnUqRPOnz+Pr776CmfOnAEAPPnkkxg1ahQUCv7iExHZCl3r3IyOaonCsgqcvKrEgu1noBIBBwFIGh6GuIhgjesZfKihMWpCsS3jhGIion8dvJiPkat+rXFcAKDty0EmCEiZFKVX8CEyJUO+v/Xuudm8eTMGDRoER0dHbN68udZzH3roIX1floiIrCjU21VrkNH1r94KUcSwZQdrPK8SgRkpp9C3nQ97cMjq9A43w4YNQ3Z2Nnx9fTFs2DCd5wmCgIqKClO0jYiIGqDagg9XNqaGQO9wo1KptP6ZiIhsV3p+oc6wYihBgEaVFefjkLXUa2+pqm7evAlPT09TvRwREVmAuhS86lo3ggAIImDwP2OrvEbykQwkppysdT4Oww+Zi1Hr3CxYsADJycnS48cffxxeXl4IDAzEiRMnTNY4IiIyrwAPBZKGh0EmVC52IxMEzB8ehgOJA7BsZDdUWwIHgqD7i0MEcOzKDfz4+3UkbDwpBSb1fJwTmTdw8GI+spTFSD6Sgd7zd2Pkql/Re/5uJB/JMNdHpEbIqGqp0NBQfPXVV+jVqxd27tyJESNGIDk5Gd9++y0yMjLw008/maOtJsFqKSKimrKUxbicX4QQbxeNXpTkIxmYkXIKFaIImSBg3vBO6NvOB8eu3MCUr49rDGkJAlDbN4p64rK28xwEYMkTXdEjxIu9OKSVId/fRoUbhUKBc+fOISgoCFOnTkVJSQlWrlyJc+fOITIyEjdu3DC68ebGcENEZBhdweeVb9Ow8dg1k74XS8pJF7PvLdWsWTNkZmYCALZv346YmBgAgCiKrJQiIrIzAR4KRLVuXmPV4u+OmzbYANqHsIgMZdSE4uHDh2PkyJFo27Yt/vrrLwwaNAgAcPz4cbRp08akDSQiooZH24abplJ1LR325JAxjOq5+eCDDzBlyhTcc8892LlzJ5o2bQoAyMrKwqRJk0zaQCIiani0bbhZ22Rj4N/nql+njTo3qXty2INDhuD2C0REZBRDJhurt20oKlMh/3YJXvwmzaD3+mbC/yGqdXOTtp9sC7dfICIis4uLCEbfdj41JhsP6azA7dLyGsGnS1AzAJXzdaqvrVMbmSBoLA5IVBe9e24cHByk7RccHHR3PDb07RfYc0NEZBm6qqwAzV6fugwO88dT/9eSi/01cmYvBbdlDDdERA1DlrJY6xCWLpxc3LiZvRSciIiovgI8FBjSuQXmP/rvCsm1TTbm5GLSl1Gl4C+99BLatGmDl156SeP40qVLceHCBSxevNgUbSMiokag6twdF7mDVAauDXceJ30Y1XOzceNG9O7du8bxXr16YcOGDfVuFBERNS7qhQJ93Z1rHaLi5GLSh1Hh5q+//oKHh0eN4+7u7sjPz693o4iIqHFKzy+s9flh3Vqw14bqZFS4adOmDbZv317j+LZt29CqVSuDX2/ZsmUICQmBs7MzIiMjcfjwYZ3n9uvXD4Ig1PgZMmSIwe9LREQNi7bFAavadPw659xQnYyacxMfH48pU6YgLy8PAwYMAACkpqbi/fffN3i+TXJyMuLj47FixQpERkZi8eLFiI2NxdmzZ+Hr61vj/JSUFJSVlUmP//rrL3Tp0gWPP/64MR+FiIgakAAPBZKGh+ksE9c25yZLWYz0/EKWipPE6FLw5cuX45133sH169cBACEhIXj99dcxevRog14nMjISERERWLp0KQBApVIhKCgIL774IhISEuq8fvHixZgzZw6ysrLg6upa5/ksBSciavjUZeKTvz6ucVwQgE2TeqGwrAKh3q7Ydy4PiSknoRK1l4oz+NgPi65zk5eXB4VCIe0vZYiysjK4uLhgw4YNGDZsmHR8zJgxuHnzJr7//vs6XyMsLAxRUVH45JNPtD5fWlqK0tJS6XFBQQGCgoIYboiIGrgsZTF6Je2uMcFYQOXeU+r/rcpBAJY80RU9Qryw/rdMfLDzPDfgtBMWWeemvLwcu3btQkpKCtT56Pr167h9+7ber5Gfn4+Kigr4+flpHPfz80N2dnad1x8+fBinTp3C+PHjdZ6TlJQEDw8P6ScoKEjv9hERkfWk5xdqrZwSq/1vVSoRePGbNEQl7caif4KN+jjXyGk8jAo3V65cQVhYGB5++GFMnjwZeXl5AIAFCxZg+vTpJm1gbT777DOEhYWhZ8+eOs9JTEyEUqmUfjIzMy3WPiIiMl6otyv02EBcb+r5OmT/jAo3U6dORY8ePXDjxg0oFP+OYT7yyCNITU3V+3W8vb0hk8mQk5OjcTwnJwf+/v61XltYWIh169bh2WefrfU8JycnuLu7a/wQEVHj5CLnwvyNgVF/y7/88gtmzZoFuVyucTwkJATXrl3T+3XkcjnCw8M1ApFKpUJqaiqioqJqvXb9+vUoLS3FU089ZVjjiYjIJugallJ/cdVWMq5LUZmqPk0iG2FUKbhKpdK68/fVq1fh5uZm0GvFx8djzJgx6NGjB3r27InFixejsLAQ48aNAwCMHj0agYGBSEpK0rjus88+w7Bhw9C8eXNjPgIRETVw6jVvVFUSjkwQkDIpCkVlKrjIHfDIxwc1nlerfh1QWWnF1Y0bB6PCzQMPPIDFixdLFUqCIOD27duYO3cuBg8ebNBrxcXFIS8vD3PmzEF2dja6du2K7du3S5OMMzIy4OCg2cF09uxZ7N+/Hz/99JMxzSciIhtQfc0bmSBg3vBO6BLUTDqn+vOvDmqPzoGecJE74OFlBzVfsF61wWRLjCoFz8zMxMCBAyGKIs6fP48ePXrg/Pnz8Pb2xr59+7QuvtdQcJ0bIiLbkqUsxuX8IoR4u2hdq0bb8wcv5mPkql9rnPvNhP9DVGv2+NsiQ76/jeq5CQoKwokTJ5CcnIwTJ07g9u3bePbZZzFq1CiNCcZERET1FeChqHUBPm3Ph3rXXNSVw1KNh8Hh5s6dO+jQoQN+/PFHjBo1CqNGjTJHu4iIiEyLw1KNhsHVUo6OjigpKTFHW4iIiExC2+7iIsB1bhoJo0rBJ0+ejAULFqC8vNzU7SEiIqo3Dks1bkbNuTly5AhSU1Px008/ISwsrMaGlSkpKSZpHBERkclwWKrRMCrceHp64tFHHzV1W4iIiEyitmEp7g5u/wwKNyqVCu+99x7OnTuHsrIyDBgwAK+//jorpIiIqEHROiwFIP92CbKUxQw4ds6gOTfvvPMOZsyYgaZNmyIwMBAffvghJk+ebK62ERERmYyIyh3De8/fjeQjGchSFuPgxXzuFG6HDFrEr23btpg+fTomTpwIANi1axeGDBmC4uLiGqsIN1RcxI+IyP7pWsRPTRAAiJWBx0GoXOk4LiJYr9fOUhYjPb8Qod6u7AGyILMt4peRkaGxvUJMTAwEQcD169dx1113GddaIiIiE3OVy2p9vuo/61UikJhyEi5yGXqEeOlcBTk9vxAnMm/i3R1nIYqGhyKyHIPCTXl5OZydnTWOOTo64s6dOyZtFBERUX0UltXc3Lk2KrFyyEodWPq285F6Z34+m4fE706i+jiHSgRmpJxC33Y+7MFpYAwKN6IoYuzYsXBycpKOlZSU4Pnnn9coB2cpOBERWZO2HcX1oRKBhJST0pDVP6NXOlWIIiuwGiCDws2YMWNqHHvqqadM1hgiIiJTqL6juCGqnq7PlS5y25hz2pgYFG5Wr15trnYQERGZVFxEMPq288GxKzcw5evjZlvDr6hMJf2Zk40bBqMW8SMiIrIFAR4KDOmswO3ScqkXx0Go7J3RN+wIAiCIgErHcy5yBxy8mI/fM5VYsOMMJxs3AAaVgtsDloITETVOWcpiXM4vQoi3C/ady9M5ZFU1zMgEAfOGd5J6gCZ/fVzv95MJAvYn9GcPjomYrRSciIjIVgV4KKSgoR6yupxfhN+v3sS728+iQhQ1wow6CKmvaeZac0uH2nCysfUw3BARUaOkDjtRrZvjoa4taoSZ6qGkrrVztOFkY+tguCEiokavaq+OLoaunQNoTjYmy2GkJCIi0oN67ZyqBKH2L1L23FgH7zoREZEe1GvnyITKhCMTBMwfHoYDiQMwa8jdWq9hz411cFiKiIhIT1UnIlednzOkcwDe2XJao7xcEIAQbxfrNLSRY7ghIiIygD7zcwDov5AOmRyHpYiIiOopPb+wRpYRAVzOL7JGcxo9hhsiIqJ60lUmzgnF1sG7TkREVE+6ysQ5odg6GG6IiIjqSZ+emyxlMQ5ezEeWsthSzWq0OKGYiIionurquUk+koHElJNQcVNNi2DPDRERUT2Ferui2vp+0o7hP/5+HQkbK4MNAKhEYEbKKfbgmBF7boiIiMxAFIGHlx3U+hw31TQv9twQERHVk7ZS8NpwgT/zYrghIiKqJ4N3DOcCf2bFcENERFRPhu4YzgX+zIvhhoiIqJ5MsWM4S8VNhxOKiYiI6km9Y/iMlFOoEEXIBAHzhndC33Y+2PJ7Ft7ecrrGNVdvFKOwrAKh3q744UQWkrZWbrzJUvH6E0RRbFQjfwUFBfDw8IBSqYS7u7u1m0NERHYkS1lcY8fwE5k3dFZN6SITBOxP6M9qqioM+f5mzw0REZGJaNsx3ND5OABLxeuLc26IiIjMyOBKqn9w003j8c4RERGZkTE9NwA33awPhhsiIiIzqquSqvpzauy5MR7n3BAREZlRbZVUl/OLkH+7BC9+k1bjuqo9N1nKYqTnFyLU25XzcPTAcENERGRmcRHBUpipWkkV4KHAicwbWq9R99xwR3HDMdwQERFZgLZKKkD3nJwjl29ApRKRkHISYrUdxfu282EPTi0YboiIiKxIVzWVtoX/AJaJ64OzlYiIiKzImGoqTjauHe8OERGRFRmzDg7LxGvHcENERGRF7LkxPd4dIiIiK9K2Do6aruPsuakdww0REZEVqdfBkQmVSUYmCEgc3AHfTPg/rBodrvWaqj03WcpiHLyYjyxlsUXaawusHm6WLVuGkJAQODs7IzIyEocPH671/Js3b2Ly5MkICAiAk5MT2rVrh61bt1qotURERKYXFxGM/Qn98c2E/8P+hP6Y2Lc1olo3h0Kuvaj5yOUbyFIW4+tfr6DX/N0YuepX9J6/G8lHMizc8obJqqXgycnJiI+Px4oVKxAZGYnFixcjNjYWZ8+eha+vb43zy8rKcP/998PX1xcbNmxAYGAgrly5Ak9PT8s3noiIyIS0rYNTW5l49VJxroHzL6uGm0WLFmHChAkYN24cAGDFihXYsmULPv/8cyQkJNQ4//PPP8fff/+NgwcPwtHREQAQEhJiySYTERFZjKGTjbkGTiWrDUuVlZXh6NGjiImJ+bcxDg6IiYnBoUOHtF6zefNmREVFYfLkyfDz80OnTp0wb948VFTo/ssvLS1FQUGBxg8REZEtMKZMnJVUVgw3+fn5qKiogJ+fn8ZxPz8/ZGdna73m0qVL2LBhAyoqKrB161bMnj0b77//Pt5++22d75OUlAQPDw/pJygoyKSfg4iIyFyMKRO/eoMTi20q3qlUKvj6+uKTTz5BeHg44uLiMHPmTKxYsULnNYmJiVAqldJPZmamBVtMRERkvNrKxAUdx9X7UDVmVptz4+3tDZlMhpycHI3jOTk58Pf313pNQEAAHB0dIZP920139913Izs7G2VlZZDL5TWucXJygpOTk2kbT0REZAHqMvEZKadQIYqQCQJeHdQenQM9UVR2B8+uPVrjmiCvxj3fBrBiuJHL5QgPD0dqaiqGDRsGoLJnJjU1FVOmTNF6Te/evfH1119DpVLBwaGy0+ncuXMICAjQGmyIiIhsXVxEMPq288Hl/CKEeLtIk4UPXszXev7VG8UoLKtAqLdro51YbNVhqfj4eKxatQpr167F6dOn8cILL6CwsFCqnho9ejQSExOl81944QX8/fffmDp1Ks6dO4ctW7Zg3rx5mDx5srU+AhERkdkFeCgQ1bq5RljRNdl48tfHG/26N1YtBY+Li0NeXh7mzJmD7OxsdO3aFdu3b5cmGWdkZEg9NAAQFBSEHTt2YNq0aejcuTMCAwMxdepUvPbaa9b6CERERFZR12RjlQgkpJxslOveCKLYuKYeFRQUwMPDA0qlEu7u7tZuDhERkVFOZN7Aw8sO1nnespHdMKRzCwu0yLwM+f62qWopIiIiqqRvmXjj6sKoxHBDRERkg2orE6+qMVZPMdwQERHZoOq7iesKOkVlKgu2qmGw6oRiIiIiMl7VMnFd6940xu0YGt8nJiIisiPqMnGFXHt/RWPsuWG4ISIisgO61r05n1uALGXj2m+K4YaIiMgOZOrYMHPO9382ugX9GG6IiIjsQG3L1qkX9GssPTgMN0RERHYg2Mul1udFETh25YaFWmNdDDdERER2QJ9F/RrLgn4MN0RERHZAn0X9GsuCfgw3REREdqD6on7aNJaycIYbIiIiOxEXEYz9Cf3x9rCOWp9vLAv6NY5PSURE1EgEeCjg6SLX+txVHeXi9obhhoiIyM7oKgvnhGIiIiKySbrKwjmhmIiIiGySrrJwTigmIiIim6RrnylOKCYiIiKbpGufKU4oJiIiIpvECcVERERkVzihmIiIiOwKh6WIiIjIrnBYioiIiOwKh6WIiIjIrnBYioiIiOwKh6WIiIjIrnBYioiIiOwKh6WIiIjIrnBYioiIiOxKYx+WamLtBhAREZFp6RqWOnlNicKyCoR6uyLAw36DDsMNERGRndE1LDVr0x8AAAcBSBoehriIYEs2y2I4LEVERGRndA1LqalEICHlJLKU9jnBmOGGiIjIzugalqpKFIFjV25YoDWWx3BDRERkZ3QNS9U8z8wNsRKGGyIiIjvTI8QLgh7n2Wv1FMMNERGRnQnwUGD+o2HSl7yuoGOvi/qxWoqIiMgOxUUEo287H1zOL8L53ALM+f7PGufY67AUww0REZGdCvBQIMBDARe59oEaDksRERGRTWpse00x3BAREdm5G0VlBh23dQw3REREds5T4ajjuNzCLbEMhhsiIiI719g20mS4ISIisnO65tykns6xyy0YGG6IiIjsnK65NR/uvoje83cj+UiGhVtkXgw3REREdk7XnBvAPjfRZLghIiKyc3XtEm5vm2gy3BAREdm5wrKKOs+xp7JwhhsiIiI7F+rtCgd9dtK0Ew0i3CxbtgwhISFwdnZGZGQkDh8+rPPcNWvWQBAEjR9nZ2cLtpaIiMi2BHgokDQ8DDJBd8KpuuZNlrIYBy/m2+w8HKvvLZWcnIz4+HisWLECkZGRWLx4MWJjY3H27Fn4+vpqvcbd3R1nz56VHgu1/GURERHRvxtppp7OwaxNf9R4XiF3wMGL+Th5VYkF289AJQIOApA0PAxxEcFWaLHxrB5uFi1ahAkTJmDcuHEAgBUrVmDLli34/PPPkZCQoPUaQRDg7+9vyWYSERHZvAAPBTxdtK9K/OzaozWOqSup+rbzQYCH7Sz4Z9VhqbKyMhw9ehQxMTHSMQcHB8TExODQoUM6r7t9+zZatmyJoKAgPPzww/jjj5oJVK20tBQFBQUaP0RERI2VoROHbbGSyqrhJj8/HxUVFfDz89M47ufnh+zsbK3XtG/fHp9//jm+//57fPnll1CpVOjVqxeuXr2q9fykpCR4eHhIP0FBQSb/HERERPbM1iqpGsSEYkNERUVh9OjR6Nq1K6Kjo5GSkgIfHx+sXLlS6/mJiYlQKpXST2ZmpoVbTERE1HDUtqCf7mtsa4NNq8658fb2hkwmQ05OjsbxnJwcvefUODo6olu3brhw4YLW552cnODk5FTvthIREdmDHiFeEACI1Y47AFDpuMbWNti0as+NXC5HeHg4UlNTpWMqlQqpqamIiorS6zUqKipw8uRJBAQEmKuZREREdiPAQ4H5j4ZJAcABwIJHw3AgcQBeuq+N1muu6th4s6GyerVUfHw8xowZgx49eqBnz55YvHgxCgsLpeqp0aNHIzAwEElJSQCAN998E//3f/+HNm3a4ObNm3jvvfdw5coVjB8/3pofg4iIyGaoy8Iv5xchxNtFqoTycdM+0mFrc26sHm7i4uKQl5eHOXPmIDs7G127dsX27dulScYZGRlwcPi3g+nGjRuYMGECsrOz0axZM4SHh+PgwYO45557rPURiIiIbE6Ah8KmyrsNIYiiWH3Yza4VFBTAw8MDSqUS7u7u1m4OERFRg/Hf/13GbC0L/L09rCOe+r8QyzeoCkO+v22uWoqIiIjMQ1clla1VSzHcEBEREQAg2MtF63FWSxEREZFNytRRFWVr1VIMN0RERARAd1XU5b8KNXYJb+i7hlu9WoqIiIgatvd2nANQuUv4I90C8d3xaw1613D23BAREZFeVCKw8VhlsFE/Tkg52eB6cBhuiIiIyGgNcddwhhsiIiICYNymmkDDW8GY4YaIiIgA/LuppqEu5t5uUENTDDdEREQEQPummo92D6wzLKw+eAW95+9G8pGMBlFJxe0XiIiISEOWslhjU03146MZf2PhP5VT2qh7fUSYvpLKkO9vloITERGRhuqbaqofX8i7Vet1VXtL1JVUfdv5WHyDTg5LERERkV4MnXBsrUoqhhsiIiLSizETjq1RScVwQ0RERHqpPuG4oeKcGyIiItJbXEQw+rbzweX8Ivx+9SYWbDsDlbUbVQ3DDRERERlEPcE4qnVzPNS1hV6VVJbEcENERERG07eSypIa+rAZERERkUEYboiIiMiuMNwQERGRXWG4ISIiIrvCcENERER2heGGiIiI7ArDDREREdkVhhsiIiKyKww3REREZFcYboiIiMiuMNwQERGRXWG4ISIionrzVDjqOC63cEsYboiIiMgEeoR4Qah2TAAQHtLM4m1huCEiIqJ6C/BQYP6jYVKwcAAw/9EwBHgoLN6WJhZ/RyIiIrJLcRHB6NvOB5fzixDi7WKVYAMw3BAREZEJBXgorBZq1DgsRURERHaF4YaIiIjsCsMNERER2RWGGyIiIrIrDDdERERkVxhuiIiIyK4w3BAREZFdYbghIiIiu8JwQ0RERHaF4YaIiIjsCsMNERER2ZVGt7eUKIoAgIKCAiu3hIiIiPSl/t5Wf4/XptGFm1u3bgEAgoKCrNwSIiIiMtStW7fg4eFR6zmCqE8EsiMqlQrXr1+Hm5sbBEEw6WsXFBQgKCgImZmZcHd3N+lr0794ny2D99kyeJ8th/faMsx1n0VRxK1bt9CiRQs4ONQ+q6bR9dw4ODjgrrvuMut7uLu78z8cC+B9tgzeZ8vgfbYc3mvLMMd9rqvHRo0TiomIiMiuMNwQERGRXWG4MSEnJyfMnTsXTk5O1m6KXeN9tgzeZ8vgfbYc3mvLaAj3udFNKCYiIiL7xp4bIiIisisMN0RERGRXGG6IiIjIrjDcEBERkV1huDHQsmXLEBISAmdnZ0RGRuLw4cO1nr9+/Xp06NABzs7OCAsLw9atWy3UUttmyH1etWoV+vTpg2bNmqFZs2aIiYmp8++FKhn6+6y2bt06CIKAYcOGmbeBdsLQ+3zz5k1MnjwZAQEBcHJyQrt27fj/HXow9D4vXrwY7du3h0KhQFBQEKZNm4aSkhILtdY27du3D0OHDkWLFi0gCAI2bdpU5zV79+5F9+7d4eTkhDZt2mDNmjVmbydE0tu6detEuVwufv755+Iff/whTpgwQfT09BRzcnK0nn/gwAFRJpOJ7777rvjnn3+Ks2bNEh0dHcWTJ09auOW2xdD7PHLkSHHZsmXi8ePHxdOnT4tjx44VPTw8xKtXr1q45bbF0Puslp6eLgYGBop9+vQRH374Ycs01oYZep9LS0vFHj16iIMHDxb3798vpqeni3v37hXT0tIs3HLbYuh9/uqrr0QnJyfxq6++EtPT08UdO3aIAQEB4rRp0yzcctuydetWcebMmWJKSooIQPzuu+9qPf/SpUuii4uLGB8fL/7555/iRx99JMpkMnH79u1mbSfDjQF69uwpTp48WXpcUVEhtmjRQkxKStJ6/ogRI8QhQ4ZoHIuMjBQnTpxo1nbaOkPvc3Xl5eWim5ubuHbtWnM10S4Yc5/Ly8vFXr16iZ9++qk4ZswYhhs9GHqfly9fLrZq1UosKyuzVBPtgqH3efLkyeKAAQM0jsXHx4u9e/c2azvtiT7h5tVXXxU7duyocSwuLk6MjY01Y8tEkcNSeiorK8PRo0cRExMjHXNwcEBMTAwOHTqk9ZpDhw5pnA8AsbGxOs8n4+5zdUVFRbhz5w68vLzM1UybZ+x9fvPNN+Hr64tnn33WEs20ecbc582bNyMqKgqTJ0+Gn58fOnXqhHnz5qGiosJSzbY5xtznXr164ejRo9LQ1aVLl7B161YMHjzYIm1uLKz1PdjoNs40Vn5+PioqKuDn56dx3M/PD2fOnNF6TXZ2ttbzs7OzzdZOW2fMfa7utddeQ4sWLWr8B0X/MuY+79+/H5999hnS0tIs0EL7YMx9vnTpEnbv3o1Ro0Zh69atuHDhAiZNmoQ7d+5g7ty5lmi2zTHmPo8cORL5+fm49957IYoiysvL8fzzz2PGjBmWaHKjoet7sKCgAMXFxVAoFGZ5X/bckF2ZP38+1q1bh++++w7Ozs7Wbo7duHXrFp5++mmsWrUK3t7e1m6OXVOpVPD19cUnn3yC8PBwxMXFYebMmVixYoW1m2ZX9u7di3nz5uHjjz/GsWPHkJKSgi1btuCtt96ydtPIBNhzoydvb2/IZDLk5ORoHM/JyYG/v7/Wa/z9/Q06n4y7z2oLFy7E/PnzsWvXLnTu3NmczbR5ht7nixcv4vLlyxg6dKh0TKVSAQCaNGmCs2fPonXr1uZttA0y5vc5ICAAjo6OkMlk0rG7774b2dnZKCsrg1wuN2ubbZEx93n27Nl4+umnMX78eABAWFgYCgsL8dxzz2HmzJlwcOC//U1B1/egu7u72XptAPbc6E0ulyM8PBypqanSMZVKhdTUVERFRWm9JioqSuN8ANi5c6fO88m4+wwA7777Lt566y1s374dPXr0sERTbZqh97lDhw44efIk0tLSpJ+HHnoI/fv3R1paGoKCgizZfJthzO9z7969ceHCBSk8AsC5c+cQEBDAYKODMfe5qKioRoBRB0qRWy6ajNW+B806XdnOrFu3TnRychLXrFkj/vnnn+Jzzz0nenp6itnZ2aIoiuLTTz8tJiQkSOcfOHBAbNKkibhw4ULx9OnT4ty5c1kKrgdD7/P8+fNFuVwubtiwQczKypJ+bt26Za2PYBMMvc/VsVpKP4be54yMDNHNzU2cMmWKePbsWfHHH38UfX19xbfffttaH8EmGHqf586dK7q5uYnffPONeOnSJfGnn34SW7duLY4YMcJaH8Em3Lp1Szx+/Lh4/PhxEYC4aNEi8fjx4+KVK1dEURTFhIQE8emnn5bOV5eC/+c//xFPnz4tLlu2jKXgDdFHH30kBgcHi3K5XOzZs6f4v//9T3ouOjpaHDNmjMb53377rdiuXTtRLpeLHTt2FLds2WLhFtsmQ+5zy5YtRQA1fubOnWv5htsYQ3+fq2K40Z+h9/ngwYNiZGSk6OTkJLZq1Up85513xPLycgu32vYYcp/v3Lkjvv7662Lr1q1FZ2dnMSgoSJw0aZJ448YNyzfchuzZs0fr/9+q7+2YMWPE6OjoGtd07dpVlMvlYqtWrcTVq1ebvZ2CKLL/jYiIiOwH59wQERGRXWG4ISIiIrvCcENERER2heGGiIiI7ArDDREREdkVhhsiIiKyKww3REREZFcYboiIAAiCgE2bNgEALl++DEEQuAM6kY1iuCEiqxs7diwEQYAgCHB0dERoaCheffVVlJSUWLtpRGSDuCs4ETUIAwcOxOrVq3Hnzh0cPXoUY8aMgSAIWLBggbWbRkQ2hj03RNQgODk5wd/fH0FBQRg2bBhiYmKwc+dOAJU7PCclJSE0NBQKhQJdunTBhg0bNK7/448/8OCDD8Ld3R1ubm7o06cPLl68CAA4cuQI7r//fnh7e8PDwwPR0dE4duyYxT8jEVkGww0RNTinTp3CwYMHIZfLAQBJSUn44osvsGLFCvzxxx+YNm0annrqKfz8888AgGvXrqFv375wcnLC7t27cfToUTzzzDMoLy8HANy6dQtjxozB/v378b///Q9t27bF4MGDcevWLat9RiIyHw5LEVGD8OOPP6Jp06YoLy9HaWkpHBwcsHTpUpSWlmLevHnYtWsXoqKiAACtWrXC/v37sXLlSkRHR2PZsmXw8PDAunXr4OjoCABo166d9NoDBgzQeK9PPvkEnp6e+Pnnn/Hggw9a7kMSkUUw3BBRg9C/f38sX74chYWF+OCDD9CkSRM8+uij+OOPP1BUVIT7779f4/yysjJ069YNAJCWloY+ffpIwaa6nJwczJo1C3v37kVubi4qKipQVFSEjIwMs38uIrI8hhsiahBcXV3Rpk0bAMDnn3+OLl264LPPPkOnTp0AAFu2bEFgYKDGNU5OTgAAhUJR62uPGTMGf/31F5YsWYKWLVvCyckJUVFRKCsrM8MnISJrY7ghogbHwcEBM2bMQHx8PM6dOwcnJydkZGQgOjpa6/mdO3fG2rVrcefOHa29NwcOHMDHH3+MwYMHAwAyMzORn59v1s9ARNbDCcVE1CA9/vjjkMlkWLlyJaZPn45p06Zh7dq1uHjxIo4dO4aPPvoIa9euBQBMmTIFBQUFeOKJJ/Dbb7/h/Pnz+O9//4uzZ88CANq2bYv//ve/OH36NH799VeMGjWqzt4eIrJd7LkhogapSZMmmDJlCt59912kp6fDx8cHSUlJuHTpEjw9PdG9e3fMmDEDANC8eXPs3r0b//nPfxAdHQ2ZTIauXbuid+/eAIDPPvsMzz33HLp3746goCDMmzcP06dPt+bHIyIzEkRRFK3dCCIiIiJT4bAUERER2RWGGyIiIrIrDDdERERkVxhuiIiIyK4w3BAREZFdYbghIiIiu8JwQ0RERHaF4YaIiIjsCsMNERER2RWGGyIiIrIrDDdERERkVxhuiIiIyK78P/RTCADRpFihAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert probabilities to binary class predictions\n",
        "y_pred_classes = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_classes)\n",
        "\n",
        "# Display confusion matrix using sklearn's visualization tool\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "oQDaopCLuvBU",
        "outputId": "73f7cfd2-1495-43e6-a382-1b682c0beaa7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAHHCAYAAAC4M/EEAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAPFZJREFUeJzt3X98zvX+x/HndY1dm9kPI5tpZn7kR0QoXz/y47RIEanjKJ1GfnROKRHhnIihnUOhIfTLj6LSL0WlRFLZkV9TSRgrio2sbTb2w/b5/uHsOl1G7XJd1y67Po+72+f27Xp/3p/P53Xt+Hrt9X6/P5+PxTAMQwAAwGdZvR0AAADwLJI9AAA+jmQPAICPI9kDAODjSPYAAPg4kj0AAD6OZA8AgI8j2QMA4ONI9gAA+DiSPXCeAwcOqEePHgoNDZXFYtHq1avdev4ffvhBFotFS5cudet5K7Nu3bqpW7du3g4D8Fkke1yWDh48qPvvv18NGjRQQECAQkJC1KlTJz3zzDM6c+aMR68dHx+vb775RjNmzNDLL7+sdu3aefR6FWnw4MGyWCwKCQm54M/xwIEDslgsslgseuqpp5w+/9GjRzVlyhSlpKS4IVoA7lLF2wEA53v//ff15z//WTabTffee69atGihwsJCffHFFxo3bpz27Nmj5557ziPXPnPmjJKTk/XPf/5TI0eO9Mg1YmJidObMGVWtWtUj5/8jVapU0enTp7VmzRoNGDDAYd+KFSsUEBCg/Pz8Szr30aNHNXXqVNWvX1+tW7cu93Eff/zxJV0PQPmQ7HFZSUtL08CBAxUTE6ONGzeqTp069n0PPvigUlNT9f7773vs+idOnJAkhYWFeewaFotFAQEBHjv/H7HZbOrUqZNeffXVMsl+5cqVuvXWW/XWW29VSCynT59WtWrV5O/vXyHXA8yKYXxcVmbOnKnc3Fy9+OKLDom+VKNGjTRq1Cj757Nnz2ratGlq2LChbDab6tevr3/84x8qKChwOK5+/frq3bu3vvjiC11//fUKCAhQgwYNtHz5cnufKVOmKCYmRpI0btw4WSwW1a9fX9K54e/S//6tKVOmyGKxOLStX79enTt3VlhYmKpXr64mTZroH//4h33/xebsN27cqBtuuEFBQUEKCwtT3759tXfv3gteLzU1VYMHD1ZYWJhCQ0M1ZMgQnT59+uI/2PPcfffd+vDDD5WVlWVv27Ztmw4cOKC77767TP/MzEyNHTtWLVu2VPXq1RUSEqJevXpp9+7d9j6bNm3SddddJ0kaMmSIfTqg9Ht269ZNLVq00I4dO9SlSxdVq1bN/nM5f84+Pj5eAQEBZb5/z549VaNGDR09erTc3xUAyR6XmTVr1qhBgwbq2LFjufoPGzZMkydPVps2bTRnzhx17dpViYmJGjhwYJm+qampuvPOO3XTTTfp6aefVo0aNTR48GDt2bNHktS/f3/NmTNHknTXXXfp5Zdf1ty5c52Kf8+ePerdu7cKCgqUkJCgp59+Wrfddpu+/PLL3z3uk08+Uc+ePXX8+HFNmTJFY8aM0ZYtW9SpUyf98MMPZfoPGDBAp06dUmJiogYMGKClS5dq6tSp5Y6zf//+slgsevvtt+1tK1euVNOmTdWmTZsy/Q8dOqTVq1erd+/emj17tsaNG6dvvvlGXbt2tSfeZs2aKSEhQZI0YsQIvfzyy3r55ZfVpUsX+3lOnjypXr16qXXr1po7d666d+9+wfieeeYZXXHFFYqPj1dxcbEkafHixfr44481b948RUVFlfu7ApBkAJeJ7OxsQ5LRt2/fcvVPSUkxJBnDhg1zaB87dqwhydi4caO9LSYmxpBkbN682d52/Phxw2azGY8++qi9LS0tzZBkzJo1y+Gc8fHxRkxMTJkYnnjiCeO3/280Z84cQ5Jx4sSJi8Zdeo0lS5bY21q3bm3Url3bOHnypL1t9+7dhtVqNe69994y17vvvvscznn77bcbNWvWvOg1f/s9goKCDMMwjDvvvNO48cYbDcMwjOLiYiMyMtKYOnXqBX8G+fn5RnFxcZnvYbPZjISEBHvbtm3byny3Ul27djUkGYsWLbrgvq5duzq0ffTRR4YkY/r06cahQ4eM6tWrG/369fvD7wigLCp7XDZycnIkScHBweXq/8EHH0iSxowZ49D+6KOPSlKZuf3mzZvrhhtusH++4oor1KRJEx06dOiSYz5f6Vz/u+++q5KSknIdc+zYMaWkpGjw4MEKDw+3t19zzTW66aab7N/zt/72t785fL7hhht08uRJ+8+wPO6++25t2rRJ6enp2rhxo9LT0y84hC+dm+e3Ws/9c1FcXKyTJ0/apyh27txZ7mvabDYNGTKkXH179Oih+++/XwkJCerfv78CAgK0ePHicl8LwP+Q7HHZCAkJkSSdOnWqXP1//PFHWa1WNWrUyKE9MjJSYWFh+vHHHx3a69WrV+YcNWrU0K+//nqJEZf1l7/8RZ06ddKwYcMUERGhgQMHatWqVb+b+EvjbNKkSZl9zZo10y+//KK8vDyH9vO/S40aNSTJqe9yyy23KDg4WK+//rpWrFih6667rszPslRJSYnmzJmjxo0by2azqVatWrriiiv09ddfKzs7u9zXrFu3rlOL8Z566imFh4crJSVFSUlJql27drmPBfA/JHtcNkJCQhQVFaVvv/3WqePOXyB3MX5+fhdsNwzjkq9ROp9cKjAwUJs3b9Ynn3yiv/71r/r666/1l7/8RTfddFOZvq5w5buUstls6t+/v5YtW6Z33nnnolW9JD355JMaM2aMunTpoldeeUUfffSR1q9fr6uvvrrcIxjSuZ+PM3bt2qXjx49Lkr755hunjgXwPyR7XFZ69+6tgwcPKjk5+Q/7xsTEqKSkRAcOHHBoz8jIUFZWln1lvTvUqFHDYeV6qfNHDyTJarXqxhtv1OzZs/Xdd99pxowZ2rhxoz799NMLnrs0zn379pXZ9/3336tWrVoKCgpy7QtcxN13361du3bp1KlTF1zUWOrNN99U9+7d9eKLL2rgwIHq0aOH4uLiyvxMyvuLV3nk5eVpyJAhat68uUaMGKGZM2dq27Ztbjs/YCYke1xWHnvsMQUFBWnYsGHKyMgos//gwYN65plnJJ0bhpZUZsX87NmzJUm33nqr2+Jq2LChsrOz9fXXX9vbjh07pnfeecehX2ZmZpljSx8uc/7tgKXq1Kmj1q1ba9myZQ7J89tvv9XHH39s/56e0L17d02bNk3z589XZGTkRfv5+fmVGTV444039PPPPzu0lf5ScqFfjJw1fvx4HT58WMuWLdPs2bNVv359xcfHX/TnCODieKgOLisNGzbUypUr9Ze//EXNmjVzeILeli1b9MYbb2jw4MGSpFatWik+Pl7PPfecsrKy1LVrV3311VdatmyZ+vXrd9Hbui7FwIEDNX78eN1+++16+OGHdfr0aS1cuFBXXXWVwwK1hIQEbd68WbfeeqtiYmJ0/PhxPfvss7ryyivVuXPni55/1qxZ6tWrlzp06KChQ4fqzJkzmjdvnkJDQzVlyhS3fY/zWa1WPf7443/Yr3fv3kpISNCQIUPUsWNHffPNN1qxYoUaNGjg0K9hw4YKCwvTokWLFBwcrKCgILVv316xsbFOxbVx40Y9++yzeuKJJ+y3Ai5ZskTdunXTpEmTNHPmTKfOB5iel+8GAC5o//79xvDhw4369esb/v7+RnBwsNGpUydj3rx5Rn5+vr1fUVGRMXXqVCM2NtaoWrWqER0dbUycONGhj2Gcu/Xu1ltvLXOd82/5utitd4ZhGB9//LHRokULw9/f32jSpInxyiuvlLn1bsOGDUbfvn2NqKgow9/f34iKijLuuusuY//+/WWucf7taZ988onRqVMnIzAw0AgJCTH69OljfPfddw59Sq93/q19S5YsMSQZaWlpF/2ZGobjrXcXc7Fb7x599FGjTp06RmBgoNGpUycjOTn5grfMvfvuu0bz5s2NKlWqOHzPrl27GldfffUFr/nb8+Tk5BgxMTFGmzZtjKKiIod+o0ePNqxWq5GcnPy73wGAI4thOLGiBwAAVDrM2QMA4ONI9gAA+DiSPQAAPo5kDwCAjyPZAwDg40j2AAD4uEr9UJ2SkhIdPXpUwcHBbn1MJwCgYhiGoVOnTikqKsr+ZkVPyM/PV2Fhocvn8ff3V0BAgBsiqliVOtkfPXpU0dHR3g4DAOCiI0eO6Morr/TIufPz8xUYXFM6e9rlc0VGRiotLa3SJfxKnexL33vu3zxeFr/yvzYTqEwOb3rK2yEAHnMqJ0eNYqPt/557QmFhoXT2tGzN4yVXckVxodK/W6bCwkKSfUUqHbq3+PmT7OGzQkJCvB0C4HEVMhVbJcClXGFYKu8yt0qd7AEAKDeLJFd+qajES8NI9gAAc7BYz22uHF9JVd7IAQBAuVDZAwDMwWJxcRi/8o7jk+wBAObAMD4AAPBVVPYAAHNgGB8AAF/n4jB+JR4Mr7yRAwCAcqGyBwCYA8P4AAD4OFbjAwAAX0VlDwAwB4bxAQDwcSYexifZAwDMwcSVfeX9NQUAAJQLlT0AwBwYxgcAwMdZLC4me4bxAQDAZYrKHgBgDlbLuc2V4yspkj0AwBxMPGdfeSMHAADlQmUPADAHE99nT7IHAJgDw/gAAMBXUdkDAMyBYXwAAHyciYfxSfYAAHMwcWVfeX9NAQAA5UJlDwAwB4bxAQDwcQzjAwAAX0VlDwAwCReH8StxfUyyBwCYA8P4AADAV1HZAwDMwWJxcTV+5a3sSfYAAHMw8a13lTdyAABQLlT2AABzMPECPZI9AMAcTDyMT7IHAJiDiSv7yvtrCgAAKBcqewCAOZh4GL/yRg4AgDNKh/Fd2ZywefNm9enTR1FRUbJYLFq9erV9X1FRkcaPH6+WLVsqKChIUVFRuvfee3X06FGHc2RmZmrQoEEKCQlRWFiYhg4dqtzcXKe/OskeAAAPyMvLU6tWrbRgwYIy+06fPq2dO3dq0qRJ2rlzp95++23t27dPt912m0O/QYMGac+ePVq/fr3Wrl2rzZs3a8SIEU7HwjA+AMAULBaLLBW4QK9Xr17q1avXBfeFhoZq/fr1Dm3z58/X9ddfr8OHD6tevXrau3ev1q1bp23btqldu3aSpHnz5umWW27RU089paioqHLHQmUPADCF0mTvyuZJ2dnZslgsCgsLkyQlJycrLCzMnuglKS4uTlarVVu3bnXq3FT2AAA4IScnx+GzzWaTzWZz6Zz5+fkaP3687rrrLoWEhEiS0tPTVbt2bYd+VapUUXh4uNLT0506P5U9AMAcLG7YJEVHRys0NNS+JSYmuhRWUVGRBgwYIMMwtHDhQpfOdTFU9gAAU3DXnP2RI0fs1bckl6r60kT/448/auPGjQ7njYyM1PHjxx36nz17VpmZmYqMjHTqOlT2AAA4ISQkxGG71GRfmugPHDigTz75RDVr1nTY36FDB2VlZWnHjh32to0bN6qkpETt27d36lpU9gAAU6jo1fi5ublKTU21f05LS1NKSorCw8NVp04d3Xnnndq5c6fWrl2r4uJi+zx8eHi4/P391axZM918880aPny4Fi1apKKiIo0cOVIDBw50aiW+RLIHAJhERSf77du3q3v37vbPY8aMkSTFx8drypQpeu+99yRJrVu3djju008/Vbdu3SRJK1as0MiRI3XjjTfKarXqjjvuUFJSktOhk+wBAKZQ0cm+W7duMgzjovt/b1+p8PBwrVy50qnrXghz9gAA+DgqewCAOfzm9rlLPr6SItkDAEyhoofxLycM4wMA4OOo7AEApnDuLbWuVPbui6WikewBAKZgkasvs6m82Z5hfAAAfByVPQDAFMy8QI9kDwAwBxPfescwPgAAPo7KHgBgDi4O4xsM4wMAcHlzdc7etZX83kWyBwCYgpmTPXP2AAD4OCp7AIA5mHg1PskeAGAKDOMDAACfRWUPADAFM1f2JHsAgCmYOdkzjA8AgI+jsgcAmIKZK3uSPQDAHEx86x3D+AAA+DgqewCAKTCMDwCAjyPZAwDg48yc7JmzBwDAx1HZAwDMwcSr8Un2AABTYBgfAAD4LCp7qOO1DfXQX+PUqmk91bkiVIPGPqcPPvvavn/88FvUv0cb1Y2ooaKiYqV8f1jTn12jHXt+tPfZ/e5U1Yuq6XDeqfPf1dxl6yvsewDlNXvJR1r76W4d+DFDAbaquv6aBpoysq8a14+w9+l9/1x9uTPV4bjB/TtpzsS7KjpcuImZK/vLItkvWLBAs2bNUnp6ulq1aqV58+bp+uuv93ZYplEt0KZv9/+sV95L1iuzRpTZf/DwcT026w398PMvCrRV1d/v+pPenj9SbW6fqpNZufZ+Mxat1fLVX9o/5+YVVEj8gLO27EzVsD930bXNY3S2uFjTnl2j/g/N139WPa6gQJu9X3y/jpp4f2/758CAqt4IF25ikYvJvhJP2ns92b/++usaM2aMFi1apPbt22vu3Lnq2bOn9u3bp9q1a3s7PFP4ZMt3+mTLdxfd/+ZH2x0+Pz73bd3br6Oubhylzdv229tzT+fr+MlTHosTcJc35z3o8PnZJ+5R4x4TlbL3iDq1aWRvDwzwV0StkIoOD3A7r8/Zz549W8OHD9eQIUPUvHlzLVq0SNWqVdNLL73k7dBwAVWr+Cn+9k7KPnVa3+7/2WHfI/E9dHD9v/XZK+P10D03ys/P63+9gHLJyc2XJNUIqebQ/sa67WoYN14d/jJDU+e/q9P5hd4ID25SOozvylZZebWyLyws1I4dOzRx4kR7m9VqVVxcnJKTk70YGc7Xs3MLvTBjiKoFVFX6Lzm6feR8ZWbn2fcvfv0z7f7+iLJy8nT9NQ00+cHbFFErVI/PfduLUQN/rKSkRBNnv6n2rRqoeaMoe/udPdspuk64Iq8I1Z4DRzV1/rtK/fG4Xp413IvRwiXceucdv/zyi4qLixUREeHQHhERoe+//75M/4KCAhUU/G8eOCcnx+Mx4pzPt+9Xl0GJqhlWXff266glT96nuCFP6Zdfz83ZP7tyo73vntSjKiw6qzn/uEsJC95TYdFZb4UN/KGxM1dp78Fj+vD50Q7tg/t3tv/31Y3qKrJWiPo+ME9pP51Q7JVXVHSYgEsq1ThrYmKiQkND7Vt0dLS3QzKN0/mFSvvpF23/9gc9PH2lzhaX6K99O160/449P6hqFT/ViwqvwCgB54ybuUofff6t1ix8WHUjavxu37Yt6kuSDh05UQGRwRPMPIzv1WRfq1Yt+fn5KSMjw6E9IyNDkZGRZfpPnDhR2dnZ9u3IkSMVFSrOY7Va5F/14gNDLa+6UsXFJTqRyYI9XH4Mw9C4mav0/qbdem/hw4qpW+sPj/lm/0+SpIhaoZ4ODx5i5mTv1WF8f39/tW3bVhs2bFC/fv0knZs/27Bhg0aOHFmmv81mk81mK9MO1wQF+is2+n/DkjFRNdXiqrrKyj6tzOw8PXpfT324+Rtl/JKt8LDqGvbnLqpzRZje3bBTknRdy1i1bRGjL7Yf0KnT+bq+ZaxmjL5Dqz7cpuxTZ7z1tYCLGvvvVXrzo+1a+dQIVa8WoIxfzk0JhlQPUGCAv9J+OqE3123XTZ2uVnhokL498LP+Oedtdby2kVo0ruvl6HGpLJZzmyvHV1Zev/VuzJgxio+PV7t27XT99ddr7ty5ysvL05AhQ7wdmmm0bhajtYtH2T8/OeYOSdLKtf/RmMTX1Lh+hAbe2l41w4KUmX1au777UbeMmKPvD6VLkgoKi9T/praaMPwW+Vetoh+PntTCVz/VghUbL3g9wNteeutzSVLvvz3j0L5g8j26u8//qWqVKtr01T4tfO1TnT5TqLoRNdTnT6019r6e3ggXcJnFMAzD20HMnz/f/lCd1q1bKykpSe3bt//D43JychQaGipby+Gy+PlXQKRAxft123xvhwB4TE5OjiJqhio7O1shIZ55pkFprmjw0Juy2oIu+TwlBXk6NO9Oj8bqKV6v7CVp5MiRFxy2BwDAbVwcxq/Mt95VqtX4AADAeZdFZQ8AgKfxIhwAAHycmVfjM4wPAICPo7IHAJiC1WqR1Xrp5bnhwrHeRrIHAJgCw/gAAMBnUdkDAEyB1fgAAPg4Mw/jk+wBAKZg5sqeOXsAAHwclT0AwBTMXNmT7AEApmDmOXuG8QEA8HEkewCAKVhksQ/lX9Lm5DtuN2/erD59+igqKkoWi0WrV6922G8YhiZPnqw6deooMDBQcXFxOnDggEOfzMxMDRo0SCEhIQoLC9PQoUOVm5vr9Hcn2QMATKF0GN+VzRl5eXlq1aqVFixYcMH9M2fOVFJSkhYtWqStW7cqKChIPXv2VH5+vr3PoEGDtGfPHq1fv15r167V5s2bNWLECKe/O3P2AAB4QK9evdSrV68L7jMMQ3PnztXjjz+uvn37SpKWL1+uiIgIrV69WgMHDtTevXu1bt06bdu2Te3atZMkzZs3T7fccoueeuopRUVFlTsWKnsAgCm4NITv4kr+86WlpSk9PV1xcXH2ttDQULVv317JycmSpOTkZIWFhdkTvSTFxcXJarVq69atTl2Pyh4AYAruWo2fk5Pj0G6z2WSz2Zw6V3p6uiQpIiLCoT0iIsK+Lz09XbVr13bYX6VKFYWHh9v7lBeVPQAAToiOjlZoaKh9S0xM9HZIf4jKHgBgCu56qM6RI0cUEhJib3e2qpekyMhISVJGRobq1Kljb8/IyFDr1q3tfY4fP+5w3NmzZ5WZmWk/vryo7AEApuCu1fghISEO26Uk+9jYWEVGRmrDhg32tpycHG3dulUdOnSQJHXo0EFZWVnasWOHvc/GjRtVUlKi9u3bO3U9KnsAgClU9ONyc3NzlZqaav+clpamlJQUhYeHq169enrkkUc0ffp0NW7cWLGxsZo0aZKioqLUr18/SVKzZs108803a/jw4Vq0aJGKioo0cuRIDRw40KmV+BLJHgAAj9i+fbu6d+9u/zxmzBhJUnx8vJYuXarHHntMeXl5GjFihLKystS5c2etW7dOAQEB9mNWrFihkSNH6sYbb5TVatUdd9yhpKQkp2Mh2QMAzMHF1fhOPkBP3bp1k2EYFz+dxaKEhAQlJCRctE94eLhWrlzp3IUvgGQPADAFM7/1jgV6AAD4OCp7AIApmPkVtyR7AIApMIwPAAB8FpU9AMAUGMYHAMDHMYwPAAB8FpU9AMAUzFzZk+wBAKbAnD0AAD7OzJU9c/YAAPg4KnsAgCkwjA8AgI9jGB8AAPgsKnsAgClY5OIwvtsiqXgkewCAKVgtFlldyPauHOttDOMDAODjqOwBAKbAanwAAHycmVfjk+wBAKZgtZzbXDm+smLOHgAAH0dlDwAwB4uLQ/GVuLIn2QMATMHMC/QYxgcAwMdR2QMATMHy3z+uHF9ZkewBAKbAanwAAOCzqOwBAKbAQ3X+wHvvvVfuE952222XHAwAAJ5i5tX45Ur2/fr1K9fJLBaLiouLXYkHAAC4WbmSfUlJiafjAADAo8z8iluX5uzz8/MVEBDgrlgAAPAYMw/jO70av7i4WNOmTVPdunVVvXp1HTp0SJI0adIkvfjii24PEAAAdyhdoOfKVlk5nexnzJihpUuXaubMmfL397e3t2jRQi+88IJbgwMAAK5zOtkvX75czz33nAYNGiQ/Pz97e6tWrfT999+7NTgAANyldBjfla2ycnrO/ueff1ajRo3KtJeUlKioqMgtQQEA4G5mXqDndGXfvHlzff7552Xa33zzTV177bVuCQoAALiP05X95MmTFR8fr59//lklJSV6++23tW/fPi1fvlxr1671RIwAALjMItdeSV956/pLqOz79u2rNWvW6JNPPlFQUJAmT56svXv3as2aNbrppps8ESMAAC4z82r8S7rP/oYbbtD69evdHQsAAPCAS36ozvbt27V3715J5+bx27Zt67agAABwNzO/4tbpZP/TTz/prrvu0pdffqmwsDBJUlZWljp27KjXXntNV155pbtjBADAZWZ+653Tc/bDhg1TUVGR9u7dq8zMTGVmZmrv3r0qKSnRsGHDPBEjAABwgdOV/WeffaYtW7aoSZMm9rYmTZpo3rx5uuGGG9waHAAA7lSJi3OXOJ3so6OjL/jwnOLiYkVFRbklKAAA3I1hfCfMmjVLDz30kLZv325v2759u0aNGqWnnnrKrcEBAOAupQv0XNkqq3JV9jVq1HD4jSYvL0/t27dXlSrnDj979qyqVKmi++67T/369fNIoAAA4NKUK9nPnTvXw2EAAOBZZh7GL1eyj4+P93QcAAB4lJkfl3vJD9WRpPz8fBUWFjq0hYSEuBQQAABwL6eTfV5ensaPH69Vq1bp5MmTZfYXFxe7JTAAANyJV9w64bHHHtPGjRu1cOFC2Ww2vfDCC5o6daqioqK0fPlyT8QIAIDLLBbXt8rK6cp+zZo1Wr58ubp166YhQ4bohhtuUKNGjRQTE6MVK1Zo0KBBnogTAABcIqcr+8zMTDVo0EDSufn5zMxMSVLnzp21efNm90YHAICbmPkVt04n+wYNGigtLU2S1LRpU61atUrSuYq/9MU4AABcbsw8jO90sh8yZIh2794tSZowYYIWLFiggIAAjR49WuPGjXN7gAAAwDVOJ/vRo0fr4YcfliTFxcXp+++/18qVK7Vr1y6NGjXK7QECAOAOpavxXdmcUVxcrEmTJik2NlaBgYFq2LChpk2bJsMw7H0Mw9DkyZNVp04dBQYGKi4uTgcOHHD3V3ftPntJiomJUUxMjDtiAQDAY1wdinf22H//+99auHChli1bpquvvlrbt2/XkCFDFBoaai+aZ86cqaSkJC1btkyxsbGaNGmSevbsqe+++04BAQGXHux5ypXsk5KSyn3C0i8AAMDlpKIfl7tlyxb17dtXt956qySpfv36evXVV/XVV19JOlfVz507V48//rj69u0rSVq+fLkiIiK0evVqDRw48JJjPV+5kv2cOXPKdTKLxUKyBwD4tJycHIfPNptNNputTL+OHTvqueee0/79+3XVVVdp9+7d+uKLLzR79mxJUlpamtLT0xUXF2c/JjQ0VO3bt1dycnLFJ/vS1feXqy/enKrqwTymF77pwbe+8XYIgMcUns6tsGtZdQkL1c47XpKio6Md2p944glNmTKlTP8JEyYoJydHTZs2lZ+fn4qLizVjxgz782jS09MlSREREQ7HRURE2Pe5i8tz9gAAVAbuGsY/cuSIw3tgLlTVS9KqVau0YsUKrVy5UldffbVSUlL0yCOPKCoqqsJfMEeyBwDACSEhIeV66du4ceM0YcIE+3B8y5Yt9eOPPyoxMVHx8fGKjIyUJGVkZKhOnTr24zIyMtS6dWu3xuzKiAYAAJWGxSJZXdicHRQ4ffq0rFbHNOvn56eSkhJJUmxsrCIjI7Vhwwb7/pycHG3dulUdOnRw+fv+FpU9AMAUSpO2K8c7o0+fPpoxY4bq1aunq6++Wrt27dLs2bN13333STo3LfDII49o+vTpaty4sf3Wu6ioKPXr1+/SA70Akj0AAB4wb948TZo0SQ888ICOHz+uqKgo3X///Zo8ebK9z2OPPaa8vDyNGDFCWVlZ6ty5s9atW+fWe+ylS0z2n3/+uRYvXqyDBw/qzTffVN26dfXyyy8rNjZWnTt3dmuAAAC4Q0XfZx8cHKy5c+dq7ty5v3vOhIQEJSQkXHJc5eH0nP1bb72lnj17KjAwULt27VJBQYEkKTs7W08++aTbAwQAwB1cma93dQrA25xO9tOnT9eiRYv0/PPPq2rVqvb2Tp06aefOnW4NDgAAuM7pYfx9+/apS5cuZdpDQ0OVlZXljpgAAHC7in42/uXE6co+MjJSqampZdq/+OILNWjQwC1BAQDgbhX91rvLidPJfvjw4Ro1apS2bt0qi8Wio0ePasWKFRo7dqz+/ve/eyJGAABcZnXDVlk5PYw/YcIElZSU6MYbb9Tp06fVpUsX2Ww2jR07Vg899JAnYgQAAC5wOtlbLBb985//1Lhx45Samqrc3Fw1b95c1atX90R8AAC4hZnn7C/5oTr+/v5q3ry5O2MBAMBjrHJt3t2qypvtnU723bt3/90HC2zcuNGlgAAAgHs5nezPfxNPUVGRUlJS9O2331b4K/sAACgvhvGdMGfOnAu2T5kyRbm5uS4HBACAJ1T0i3AuJ267k+Cee+7RSy+95K7TAQAAN3HbW++Sk5Pd/pYeAADc5dz77F15EY4bg6lgTif7/v37O3w2DEPHjh3T9u3bNWnSJLcFBgCAOzFn74TQ0FCHz1arVU2aNFFCQoJ69OjhtsAAAIB7OJXsi4uLNWTIELVs2VI1atTwVEwAALgdC/TKyc/PTz169ODtdgCASsfihj+VldOr8Vu0aKFDhw55IhYAADymtLJ3ZausnE7206dP19ixY7V27VodO3ZMOTk5DhsAALi8lHvOPiEhQY8++qhuueUWSdJtt93m8NhcwzBksVhUXFzs/igBAHCRmefsy53sp06dqr/97W/69NNPPRkPAAAeYbFYfvfdLuU5vrIqd7I3DEOS1LVrV48FAwAA3M+pW+8q8281AABzYxi/nK666qo/TPiZmZkuBQQAgCfwBL1ymjp1apkn6AEAgMubU8l+4MCBql27tqdiAQDAY6wWi0svwnHlWG8rd7Jnvh4AUJmZec6+3A/VKV2NDwAAKpdyV/YlJSWejAMAAM9ycYFeJX40vvOvuAUAoDKyyiKrCxnblWO9jWQPADAFM9965/SLcAAAQOVCZQ8AMAUzr8Yn2QMATMHM99kzjA8AgI+jsgcAmIKZF+iR7AEApmCVi8P4lfjWO4bxAQDwcVT2AABTYBgfAAAfZ5Vrw9mVeSi8MscOAADKgcoeAGAKFovFpde1V+ZXvZPsAQCmYJFrL66rvKmeZA8AMAmeoAcAAHwWlT0AwDQqb23uGpI9AMAUzHyfPcP4AAD4OCp7AIApcOsdAAA+jifoAQAAn0VlDwAwBYbxAQDwcWZ+gh7D+AAA+DgqewCAKTCMDwCAj2M1PgAAPq60sndlc9bPP/+se+65RzVr1lRgYKBatmyp7du32/cbhqHJkyerTp06CgwMVFxcnA4cOODOry2JZA8AgEf8+uuv6tSpk6pWraoPP/xQ3333nZ5++mnVqFHD3mfmzJlKSkrSokWLtHXrVgUFBalnz57Kz893aywM4wMATKGiV+P/+9//VnR0tJYsWWJvi42Ntf+3YRiaO3euHn/8cfXt21eStHz5ckVERGj16tUaOHCgC9E6orIHAJhC6YtwXNkkKScnx2ErKCi44PXee+89tWvXTn/+859Vu3ZtXXvttXr++eft+9PS0pSenq64uDh7W2hoqNq3b6/k5GS3fneSPQAAToiOjlZoaKh9S0xMvGC/Q4cOaeHChWrcuLE++ugj/f3vf9fDDz+sZcuWSZLS09MlSREREQ7HRURE2Pe5C8P4AABTsMoiqwsD+aXHHjlyRCEhIfZ2m812wf4lJSVq166dnnzySUnStddeq2+//VaLFi1SfHz8JcdxKajsAQCm4K5h/JCQEIftYsm+Tp06at68uUNbs2bNdPjwYUlSZGSkJCkjI8OhT0ZGhn2fu5DsAQDwgE6dOmnfvn0Obfv371dMTIykc4v1IiMjtWHDBvv+nJwcbd26VR06dHBrLAzjAwBMwfLfP64c74zRo0erY8eOevLJJzVgwAB99dVXeu655/Tcc8+dO5/FokceeUTTp09X48aNFRsbq0mTJikqKkr9+vW75DgvhGQPADCF3w7FX+rxzrjuuuv0zjvvaOLEiUpISFBsbKzmzp2rQYMG2fs89thjysvL04gRI5SVlaXOnTtr3bp1CggIuPRAL4BkDwCAh/Tu3Vu9e/e+6H6LxaKEhAQlJCR4NA6SPQDAFCwursZ3ZQrA20j2AABTqOhh/MsJyR4AYApmTvbcegcAgI+jsgcAmEJF33p3OSHZAwBMwWo5t7lyfGXFMD4AAD6Oyh4AYAoM4wMA4ONYjQ8AAHwWlT0AwBQscm0ovhIX9iR7AIA5sBofAAD4LCp7/K6XVn2qeUvX6e6+nTTu/tskSdPnvaWtu1J1IjNHgQE2tWoeo1FDeik2uraXowXKxyLp1uYRuq5emEICqij7TJH+82OW1n1/3N7nlma11TY6VDUC/VVcYuhw1hmt+TZdP/x6xnuBwyVmXo3v1cp+8+bN6tOnj6KiomSxWLR69WpvhoPz7Nl/RG99uFWNY+s4tDdrdKWmjP6z3l78qJ6dPlSGYeiBx19QcXGJlyIFnNOjyRW6oUG4VqUc1bSP9+vdb9N101W11K1hTXuf47kFWpVyVDM+2a/Zmw7qZF6hRt4Qq+r+fl6MHK4oXY3vylZZeTXZ5+XlqVWrVlqwYIE3w8AFnD5ToH/MfE2THr5DIdUDHfbd0au92rZsoKiIcDVrVFcP3ttT6SeydfT4r16KFnBObM1q+vpojvakn1Lm6SLt+jlHe4/nKib8f3/Xtx/J1r7jeTqZV6Rjpwr09tfHFFjVT3VDA7wYOVxhccNWWXk12ffq1UvTp0/X7bff7s0wcAGJz67WDdc31f9d2/h3+53JL9R767erbmS4ImuFVlB0gGvSTp5Wk9rVVbu6vySpbmiAGtaspu/Scy/Y389iUafYcJ0uLNZP2fkVGSrgFpVqzr6goEAFBQX2zzk5OV6Mxnet+yxF36ce1SvPjLxon1VrkzX3pQ90Jr9Q9a+8QgtnDFPVqpXqrxNM7ON9JxRQ1apJPa6SYZwbnl2zJ0PbjmQ59GsRGaz72kerqp9VOflnNe+LNOUVFnsnaLjMKousLozFWytxbV+pVuMnJiYqNDTUvkVHR3s7JJ+TfiJLsxav0YzHBsrmX/Wi/Xp1b61X543SC/++X/Xq1tL4xBUqKCyqwEiBS9fmylBdFx2mpV8d0b82HNDL23/SjY1rqX29MId++0/kKvGTVD296aC+Sz+loe3rqbqNOfvKyszD+JWqFJs4caLGjBlj/5yTk0PCd7O9B35WZlau7n4oyd5WXFKind+m6fU1ydr67gz5+VkVHBSo4KBAxdStpWua1lOXAVO0ccse9erW2nvBA+V0e8tIfbzvhHb8lC1JOppToPBqVdWj6RXaejjL3q+w2NCJvEKdyJN+yPxZT/S8Sh3rh+vjfSe8FDlwaSpVsrfZbLLZbN4Ow6dd37qR3nh2tEPbE3PeUOyVV2jwn7vJz6/sYJDx3/9bVHS2AiIEXFfVz2r/e1uqxPjjW6sskqpU5iermJ2r5Xkl/p++UiV7eF5QNZsa1Y90aAsM8FdoSDU1qh+pn46d1Eebv1aHNo1VIzRIGb9ka8kbm2Tzr6rO1zX1UtSAc749dko9m9RW5ukiHcvJV3RYoP7UuJaSfzh3R4m/n0U3N62tr4/lKCf/rIL8/dS1YU2FBVbVrv+OBqDyMfN99l5N9rm5uUpNTbV/TktLU0pKisLDw1WvXj0vRoaL8fevql170rTy3S+Uk3tGNcOqq02LWC19+gGFh1X3dnhAuazafVS9m0doYOsoVf/vQ3W+OJSpD/eee6hOiSFFBNs0PCZGQf5+yiss1uFfz2j2Z4d07FTBH5wduPxYDMM4fzSrwmzatEndu3cv0x4fH6+lS5f+4fE5OTkKDQ3Vtn1HVT04xAMRAt43a/Mhb4cAeEzh6Vy9cl9HZWdnKyTEM/+Ol+aKDSmHXcoVuadydGPreh6N1VO8Wtl369ZNXvxdAwBgIiaesq9ct94BAADnsUAPAGAOJi7tSfYAAFNgNT4AAD7O1TfX8dY7AABw2aKyBwCYgomn7En2AACTMHG2ZxgfAAAfR2UPADAFVuMDAODjWI0PAAB8FpU9AMAUTLw+j2QPADAJE2d7hvEBAPBxVPYAAFNgNT4AAD7OzKvxSfYAAFMw8ZQ9c/YAAPg6KnsAgDmYuLQn2QMATMHMC/QYxgcAwMdR2QMATIHV+AAA+DgTT9kzjA8AgK+jsgcAmIOJS3uSPQDAFFiNDwAAfBaVPQDAFFiNDwCAjzPxlD3JHgBgEibO9szZAwDg40j2AABTsLjhz6X617/+JYvFokceecTelp+frwcffFA1a9ZU9erVdccddygjI8MN37Qskj0AwBws/1ukdynbpeb6bdu2afHixbrmmmsc2kePHq01a9bojTfe0GeffaajR4+qf//+rn/PCyDZAwDgIbm5uRo0aJCef/551ahRw96enZ2tF198UbNnz9af/vQntW3bVkuWLNGWLVv0n//8x+1xkOwBAKZgccMmSTk5OQ5bQUHBRa/54IMP6tZbb1VcXJxD+44dO1RUVOTQ3rRpU9WrV0/Jycnu+LoOSPYAAHNwU7aPjo5WaGiofUtMTLzg5V577TXt3LnzgvvT09Pl7++vsLAwh/aIiAilp6e7+k3L4NY7AACccOTIEYWEhNg/22y2C/YZNWqU1q9fr4CAgIoM74Ko7AEApuCu1fghISEO24WS/Y4dO3T8+HG1adNGVapUUZUqVfTZZ58pKSlJVapUUUREhAoLC5WVleVwXEZGhiIjI93+3ansAQCmUJGPy73xxhv1zTffOLQNGTJETZs21fjx4xUdHa2qVatqw4YNuuOOOyRJ+/bt0+HDh9WhQ4dLD/IiSPYAALhZcHCwWrRo4dAWFBSkmjVr2tuHDh2qMWPGKDw8XCEhIXrooYfUoUMH/d///Z/b4yHZAwBM4XJ7Wu6cOXNktVp1xx13qKCgQD179tSzzz7r5qucQ7IHAJiDl7P9pk2bHD4HBARowYIFWrBggWsnLgeSPQDAFFx95K0rx3obq/EBAPBxVPYAAFOwyMXV+G6LpOKR7AEApnC5LdCrSAzjAwDg46jsAQCmUJEP1bnckOwBACZh3oF8hvEBAPBxVPYAAFNgGB8AAB9n3kF8hvEBAPB5VPYAAFNgGB8AAB9n5mfjk+wBAOZg4kl75uwBAPBxVPYAAFMwcWFPsgcAmIOZF+gxjA8AgI+jsgcAmAKr8QEA8HUmnrRnGB8AAB9HZQ8AMAUTF/YkewCAObAaHwAA+CwqewCASbi2Gr8yD+ST7AEApsAwPgAA8FkkewAAfBzD+AAAUzDzMD7JHgBgCmZ+XC7D+AAA+DgqewCAKTCMDwCAjzPz43IZxgcAwMdR2QMAzMHEpT3JHgBgCqzGBwAAPovKHgBgCqzGBwDAx5l4yp5kDwAwCRNne+bsAQDwcVT2AABTMPNqfJI9AMAUWKBXSRmGIUnKzT3l5UgAzyk8nevtEACPKTyTJ+l//557Uk5OjleP96ZKnexPnTqX5Lu3beLlSAAArjh16pRCQ0M9cm5/f39FRkaqcWy0y+eKjIyUv7+/G6KqWBajIn6d8pCSkhIdPXpUwcHBslTm8ZVKJCcnR9HR0Tpy5IhCQkK8HQ7gVvz9rniGYejUqVOKioqS1eq5NeP5+fkqLCx0+Tz+/v4KCAhwQ0QVq1JX9larVVdeeaW3wzClkJAQ/jGEz+Lvd8XyVEX/WwEBAZUySbsLt94BAODjSPYAAPg4kj2cYrPZ9MQTT8hms3k7FMDt+PsNX1WpF+gBAIA/RmUPAICPI9kDAODjSPYAAPg4kj0AAD6OZI9yW7BggerXr6+AgAC1b99eX331lbdDAtxi8+bN6tOnj6KiomSxWLR69WpvhwS4Fcke5fL6669rzJgxeuKJJ7Rz5061atVKPXv21PHjx70dGuCyvLw8tWrVSgsWLPB2KIBHcOsdyqV9+/a67rrrNH/+fEnn3ksQHR2thx56SBMmTPBydID7WCwWvfPOO+rXr5+3QwHchsoef6iwsFA7duxQXFycvc1qtSouLk7JyclejAwAUB4ke/yhX375RcXFxYqIiHBoj4iIUHp6upeiAgCUF8keAAAfR7LHH6pVq5b8/PyUkZHh0J6RkaHIyEgvRQUAKC+SPf6Qv7+/2rZtqw0bNtjbSkpKtGHDBnXo0MGLkQEAyqOKtwNA5TBmzBjFx8erXbt2uv766zV37lzl5eVpyJAh3g4NcFlubq5SU1Ptn9PS0pSSkqLw8HDVq1fPi5EB7sGtdyi3+fPna9asWUpPT1fr1q2VlJSk9u3bezsswGWbNm1S9+7dy7THx8dr6dKlFR8Q4GYkewAAfBxz9gAA+DiSPQAAPo5kDwCAjyPZAwDg40j2AAD4OJI9AAA+jmQPAICPI9kDLho8eLDDu8+7deumRx55pMLj2LRpkywWi7Kysi7ax2KxaPXq1eU+55QpU9S6dWuX4vrhhx9ksViUkpLi0nkAXDqSPXzS4MGDZbFYZLFY5O/vr0aNGikhIUFnz571+LXffvttTZs2rVx9y5OgAcBVPBsfPuvmm2/WkiVLVFBQoA8++EAPPvigqlatqokTJ5bpW1hYKH9/f7dcNzw83C3nAQB3obKHz7LZbIqMjFRMTIz+/ve/Ky4uTu+9956k/w29z5gxQ1FRUWrSpIkk6ciRIxowYIDCwsIUHh6uvn376ocffrCfs7i4WGPGjFFYWJhq1qypxx57TOc/cfr8YfyCggKNHz9e0dHRstlsatSokV588UX98MMP9uex16hRQxaLRYMHD5Z07q2CiYmJio2NVWBgoFq1aqU333zT4ToffPCBrrrqKgUGBqp79+4OcZbX+PHjddVVV6latWpq0KCBJk2apKKiojL9Fi9erOjoaFWrVk0DBgxQdna2w/4XXnhBzZo1U0BAgJo2bapnn33W6VgAeA7JHqYRGBiowsJC++cNGzZo3759Wr9+vdauXauioiL17NlTwcHB+vzzz/Xll1+qevXquvnmm+3HPf3001q6dKleeuklffHFF8rMzNQ777zzu9e999579eqrryopKUl79+7V4sWLVb16dUVHR+utt96SJO3bt0/Hjh3TM888I0lKTEzU8uXLtWjRIu3Zs0ejR4/WPffco88++0zSuV9K+vfvrz59+iglJUXDhg3ThAkTnP6ZBAcHa+nSpfruu+/0zDPP6Pnnn9ecOXMc+qSmpmrVqlVas2aN1q1bp127dumBBx6w71+xYoUmT56sGTNmaO/evXryySc1adIkLVu2zOl4AHiIAfig+Ph4o2/fvoZhGEZJSYmxfv16w2azGWPHjrXvj4iIMAoKCuzHvPzyy0aTJk2MkpISe1tBQYERGBhofPTRR4ZhGEadOnWMmTNn2vcXFRUZV155pf1ahmEYXbt2NUaNGmUYhmHs27fPkGSsX7/+gnF++umnhiTj119/tbfl5+cb1apVM7Zs2eLQd+jQocZdd91lGIZhTJw40WjevLnD/vHjx5c51/kkGe+8885F98+aNcto27at/fMTTzxh+Pn5GT/99JO97cMPPzSsVqtx7NgxwzAMo2HDhsbKlSsdzjNt2jSjQ4cOhmEYRlpamiHJ2LVr10WvC8CzmLOHz1q7dq2qV6+uoqIilZSU6O6779aUKVPs+1u2bOkwT797926lpqYqODjY4Tz5+fk6ePCgsrOzdezYMYfX+lapUkXt2rUrM5RfKiUlRX5+furatWu5405NTdXp06d10003ObQXFhbq2muvlSTt3bu3zOuFO3ToUO5rlHr99deVlJSkgwcPKjc3V2fPnlVISIhDn3r16qlu3boO1ykpKdG+ffsUHBysgwcPaujQoRo+fLi9z9mzZxUaGup0PAA8g2QPn9W9e3ctXLhQ/v7+ioqKUpUqjn/dg4KCHD7n5uaqbdu2WrFiRZlzXXHFFZcUQ2BgoNPH5ObmSpLef/99hyQrnVuH4C7JyckaNGiQpk6dqp49eyo0NFSvvfaann76aadjff7558v88uHn5+e2WAG4hmQPnxUUFKRGjRqVu3+bNm30+uuvq3bt2mWq21J16tTR1q1b1aVLF0nnKtgdO3aoTZs2F+zfsmVLlZSU6LPPPlNcXFyZ/aUjC8XFxfa25s2by2az6fDhwxcdEWjWrJl9sWGp//znP3/8JX9jy5YtiomJ0T//+U97248//lim3+HDh3X06FFFRUXZr2O1WtWkSRNFREQoKipKhw4d0qBBg5y6PoCKwwI94L8GDRqkWrVqqW/fvvr888+VlpamTZs26eGHH9ZPP/0kSRo1apT+9a9/afXq1fr+++/1wAMP/O498vXr11d8fLzuu+8+rV692n7OVatWSZJiYmJksVi0du1anThxQrm5uQoODtbYsWM1evRoLVu2TAcPHtTOnTs1b948+6K3v/3tbzpw4IDGjRunffv2aeXKlVq6dKlT37dx48Y6fPiwXnvtNR08eFBJSUkXXGwYEBCg+Ph47d69W59//rkefvhhDRgwQJGRkZKkqVOnKjExUUlJSdq/f7+++eYbLVmyRLNnz3YqHgCeQ7IH/qtatWravHmz6tWrp/79+6tZs2YaOnSo8vPz7ZX+o48+qr/+9a+Kj49Xhw4dFBwcrNtvv/13z7tw4ULdeeedeuCBB9S0aVMNHz5ceXl5kqS6detq6tSpmjBhgiIiIjRy5EhJ0rRp0zRp0iQlJiaqWbNmuvnmm/X+++8rNjZW0rl59LfeekurV69Wq1attGjRIj355JNOfd/bbrtNo0eP1siRI9W6dWtt2bJFkyZNKtOvUaNG6t+/v2655Rb16NFD11xzjcOtdcOGDdMLL7ygJUuWqGXLluratauWLl1qjxWA91mMi60sAgAAPoHKHgAAH0eyBwDAx5HsAQDwcSR7AAB8HMkeAAAfR7IHAMDHkewBAPBxJHsAAHwcyR4AAB9HsgcAwMeR7AEA8HEkewAAfNz/A3sdRWOYe0gGAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_classes, normalize='all')\n",
        "\n",
        "# Display confusion matrix using sklearn's visualization tool\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "yCh9FLX3wRax",
        "outputId": "1af7a36e-ba39-4cdd-f2d4-f8a3f9d6d215"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check whether testset is imbalanced\n",
        "print(f\"positive classes in test set: {(y_test == 1).sum()}; negative class in test set: {(y_test == 0).sum()}\")\n",
        "print(f\"positive classes in test set: {(y_train == 1).sum()}; negative class in test set: {(y_train == 0).sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXKq2qqpvF8I",
        "outputId": "9523f24b-5126-4c36-970b-3ecc23f43da1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive classes in test set: 126; negative class in test set: 160\n",
            "positive classes in test set: 1137; negative class in test set: 1733\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's see example of errors\n",
        "\n",
        "# False Positive: Predicted as 1 but actual is 0\n",
        "false_positives = np.where((y_pred_classes == 1) & (y_test.astype('int32') == 0))[0]\n",
        "\n",
        "# False Negative: Predicted as 0 but actual is 1\n",
        "false_negatives = np.where((y_pred_classes == 0) & (y_test.astype('int32') == 1))[0]"
      ],
      "metadata": {
        "id": "0IxESBwAxDw4"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_probs[false_positives]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIpU6jZ14crj",
        "outputId": "4004f511-5b48-4f0a-a554-74e3036a6ce2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.8435365 , 0.6135118 , 0.7644112 , 0.61166334, 0.82029605,\n",
              "       0.989393  , 0.7251836 , 0.79418707, 0.7755449 , 0.9421292 ,\n",
              "       0.88819844, 0.51489127, 0.86378646, 0.8299181 , 0.849805  ,\n",
              "       0.5228213 , 0.7095722 , 0.84478587, 0.8487853 , 0.89769155,\n",
              "       0.90187263, 0.87401944, 0.84304   , 0.6987388 , 0.67142755],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_probs[false_negatives]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWrhi5xN4vJU",
        "outputId": "26839d63-aa02-4a1f-f3c4-3274defc9856"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.15323438, 0.23875079, 0.13259995, 0.02763895, 0.33291402,\n",
              "       0.0086146 , 0.25041392, 0.2775403 , 0.1782518 , 0.16291553,\n",
              "       0.109284  , 0.1609927 , 0.09381234, 0.17061967, 0.25208876,\n",
              "       0.1615212 , 0.38984492, 0.45257407, 0.3734185 , 0.01432866,\n",
              "       0.15068427, 0.03415782, 0.00893982, 0.07122347, 0.01392036,\n",
              "       0.33597085, 0.02748449, 0.44942382, 0.34080598, 0.10416926,\n",
              "       0.04488195, 0.09312115, 0.3732928 , 0.09947425, 0.1601122 ,\n",
              "       0.40786946, 0.07993914, 0.3282799 , 0.34231362, 0.13131489,\n",
              "       0.34967518, 0.21777433, 0.11471594], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#detokenizing the sequences\n",
        "def detokenize(sequence, index_to_word):\n",
        "\n",
        "    # 4. Map tokens to indices, use 'UNK' index if not found\n",
        "    text = [index_to_word.get(token, '') for token in sequence]\n",
        "\n",
        "    return ' '.join(text)"
      ],
      "metadata": {
        "id": "ErZ2GAwC29nF"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's see all False Negatives and count how many of them contain OOV\n",
        "oov = 0\n",
        "\n",
        "for id in false_negatives:\n",
        "    detokenized = detokenize(x_test[id][x_test[id]>0], idx_to_word)\n",
        "    print(f\"detokenized lemmatized version of tweet: {detokenized}\")\n",
        "    print(f\"real tweet: {test['tweet'].iloc[id]}\")\n",
        "    print(f\"{detokenized.count('UNK')} OOV tokens\")\n",
        "    print()\n",
        "    if 'UNK' in detokenized:\n",
        "      oov += 1\n",
        "\n",
        "print(f\"Number of False Negatives with OOV word is: {oov} out of {len(false_negatives)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nifj6j1synPN",
        "outputId": "8c24cd13-c840-4cdf-eeaf-690483460617"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "detokenized lemmatized version of tweet: UNK get gangbanged to death\n",
            "real tweet: suika gets gangbanged to death\n",
            "1 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: maybe something involve her get gangbanged\n",
            "real tweet: maybe something involving her getting gangbanged\n",
            "0 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: UNK islamic UNK of afghanistan have announce the end of UNK in the country cite gender UNK student will attend university on UNK wednesday and saturday while tuesday thursday and sunday be fix for male\n",
            "real tweet: kabul islamic emirate of afghanistan has announced the end of coeducation in the country citing gender harassmentfemale students will attend universities on monday wednesday and saturday while tuesday thursday and sunday are fixed for males\n",
            "5 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: the violent UNK of a farright movement that see UNK a vessel for breed a new white generation express itself in a UNK on UNK to traditional gender UNK every minute to read take 5 min out of your sun\n",
            "real tweet: the violent antifeminism of a farright movement that sees principally as vessels for breeding a new white generation expresses itself in a fixation on areturn to traditional gender rolesworth every minute to read take 5 min out of your sun\n",
            "5 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: hot girl cant get nowhere without a UNK\n",
            "real tweet: hot girls cant get nowhere without a gps\n",
            "1 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: that gold digger be nice but the picture and set up for them be elite UNK be like the UNK of the UNK UNK always a work of art\n",
            "real tweet: that gold digger is nice but the picture and set up for them are elite pinwork is like the revealing of the mona lisa always a work of art\n",
            "4 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: best way to do that be from behind her with your hand on her hip\n",
            "real tweet: best way to do that is from behind her with your hands on her hips\n",
            "0 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: wait till ur husband mess up u gonna love the UNK death threat\n",
            "real tweet: wait till ur husband messes up u gonna love the scouser death threats\n",
            "1 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: UNK i still get an exam tomorrow i hate woman\n",
            "real tweet: aughhh i still got an exam tomorrow i hate women\n",
            "1 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: call to clean up UNK laddish culture after mp porn shame via\n",
            "real tweet: calls to clean up parliaments laddish culture after mps porn shame via\n",
            "1 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: mansplaining the concept of a pee drawer to my partner who want me\n",
            "real tweet: mansplaining the concept of a pee drawer to my partner who want me\n",
            "0 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: UNK cross legs amp UNK manspreading\n",
            "real tweet: wonwoo cross legs amp jun manspreading\n",
            "2 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: go weak rn play the UNK manspreading i be on my knee\n",
            "real tweet: going weak rn playing the guitar manspreading i am on my knees\n",
            "1 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: can you confront your misogyny misandry be hardly a problem in the world by comparison and if it exist it a reaction to abuse\n",
            "real tweet: can you confront your misogyny misandry is hardly a problem in the world by comparison and if it exists its a reaction to abuse\n",
            "0 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: most woman nowadays look like this with no makeup hard to find the good one under ton of makeup always go on a date to the beach lol\n",
            "real tweet: most women nowadays look like this with no makeup hard to find the good ones under ton of makeup always go on a date to the beach lol\n",
            "0 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: i dont need a man to tell me what to stand up for thank you\n",
            "real tweet: i dont need a man to tell me what to stand up for thank you\n",
            "0 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: they arent because when a woman be financially stable she believe she doesnt need a man\n",
            "real tweet: they arent because when a woman is financially stable she believes she doesnt need a man\n",
            "0 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: female UNK be UNK isnt always bad n i know UNK have always kinda have an UNK issue most medium do tbh but it seem to be nearly the only way the game be interested in present woman and it kinda suck esp since yea the game be good\n",
            "real tweet: female charas being flirtysexy isnt always bad n i know digimon has always kinda had an objectificationofwomen issue most media does tbh but it seems to be nearly the only way the game is interested in presenting women and it kinda sucks esp since yea the game is good\n",
            "4 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: it objectification amp UNK i saw someone take time out of their day to make a strong political point about UNK sarcasm he tweet about how her photo look like it have lot of UNK such pathetic clown\n",
            "real tweet: its objectification amp dehumanizing i saw someone take time out of their day to make a strong political point about horwath sarcasm he tweeted about how her photo looked like it had lots of photoshop such pathetic clowns\n",
            "3 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: why bother go to UNK if life there be just go to be more of the same toxic sexism racism and bigotry the same horrible oppression unfairness and inequality that make earth a living hell for so many\n",
            "real tweet: why bother going to mars if life there is just going to be more of the same toxic sexism racism and bigotry the same horrible oppression unfairness and inequality that makes earth a living hell for so many\n",
            "1 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: have i miss something or have phallocentrism become the late cult\n",
            "real tweet: have i missed something or has phallocentrism become the latest cult\n",
            "0 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: fuck sake be it possible to have a furry space thats not explicitly UNK and doesnt immediately become yet another showcase for UNK phallocentrism\n",
            "real tweet: fucks sake is it possible to have a furry space thats not explicitly contentrestricted and doesnt immediately become yet another showcase for sizequeen phallocentrism\n",
            "2 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: cyborg politics be the struggle for language and the struggle against perfect communication against the one code that translate all mean perfectly the central UNK of phallogocentrism\n",
            "real tweet: cyborg politics is the struggle for language and the struggle against perfect communication against the one code that translates all meaning perfectly the central dogma of phallogocentrism\n",
            "1 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: eat out both hole and then slide my dick in you and pound you till you UNK\n",
            "real tweet: eat out both holes and then slide my dick in you and pound you till you squirt\n",
            "1 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: accord to the human right commission 1 in 3 people experience sexual harassment at work we have create an online course provide strategy to prevent and respond should UNK occur start your course at\n",
            "real tweet: according to the human rights commission 1 in 3 people experience sexual harassment at work we have created an online course providing strategies to prevent and respond should incidents occur start your course at\n",
            "1 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: i dont care what gender race UNK orientation a person be as long a they be qualify for that position that be say be she qualify base on UNK or be she choose solely because she be black and gay to please UNK just say\n",
            "real tweet: i dont care what gender race religionsexual orientation a person is as long as they are qualified for that position that being said is she qualified based on experienceeducation or was she chosen solely because she is black and gay to please progressiveswoke just saying\n",
            "3 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: it just show how money rule the world im so UNK that UNK would even allow it out of the building and to let that reality skank get it be an incredible insult i be wait for an sub full of UNK UNK to UNK her in the end UNK look well\n",
            "real tweet: it just shows how money rules the world im so disappointed that ripleys would even allow it out of the building and to let that reality skank get it was an incredible insult i was waiting for an sub full of armed robbers to overtake her in the end khloe looked better\n",
            "6 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: i kinda get her point but a slag be too far off for me\n",
            "real tweet: i kinda get her point but a slag is too far off for me\n",
            "0 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: yea back when i didnt even have one to slap unfortunate\n",
            "real tweet: yea back when i didnt even have one to slap unfortunate\n",
            "0 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: jealous UNK talk about his new album u UNK slutbag\n",
            "real tweet: jealous plss talk about his new album u wrinkly slutbag\n",
            "2 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: UNK i literally take it last night slutbag\n",
            "real tweet: der i literally took it last night slutbag\n",
            "1 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: never know you all share UNK how do we stop be UNK again yeah\n",
            "real tweet: never knew you all share tits how did we stop being pals again yeah\n",
            "2 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: UNK UNK\n",
            "real tweet: bounceeyyyy boobieeeessssss\n",
            "2 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: then proceed to have the UNK to inform me that it be UNK and too early for trophy UNK talk\n",
            "real tweet: then proceeded to have the audacity to inform me that it was 8am and too early for trophy wifegf talk\n",
            "3 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: i pack my UNK case when we be go to a UNK in england tell him to pop his underpants in get to england he put his UNK outfit on and everyone discover what a true UNK doesnt wear under his UNK if i dont do it it doesnt get do men\n",
            "real tweet: i packed my hubbies case when we were going to a wedding in england told him to pop his underpants in gets to england he puts his kilt outfit on and everyone discovered what a true scot doesnt wear under his kilt if i dont do it it doesnt get done men\n",
            "5 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: woman before soy UNK and UNK UNK be just typical woman average back UNK\n",
            "real tweet: women before soy oil and corn syrupthose were just typical woman average back thenn\n",
            "4 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: so why tf ya call it UNK shouldnt it be womanism if thats the case\n",
            "real tweet: so why tf ya call it femism shouldnt it be womanism if thats the case\n",
            "1 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: you dont know who UNK womanism huh okay risk skin cancer i guess best of luck to you\n",
            "real tweet: you dont know who invented womanism huh okay risk skin cancer i guess best of luck to you\n",
            "1 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: say the man who be always on his phone well in your case you can still UNK woman for sex while outside\n",
            "real tweet: says the man who is always on his phone well in your case you can still proposition women for sex while outside\n",
            "1 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: 2 UNK room the other UNK i think you have be in term of your comparison to UNK novel while you may be correct that there may be a difference in interest in your comparison there be no UNK for men to buy UNK novel woman have to UNK themselves for\n",
            "real tweet: 2 poker rooms the other fallacy i think you have is in terms of your comparison to romance novels while you may be correct that there may be a difference in interest in your comparison there are no barriers for men to buy romance novels women have to brace themselves for\n",
            "6 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: didnt abuse him say it to his UNK to prove this be a false UNK the UNK UNK hurting of woman generally to the extent he warn his companion that woman shouldnt be hurt during war UNK of be UNK UNK be against kill of any unless\n",
            "real tweet: didnt abuse him saying it to his faceproofs to prove this is a false writing_ the prophet detest hurting of women generally to the extent he warned his companions that women shouldnt be hurt during wars talkless of being killedthe prophet is against killing of any unless\n",
            "7 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: you look like a UNK i be now move UNK i dont like you\n",
            "real tweet: you look like a bitchwell i am now move kz i dont like you\n",
            "2 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: this UNK be no more then selfish cunt more matter how genuine you be you do all the right thing and they still make you look like a cunt it only get bad too and people ask me why i dont bother with anyone\n",
            "real tweet: this genration are no more then selfish cunts more matter how genuine you are you do all the right things and they still make you look like a cunt its only getting worse too and people ask me why i dont bother with anyone\n",
            "1 OOV tokens\n",
            "\n",
            "Number of False Negatives with OOV word is: 33 out of 43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#worst False Negatives\n",
        "worst_FN = np.where(y_pred_probs[false_negatives] <= 0.1)[0]\n",
        "\n",
        "for id in worst_FN:\n",
        "    detokenized = detokenize(x_test[false_negatives[id]][x_test[false_negatives[id]]>0], idx_to_word)\n",
        "    print(y_pred_probs[false_negatives[id]])\n",
        "    print(f\"detokenized lemmatized version of tweet: {detokenized}\")\n",
        "    print(f\"real tweet: {test['tweet'].iloc[false_negatives[id]]}\")\n",
        "    print(f\"{detokenized.count('UNK')} OOV tokens\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6gj2C_-7O9N",
        "outputId": "ba1ebbb5-3109-4341-dca4-641db05106a6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.027638953\n",
            "detokenized lemmatized version of tweet: the violent UNK of a farright movement that see UNK a vessel for breed a new white generation express itself in a UNK on UNK to traditional gender UNK every minute to read take 5 min out of your sun\n",
            "real tweet: the violent antifeminism of a farright movement that sees principally as vessels for breeding a new white generation expresses itself in a fixation on areturn to traditional gender rolesworth every minute to read take 5 min out of your sun\n",
            "5 OOV tokens\n",
            "\n",
            "0.008614599\n",
            "detokenized lemmatized version of tweet: that gold digger be nice but the picture and set up for them be elite UNK be like the UNK of the UNK UNK always a work of art\n",
            "real tweet: that gold digger is nice but the picture and set up for them are elite pinwork is like the revealing of the mona lisa always a work of art\n",
            "4 OOV tokens\n",
            "\n",
            "0.09381234\n",
            "detokenized lemmatized version of tweet: go weak rn play the UNK manspreading i be on my knee\n",
            "real tweet: going weak rn playing the guitar manspreading i am on my knees\n",
            "1 OOV tokens\n",
            "\n",
            "0.014328657\n",
            "detokenized lemmatized version of tweet: why bother go to UNK if life there be just go to be more of the same toxic sexism racism and bigotry the same horrible oppression unfairness and inequality that make earth a living hell for so many\n",
            "real tweet: why bother going to mars if life there is just going to be more of the same toxic sexism racism and bigotry the same horrible oppression unfairness and inequality that makes earth a living hell for so many\n",
            "1 OOV tokens\n",
            "\n",
            "0.034157816\n",
            "detokenized lemmatized version of tweet: fuck sake be it possible to have a furry space thats not explicitly UNK and doesnt immediately become yet another showcase for UNK phallocentrism\n",
            "real tweet: fucks sake is it possible to have a furry space thats not explicitly contentrestricted and doesnt immediately become yet another showcase for sizequeen phallocentrism\n",
            "2 OOV tokens\n",
            "\n",
            "0.008939821\n",
            "detokenized lemmatized version of tweet: cyborg politics be the struggle for language and the struggle against perfect communication against the one code that translate all mean perfectly the central UNK of phallogocentrism\n",
            "real tweet: cyborg politics is the struggle for language and the struggle against perfect communication against the one code that translates all meaning perfectly the central dogma of phallogocentrism\n",
            "1 OOV tokens\n",
            "\n",
            "0.07122347\n",
            "detokenized lemmatized version of tweet: eat out both hole and then slide my dick in you and pound you till you UNK\n",
            "real tweet: eat out both holes and then slide my dick in you and pound you till you squirt\n",
            "1 OOV tokens\n",
            "\n",
            "0.01392036\n",
            "detokenized lemmatized version of tweet: accord to the human right commission 1 in 3 people experience sexual harassment at work we have create an online course provide strategy to prevent and respond should UNK occur start your course at\n",
            "real tweet: according to the human rights commission 1 in 3 people experience sexual harassment at work we have created an online course providing strategies to prevent and respond should incidents occur start your course at\n",
            "1 OOV tokens\n",
            "\n",
            "0.027484491\n",
            "detokenized lemmatized version of tweet: it just show how money rule the world im so UNK that UNK would even allow it out of the building and to let that reality skank get it be an incredible insult i be wait for an sub full of UNK UNK to UNK her in the end UNK look well\n",
            "real tweet: it just shows how money rules the world im so disappointed that ripleys would even allow it out of the building and to let that reality skank get it was an incredible insult i was waiting for an sub full of armed robbers to overtake her in the end khloe looked better\n",
            "6 OOV tokens\n",
            "\n",
            "0.044881955\n",
            "detokenized lemmatized version of tweet: UNK i literally take it last night slutbag\n",
            "real tweet: der i literally took it last night slutbag\n",
            "1 OOV tokens\n",
            "\n",
            "0.09312115\n",
            "detokenized lemmatized version of tweet: never know you all share UNK how do we stop be UNK again yeah\n",
            "real tweet: never knew you all share tits how did we stop being pals again yeah\n",
            "2 OOV tokens\n",
            "\n",
            "0.09947425\n",
            "detokenized lemmatized version of tweet: then proceed to have the UNK to inform me that it be UNK and too early for trophy UNK talk\n",
            "real tweet: then proceeded to have the audacity to inform me that it was 8am and too early for trophy wifegf talk\n",
            "3 OOV tokens\n",
            "\n",
            "0.07993914\n",
            "detokenized lemmatized version of tweet: so why tf ya call it UNK shouldnt it be womanism if thats the case\n",
            "real tweet: so why tf ya call it femism shouldnt it be womanism if thats the case\n",
            "1 OOV tokens\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's see all False Positives and count how many of them contain OOV\n",
        "oov = 0\n",
        "\n",
        "for id in false_positives:\n",
        "    detokenized = detokenize(x_test[id][x_test[id]>0], idx_to_word)\n",
        "    print(f\"detokenized lemmatized version of tweet: {detokenized}\")\n",
        "    print(f\"real tweet: {test['tweet'].iloc[id]}\")\n",
        "    print(f\"{detokenized.count('UNK')} OOV tokens\")\n",
        "    print()\n",
        "    if 'UNK' in detokenized:\n",
        "      oov += 1\n",
        "\n",
        "print(f\"Number of False Positives with OOV word is: {oov} out of {len(false_positives)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwIrJ2-j1cvz",
        "outputId": "663dda6b-aff2-49da-9201-ea5474b1429e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "detokenized lemmatized version of tweet: sex a in gender harassment be what they be UNK\n",
            "real tweet: sex as in gender harassment is what they are inferring\n",
            "1 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: my baby call me UNK sha for the first time today twice yall dont understand how UNK that make me baby girl have autism and get her to talk without be prompt have be a challenge shes come so far\n",
            "real tweet: my baby called me mommy sha for the first time today twice yall dont understand how hype that made me baby girl has autism and getting her to talk without being prompted has been a challenge shes come so far\n",
            "2 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: how do we reach a point where UNK be have the UNK to talk about UNK rap do yall see who you stan be yall ok your girl cant write cant deliver cant come close to UNK UNK tf be yall get brave for fashion deal\n",
            "real tweet: how did we reach a point where blonks are having the audacity to talk about yoongis rap do yall see who you stan are yall ok your girls cant write cant deliver cant come close to btss lyricism tf are yall getting brave for fashion deals\n",
            "5 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: he try to expose this gold digger but it UNK 90 day fiance b via\n",
            "real tweet: he tries to expose this gold digger but it backfires 90 day fiance b via\n",
            "1 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: yall be husband and wife and best friend you guy have so much fun it awesome you keep each other laughing and smile\n",
            "real tweet: yall are husband and wife and best friends you guys have so much fun its awesome you keep each other laughing and smiling\n",
            "0 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: yup i hate when men rape and kill woman\n",
            "real tweet: yup i hate when men rape and kill women\n",
            "0 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: UNK let anyone body shame you in any wayyou be fat so UNK be beautiful my UNK confident in UNK\n",
            "real tweet: ladiesdont let anyone body shame you in any wayyou are fat so whatyou are beautiful my dearbe confident in yourselfpeace\n",
            "4 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: stop dont lie to these people lady dont let this man trick you out of the great UNK of your life cause what\n",
            "real tweet: stop dont lie to these people ladies dont let this man trick you out of the greatest organs of your life cause what\n",
            "1 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: lady dont have a miscarriage in UNK if you do in addition to probably have your friend and family sue by some UNK UNK youll be charge with murder\n",
            "real tweet: ladies dont have a miscarriage in louisiana if you do in addition to probably having your friends and family sued by some opportunistic yokel youll be charged with murder\n",
            "3 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: not all men look good with beard btw pls stop try to grow it out\n",
            "real tweet: not all men look good with beard btw pls stop trying to grow it out\n",
            "0 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: on the audio from when his finger be cut off even the people that be there say she do it she say shes totally against cocaine but do cocaine try to say the nurse be basically lie in her note about her do drug everyone be lie but her\n",
            "real tweet: on the audio from when his finger was cut off even the people that were there said she did it she says shes totally against cocaine but does cocaine tries to say the nurse is basically lying in her notes about her doing drugs everyone is lying but her\n",
            "0 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: it be interest to see other UNK lie in english that the reason they didnt feed child be because it would take away from their family time etc no it UNK a patriarchal this be the food we have for the winter for our mouth not others\n",
            "real tweet: it was interesting to see other swedes lying in english that the reason they didnt feed children was because it would take away from their family time etc no its survivalism a patriarchal this is the food we have for the winter for our mouths not others\n",
            "2 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: part of the experience of be a black man be deal with the penis envy amp gossip mentality of other race of men we just be chill amp they be hat for no reason it definitely something that stay in the back of some of their mind but men in general get along very well\n",
            "real tweet: part of the experience of being a black man is dealing with the penis envy amp gossip mentality of other races of men we just be chilling amp they be hating for no reason its definitely something that stays in the back of some of their minds but men in general get along very well\n",
            "0 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: call a man bald be sexual harassment via\n",
            "real tweet: calling a man bald is sexual harassment via\n",
            "0 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: the bill define UNK therapy a practice intend to change a lesbian gay bisexual transgender or queer individual sexual orientation gender identity or both\n",
            "real tweet: the bill defined conversion therapy as practices intended to change a lesbian gay bisexual transgender or queer individuals sexual orientation gender identity or both\n",
            "1 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: so you stereotype someone base on their appearance be what make you some form of UNK individual a oppose to a UNK racist cretin get it judge people by the race and appearance accord to this guy\n",
            "real tweet: so you stereotyping someone based on their appearance is what makes you some form of enlightened individual as opposed to a throwback racist cretin got it judge people by the race and appearance according to this guy\n",
            "2 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: cant take my eye off you youd be like heaven to touch i wanna hold you so much\n",
            "real tweet: cant take my eyes off you youd be like heaven to touch i wanna hold you so much\n",
            "0 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: oh so now u cant understand womens word\n",
            "real tweet: oh so now u cant understand womens words\n",
            "0 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: the question be do i wear the very short skirt that literally show my as with UNK or UNK out for a short\n",
            "real tweet: the question is do i wear the very short skirt that literally shows my ass with kneehighs or opt out for a short\n",
            "2 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: im so annoy by ex mutuals who hurt my friend amp UNK act like UNK good when it be a couple month amp they can UNK try to UNK me again amp when i dont forgive them they pull this victim card shit on my own friend like how dare you\n",
            "real tweet: im so annoyed by ex mutuals who hurt my friends amp suddenly act like everythings good when its been a couple months amp they can suddenly try to befriend me again amp when i dont forgive them they pull this victim card shit on my own friends like how dare you\n",
            "4 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: my new favorite meme be the pregnant woman drive in the UNK UNK lane tell the state trooper who pull her over that she be drive with another person\n",
            "real tweet: my new favorite meme is the pregnant woman driving in the oklahoma hov lane telling the state trooper who pulled her over that she is driving with another person\n",
            "2 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: yeah woman be get just a bad ive notice it anyway im sorry people be send you stuff like that it can be so gross\n",
            "real tweet: yeah women are getting just as bad ive noticed it anyway im sorry people are sending you stuff like that it can be so gross\n",
            "0 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: yo i swear UNK men and woman be the funny\n",
            "real tweet: yo i swear sagittarius men and women are the funniest\n",
            "1 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: woman shouldnt have to share their trauma story for you to feel empathy for the way theyre feel today stand with them we deserve a choice UNK si UNK\n",
            "real tweet: women shouldnt have to share their trauma stories for you to feel empathy for the way theyre feeling today stand with them we deserve a choice juntas si podemos\n",
            "2 OOV tokens\n",
            "\n",
            "detokenized lemmatized version of tweet: how will they be drag by action i show you where i be stand i tell you what i be wear im not go to yell or shout just hold a sign how will that bring hate upon the guy\n",
            "real tweet: how will they be dragged by actions i showed you where i am standing i told you what i am wearing im not going to yell or shout just holding a sign how will that bring hate upon the guys\n",
            "0 OOV tokens\n",
            "\n",
            "Number of False Positives with OOV word is: 15 out of 25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#worst False Positives\n",
        "worst_FP = np.where(y_pred_probs[false_positives] >= 0.9)[0]\n",
        "\n",
        "for id in worst_FP:\n",
        "    detokenized = detokenize(x_test[false_positives[id]][x_test[false_positives[id]]>0], idx_to_word)\n",
        "    print(y_pred_probs[false_positives[id]])\n",
        "    print(f\"detokenized lemmatized version of tweet: {detokenized}\")\n",
        "    print(f\"real tweet: {test['tweet'].iloc[false_positives[id]]}\")\n",
        "    print(f\"{detokenized.count('UNK')} OOV tokens\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7UqHM7mAd0b",
        "outputId": "e4f87186-e33f-4599-e224-b8f42d3a8e51"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.989393\n",
            "detokenized lemmatized version of tweet: yup i hate when men rape and kill woman\n",
            "real tweet: yup i hate when men rape and kill women\n",
            "0 OOV tokens\n",
            "\n",
            "0.9421292\n",
            "detokenized lemmatized version of tweet: not all men look good with beard btw pls stop try to grow it out\n",
            "real tweet: not all men look good with beard btw pls stop trying to grow it out\n",
            "0 OOV tokens\n",
            "\n",
            "0.90187263\n",
            "detokenized lemmatized version of tweet: my new favorite meme be the pregnant woman drive in the UNK UNK lane tell the state trooper who pull her over that she be drive with another person\n",
            "real tweet: my new favorite meme is the pregnant woman driving in the oklahoma hov lane telling the state trooper who pulled her over that she is driving with another person\n",
            "2 OOV tokens\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SINCE EMBEDDINGS ARE NOT TRAINED, SO THOSE TOKENS THAT WERE OOV FOR GLOVE EMBEDDING STILL HAVE RANDOM EMBEDDINGS THE SAME AS 'UNK'. SO NEED TO SEE HOW MANY INITIALLY OOV WORDS ARE IN EACH ERROR PREDICTION."
      ],
      "metadata": {
        "id": "0AueXCRCBFVq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Clearly because of OOV words\n",
        "detokenized lemmatized version of tweet: never know you all share UNK how do we stop be UNK again yeah  \n",
        "real tweet: never knew you all share tits how did we stop being pals again yeah\n",
        "\n",
        "#### Clear mistake  \n",
        "detokenized lemmatized version of tweet: UNK i still get an exam tomorrow i hate woman  \n",
        "real tweet: aughhh i still got an exam tomorrow i hate women"
      ],
      "metadata": {
        "id": "KW7zI12vtoaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test['tweet'][false_positives[0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "M-cB3JCY1LrJ",
        "outputId": "ef78e313-3b44-4551-dd53-224325a688c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-69-064c7e52b3d9>:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  test['tweet'][false_positives[0]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sex as in gender harassment is what they are inferring'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "so, I can analyze some mistakes, some biggest mistakes, analyze if they contain OOV or how much of errors contained OOV, analyze the plots. Train set is imbalanced, so performance on  test set is biased towards not_sexist"
      ],
      "metadata": {
        "id": "dAJfQ2oB41KW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P42XYjb6K3k5"
      },
      "source": [
        "# [Task 8 - 0.5 points] Report\n",
        "\n",
        "Wrap up your experiment in a short report (up to 2 pages)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9oXSaW1K5S7"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* Use the NLP course report template.\n",
        "* Summarize each task in the report following the provided template."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHw2L6PlLDyE"
      },
      "source": [
        "### Recommendations\n",
        "\n",
        "The report is not a copy-paste of graphs, tables, and command outputs.\n",
        "\n",
        "* Summarize classification performance in Table format.\n",
        "* **Do not** report command outputs or screenshots.\n",
        "* Report learning curves in Figure format.\n",
        "* The error analysis section should summarize your findings.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMUqh1utLflM"
      },
      "source": [
        "# Submission\n",
        "\n",
        "* **Submit** your report in PDF format.\n",
        "* **Submit** your python notebook.\n",
        "* Make sure your notebook is **well organized**, with no temporary code, commented sections, tests, etc...\n",
        "* You can upload **model weights** in a cloud repository and report the link in the report."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypagJed7LheY"
      },
      "source": [
        "# FAQ\n",
        "\n",
        "Please check this frequently asked questions before contacting us"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgtFwKXMLjww"
      },
      "source": [
        "### Execution Order\n",
        "\n",
        "You are **free** to address tasks in any order (if multiple orderings are available)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BjMk5e_M4n7"
      },
      "source": [
        "### Trainable Embeddings\n",
        "\n",
        "You are **free** to define a trainable or non-trainable Embedding layer to load the GloVe embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8TVgpYlM6s5"
      },
      "source": [
        "### Model architecture\n",
        "\n",
        "You **should not** change the architecture of a model (i.e., its layers).\n",
        "However, you are **free** to play with their hyper-parameters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ia6IapI1M_A7"
      },
      "source": [
        "### Neural Libraries\n",
        "\n",
        "You are **free** to use any library of your choice to implement the networks (e.g., Keras, Tensorflow, PyTorch, JAX, etc...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWDaW8DyNBu5"
      },
      "source": [
        "### Keras TimeDistributed Dense layer\n",
        "\n",
        "If you are using Keras, we recommend wrapping the final Dense layer with `TimeDistributed`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1WcrpemNEQm"
      },
      "source": [
        "### Robust Evaluation\n",
        "\n",
        "Each model is trained with at least 3 random seeds.\n",
        "\n",
        "Task 4 requires you to compute the average performance over the 3 seeds and its corresponding standard deviation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mVe5dqzNI_u"
      },
      "source": [
        "### Model Selection for Analysis\n",
        "\n",
        "To carry out the error analysis you are **free** to either\n",
        "\n",
        "* Pick examples or perform comparisons with an individual seed run model (e.g., Baseline seed 1337)\n",
        "* Perform ensembling via, for instance, majority voting to obtain a single model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8a4pDKSNKzI"
      },
      "source": [
        "### Error Analysis\n",
        "\n",
        "Some topics for discussion include:\n",
        "   * Precision/Recall curves.\n",
        "   * Confusion matrices.\n",
        "   * Specific misclassified samples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "ThjNAPkj_HhS"
      },
      "source": [
        "### Bonus Points\n",
        "Bonus points are arbitrarily assigned based on significant contributions such as:\n",
        "- Outstanding error analysis\n",
        "- Masterclass code organization\n",
        "- Suitable extensions\n",
        "Note that bonus points are only assigned if all task points are attributed (i.e., 6/6).\n",
        "\n",
        "**Possible Extensions/Explorations for Bonus Points:**\n",
        "- **Try other preprocessing strategies**: e.g., but not limited to, explore techniques tailored specifically for tweets or  methods that are common in social media text.\n",
        "- **Experiment with other custom architectures or models from HuggingFace**\n",
        "- **Explore Spanish tweets**: e.g., but not limited to, leverage multilingual models to process Spanish tweets and assess their performance compared to monolingual models.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xmMKE7vLu-y"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# The End"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}